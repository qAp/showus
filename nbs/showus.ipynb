{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "amino-address",
   "metadata": {
    "tags": []
   },
   "source": [
    "# showus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-american",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#default_exp showus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-decline",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/nlp-packages/datasets/datasets/fsspec-2021.4.0-py3-none-any.whl\r\n",
      "Installing collected packages: fsspec\r\n",
      "  Attempting uninstall: fsspec\r\n",
      "    Found existing installation: fsspec 0.8.7\r\n",
      "    Uninstalling fsspec-0.8.7:\r\n",
      "      Successfully uninstalled fsspec-0.8.7\r\n",
      "Successfully installed fsspec-2021.4.0\r\n",
      "Looking in links: file:///kaggle/input/coleridge-packages/packages/datasets\r\n",
      "Processing /kaggle/input/coleridge-packages/packages/datasets/datasets-1.5.0-py3-none-any.whl\r\n",
      "Processing /kaggle/input/coleridge-packages/packages/datasets/huggingface_hub-0.0.7-py3-none-any.whl\r\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.11.1)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.2.3)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.19.5)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.25.1)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.7/site-packages (from datasets) (2021.4.0)\r\n",
      "Processing /kaggle/input/coleridge-packages/packages/datasets/tqdm-4.49.0-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.3)\r\n",
      "Requirement already satisfied: pyarrow>=0.17.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (3.0.0)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (3.4.0)\r\n",
      "Processing /kaggle/input/coleridge-packages/packages/datasets/xxhash-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2020.12.5)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.4)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (4.0.0)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.10)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.4.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.7.4.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.1)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2021.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\r\n",
      "Installing collected packages: tqdm, xxhash, huggingface-hub, datasets\r\n",
      "  Attempting uninstall: tqdm\r\n",
      "    Found existing installation: tqdm 4.59.0\r\n",
      "    Uninstalling tqdm-4.59.0:\r\n",
      "      Successfully uninstalled tqdm-4.59.0\r\n",
      "Successfully installed datasets-1.5.0 huggingface-hub-0.0.7 tqdm-4.49.0 xxhash-2.0.0\r\n",
      "Processing /kaggle/input/coleridge-packages/seqeval-1.2.2-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from seqeval==1.2.2) (1.19.5)\r\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.7/site-packages (from seqeval==1.2.2) (0.24.1)\r\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (1.5.4)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (1.0.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (2.1.0)\r\n",
      "Installing collected packages: seqeval\r\n",
      "Successfully installed seqeval-1.2.2\r\n",
      "Processing /kaggle/input/coleridge-packages/tokenizers-0.10.1-cp37-cp37m-manylinux1_x86_64.whl\r\n",
      "Installing collected packages: tokenizers\r\n",
      "  Attempting uninstall: tokenizers\r\n",
      "    Found existing installation: tokenizers 0.10.2\r\n",
      "    Uninstalling tokenizers-0.10.2:\r\n",
      "      Successfully uninstalled tokenizers-0.10.2\r\n",
      "Successfully installed tokenizers-0.10.1\r\n",
      "Processing /kaggle/input/coleridge-packages/transformers-4.5.0.dev0-py3-none-any.whl\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (3.0.12)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (20.9)\r\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (0.0.45)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (3.4.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (2.25.1)\r\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (0.10.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (2021.3.17)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (4.49.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (1.19.5)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers==4.5.0.dev0) (3.7.4.3)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers==4.5.0.dev0) (3.4.1)\r\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers==4.5.0.dev0) (2.4.7)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.5.0.dev0) (2020.12.5)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.5.0.dev0) (4.0.0)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.5.0.dev0) (2.10)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.5.0.dev0) (1.26.4)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.5.0.dev0) (1.0.1)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.5.0.dev0) (7.1.2)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.5.0.dev0) (1.15.0)\r\n",
      "Installing collected packages: transformers\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.5.1\r\n",
      "    Uninstalling transformers-4.5.1:\r\n",
      "      Successfully uninstalled transformers-4.5.1\r\n",
      "Successfully installed transformers-4.5.0.dev0\r\n"
     ]
    }
   ],
   "source": [
    "! pip install /kaggle/input/nlp-packages/datasets/datasets/fsspec-2021.4.0-py3-none-any.whl\n",
    "! pip install datasets --no-index --find-links=file:///kaggle/input/coleridge-packages/packages/datasets\n",
    "! pip install ../input/coleridge-packages/seqeval-1.2.2-py3-none-any.whl\n",
    "! pip install ../input/coleridge-packages/tokenizers-0.10.1-cp37-cp37m-manylinux1_x86_64.whl\n",
    "! pip install ../input/coleridge-packages/transformers-4.5.0.dev0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-compilation",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import os, shutil, time\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "from functools import partial\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tokenizers.pre_tokenizers import BertPreTokenizer\n",
    "import transformers, seqeval\n",
    "from transformers import AutoTokenizer, DataCollatorForTokenClassification\n",
    "from transformers import AutoModelForTokenClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import load_dataset, ClassLabel, load_metric\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-milwaukee",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-christianity",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "Path.ls = lambda pth: list(pth.iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-funds",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-cannon",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def load_train_meta(pth, group_id=True):\n",
    "    df = pd.read_csv(pth)\n",
    "    if group_id:\n",
    "        df = df.groupby('Id').agg({'pub_title': 'first', \n",
    "                                   'dataset_title': '|'.join, \n",
    "                                   'dataset_label': '|'.join, \n",
    "                                   'cleaned_label': '|'.join}).reset_index()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-graph",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14316 19661\n",
      "['Baltimore Longitudinal Study of Aging (BLSA)|Baltimore Longitudinal Study of Aging'\n",
      " 'Beginning Postsecondary Students Longitudinal Study|Education Longitudinal Study|Beginning Postsecondary Students'\n",
      " \"ADNI|Alzheimer's Disease Neuroimaging Initiative (ADNI)\"\n",
      " \"ADNI|Alzheimer's Disease Neuroimaging Initiative (ADNI)\"\n",
      " \"ADNI|Alzheimer's Disease Neuroimaging Initiative (ADNI)\"\n",
      " \"ADNI|Alzheimer's Disease Neuroimaging Initiative (ADNI)\"\n",
      " \"ADNI|Alzheimer's Disease Neuroimaging Initiative (ADNI)\"\n",
      " 'Baltimore Longitudinal Study of Aging (BLSA)|Baltimore Longitudinal Study of Aging'\n",
      " \"ADNI|Alzheimer's Disease Neuroimaging Initiative (ADNI)\"\n",
      " 'Beginning Postsecondary Student|Beginning Postsecondary Students']\n"
     ]
    }
   ],
   "source": [
    "pth = Path('/kaggle/input/coleridgeinitiative-show-us-the-data/train.csv')\n",
    "df = load_train_meta(pth, group_id=True)\n",
    "df_nogroup = load_train_meta(pth, group_id=False)\n",
    "print(len(df), len(df_nogroup))\n",
    "dup_ids = df_nogroup[df_nogroup.Id.duplicated()].Id.unique()\n",
    "print(df[df.Id.isin(dup_ids)].dataset_label.values[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-password",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def load_papers(dir_json, paper_ids):\n",
    "    '''\n",
    "    Load papers into a dictionary.\n",
    "    \n",
    "    `papers`: \n",
    "        {''}\n",
    "    '''\n",
    "    \n",
    "    papers = {}\n",
    "    for paper_id in paper_ids:\n",
    "        with open(f'{dir_json}/{paper_id}.json', 'r') as f:\n",
    "            paper = json.load(f)\n",
    "            papers[paper_id] = paper\n",
    "    return papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-giving",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'section_title': 'Materials and methods', 'text': ''}\n"
     ]
    }
   ],
   "source": [
    "df = load_train_meta('/kaggle/input/coleridgeinitiative-show-us-the-data/train.csv', group_id=True).iloc[-10:]\n",
    "papers = load_papers('/kaggle/input/coleridgeinitiative-show-us-the-data/train/', df.Id)\n",
    "print(type(papers))\n",
    "print(\n",
    "    papers[ np.random.choice(df.Id.values) ][2]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-tampa",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-annual",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "# Special tokens\n",
    "AAAsTITLE = 'AAAsTITLE'  # Start of section title\n",
    "ZZZsTITLE = 'ZZZsTITLE'  # End of section title\n",
    "AAAsTEXT = 'AAAsTEXT'    # Start of section text\n",
    "ZZZsTEXT = 'ZZZsTEXT'    # End of section text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-cooperative",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def load_section(section, mark_title=False, mark_text=False):\n",
    "    '''\n",
    "    '''\n",
    "    title, text  = section['section_title'], section['text']\n",
    "    \n",
    "    out = ''\n",
    "    \n",
    "    if title:\n",
    "        if mark_title:\n",
    "            out = f\"{AAAsTITLE} {title} {ZZZsTITLE}\"\n",
    "        else:\n",
    "            out = title\n",
    "    \n",
    "    if text:\n",
    "        if mark_text:\n",
    "            out += f\"\\n\\n{AAAsTEXT} {text} {ZZZsTEXT}\"\n",
    "        else:\n",
    "            out += f\"\\n\\n{text}\"\n",
    "            \n",
    "    return out\n",
    "\n",
    "\n",
    "def load_paper(paper, mark_title=False, mark_text=False):\n",
    "    sections = (load_section(section, mark_title, mark_text) for section in paper)\n",
    "    return '\\n\\n'.join(sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-climate",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAAsTITLE Limitations ZZZsTITLE\n",
      "\n",
      "A limitation that arises with a longitudinal study is the loss of participants over time. The total sample of respondents was satisfactory but not optimal even though regular reminders were sent. The logistical and financial needs to track individuals over time was costly and time consuming. Thus the generalizability of this study could be hindered. However, the short period of recall of only 3-months would have reduced the effect of recall bias.\n",
      "\n",
      "==================================================\n",
      "Abstract\n",
      "\n",
      "AAAsTEXT The aim of this study was to identify if acquiring ICT skills through DOT Lebanon's ICT training program (a local NGO) improved income generation opportunities after 3-months of completing the training. The target population was the NGO's vulnerable young beneficiaries. This study was completed in an effort to find creative and digital solutions to the high rate of youth unemployment in Lebanon (37%), one of the highest rates in the world. Results showed that 48% of beneficiaries who were unemployed at baseline, were exposed to at least one income generation opportunity 3 months after completing the DOT Lebanon training. Also, 49% of beneficiaries who were already employed at baseline were exposed to at least one income generation opportunity. Gender, English proficiency and governorate were variables that were found to be statistically significant. Males were more likely than females to be exposed to income generation opportunities. Those who knew little English had better chances than those who had no English proficiency. Beneficiaries living in the capital Beirut were more likely than others to be exposed to income generation opportunities. ZZZsTEXT\n",
      "\n",
      "Introduction\n",
      "\n",
      "AAAsTEXT The spur of ICT (Information and Communication Technologies) innovations in the twenty-first century has massively disrupted economies and business models (Christensen, 2013; Tohmatsu, 2012) . Millions of jobs face a high probability of being replaced because computers and the internet are reshaping the labor market (Oliver, 2015) . In the framework of globalization, digital skills are now considered preliminary for securing professional employment across the globe (Pirzada & Khan, 2013) . Consequently, many employers across a wide range of sectors are increasingly viewing ICT skills as an important component of employability (Belt & Richardson, 2005; Johnson & Burden, 2003) . The omnipresence of computing has made digital literacy increasingly critical to success in any occu\n"
     ]
    }
   ],
   "source": [
    "df = load_train_meta('/kaggle/input/coleridgeinitiative-show-us-the-data/train.csv', group_id=True).iloc[:10]\n",
    "papers = load_papers('/kaggle/input/coleridgeinitiative-show-us-the-data/train', df.Id)\n",
    "\n",
    "idx_paper, idx_section = 0, 11\n",
    "paper   = papers[df.Id.iloc[idx_paper]]\n",
    "section = paper[idx_section]\n",
    "\n",
    "print(load_section(section, mark_title=True, mark_text=False), end='\\n\\n')\n",
    "print(50 * '=')\n",
    "print(load_paper(paper, mark_title=False, mark_text=True)[:2_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-alexandria",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def text2words(text, pretokenizer=BertPreTokenizer()):\n",
    "    '''\n",
    "    Pre-tokenizes a piece of text.  BertPreTokenizer tokenizes by space and \n",
    "    punctuation.\n",
    "    '''\n",
    "    tokenized_text = pretokenizer.pre_tokenize_str(text)\n",
    "    if tokenized_text:\n",
    "        tokenized_text, _ = zip(*tokenized_text)\n",
    "    return list(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-integer",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A long diag is caught on chest and burst by Kuzaev, but the ball runs away from him before he can cross. \n",
      "That was good football though, and I really like the way Russia are approaching this game.\n",
      "\n",
      "['A', 'long', 'diag', 'is', 'caught', 'on', 'chest', 'and', 'burst', 'by', 'Kuzaev', ',', 'but', 'the', 'ball', 'runs', 'away', 'from', 'him', 'before', 'he', 'can', 'cross', '.', 'That', 'was', 'good', 'football', 'though', ',', 'and', 'I', 'really', 'like', 'the', 'way', 'Russia', 'are', 'approaching', 'this', 'game', '.']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "text = '''A long diag is caught on chest and burst by Kuzaev, but the ball runs away from him before he can cross. \n",
    "That was good football though, and I really like the way Russia are approaching this game.\n",
    "'''\n",
    "print(text)\n",
    "\n",
    "pretokenizer = BertPreTokenizer()\n",
    "print(text2words(text, pretokenizer=pretokenizer))\n",
    "\n",
    "print(text2words(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-needle",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def clean_training_text(txt, lower=False, total_clean=False):\n",
    "    \"\"\"\n",
    "    Competition's evaluation: `lower=True` and `total_clean=False`.\n",
    "    \"\"\"\n",
    "    txt = str(txt).lower() if lower else str(txt)\n",
    "    txt = re.sub('[^A-Za-z0-9]+', ' ', txt).strip()\n",
    "    if total_clean:\n",
    "        txt = re.sub(' +', ' ', txt)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-college",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaggle This competition awards 90 000\n",
      "AASECTIONTITLE Abstract ZZSECTIONTITLE AASECTIONTEXT This paper is about datasets ZZSECTIONTEXT\n",
      "hopkld 7 11 002\n"
     ]
    }
   ],
   "source": [
    "print(clean_training_text('@kaggle This competition awards $90,000!!!!.'))\n",
    "print(clean_training_text('''AASECTIONTITLE Abstract ZZSECTIONTITLE \\n AASECTIONTEXT This paper is about datasets. ZZSECTIONTEXT'''))\n",
    "print(clean_training_text('HoPKLd + 7 !  11,002', total_clean=True, lower=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-liberal",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def extract_sentences(paper, sentence_definition='sentence', \n",
    "                      mark_title=False, mark_text=False):\n",
    "    '''\n",
    "    Returns:\n",
    "        sentences (list): List of sentences.  Each sentence is a string.\n",
    "    '''\n",
    "    if sentence_definition == 'sentence':\n",
    "        sentences = [sentence for s in paper \n",
    "                     for sentence in s['text'].split('.') if s['text']]\n",
    "        \n",
    "    elif sentence_definition == 'section':\n",
    "        sentences = [load_section(s, mark_title=mark_title, mark_text=mark_text) \n",
    "                     for s in paper if s['section_title'] or s['text']]\n",
    "        \n",
    "    elif sentence_definition == 'paper':\n",
    "        sentences = [load_paper(paper, mark_title=mark_title, mark_text=mark_text)]\n",
    "        \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-strengthening",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAAsTITLE Abstract ZZZsTITLE\n",
      "\n",
      "Background and Purpose: Neuropsychiatric symptoms (NPS) are frequently encountered in patients with Alzheimer's disease (AD). Focal grey matter atrophy has been linked to NPS development. Cerebrovascular disease can cause focal lesions and is common among AD patients. As cerebrovascular disease can be detected on MRI as white matter hyperintensities (WMH), this study evaluated WMH burden in mild cognitive impairment (MCI), AD and normal controls and determined their relationship with NPS. Methods: NPS were assessed using the Neuropsychiatric Inventory and grouped into subsyndromes. WMH were measured using an automatic segmentation technique and mean deformation-based morphometry was used to measure atrophy of grey matter regions. Results: WMHs and grey matter atrophy both contributed significantly to NPS subsyndromes in MCI and AD subjects, however, WMH burden played a greater role. Conclusions: This study could provide a better understanding of the pathophysiology of NPS in AD.\n"
     ]
    }
   ],
   "source": [
    "df = load_train_meta('/kaggle/input/coleridgeinitiative-show-us-the-data/train.csv', group_id=True).iloc[100:110]\n",
    "papers = load_papers('/kaggle/input/coleridgeinitiative-show-us-the-data/train', df.Id)\n",
    "\n",
    "idx = 6\n",
    "\n",
    "paper = papers[df.Id.iloc[idx]]\n",
    "sentences = extract_sentences(paper, sentence_definition='section', mark_title=True, mark_text=False)\n",
    "\n",
    "print(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-plumbing",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def shorten_sentences(sentences, max_length=64, overlap=20):\n",
    "    '''\n",
    "    Args:\n",
    "        sentences (list): List of sentences. Each sentence is list of words.\n",
    "        max_length (int): Maximum number of words allowed for each sentence.\n",
    "        overlap (int): If a sentence exceeds `max_length`, we split it to multiple sentences with \n",
    "            this amount of overlapping.\n",
    "    '''\n",
    "    \n",
    "    short_sentences = []\n",
    "    for sentence in sentences:\n",
    "        if len(sentence) > max_length:\n",
    "            for p in range(0, len(sentence), max_length - overlap):\n",
    "                short_sentences.append(sentence[p:p+max_length])\n",
    "        else:\n",
    "            short_sentences.append(sentence)\n",
    "    return short_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-bouquet",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['AAAsTITLE', 'EURO2020', 'ZZZsTITLE', 'AAAsTEXT', 'When', 'Patrik', 'Schick', 'planted', 'his', 'header', 'beyond', 'David', 'Marshall', ',', 'the', 'place', 'fell', 'silent', 'for', 'the', 'first', 'time', '.', 'When', 'Schick', \"'\", 's', 'utterly', 'majestic', 'second', 'soared', 'over', 'the', 'goalkeeper', ',', 'frustration', 'turned', 'to', 'exasperation', 'and', ',', 'eventually', ',', 'resignation', '.', 'ZZZsTEXT'], ['The', 'day', 'began', 'with', 'a', 'feverish', 'excitement', '.', 'Cans', 'of', 'lager', 'were', 'consumed', 'at', 'breakfast', ';', 'establishments', 'rammed', 'by', 'noon', '.', 'Schoolchildren', 'were', 'given', 'a', 'break', 'to', 'watch', 'the', 'game', '.', 'Glasgow', 'hummed', 'and', 'buzzed', 'in', 'a', 'way', 'it', 'has', 'not', 'done', 'for', 'years', '.'], []]\n",
      "\n",
      "[['AAAsTITLE', 'EURO2020', 'ZZZsTITLE', 'AAAsTEXT', 'When', 'Patrik', 'Schick', 'planted', 'his', 'header'], ['his', 'header', 'beyond', 'David', 'Marshall', ',', 'the', 'place', 'fell', 'silent'], ['fell', 'silent', 'for', 'the', 'first', 'time', '.', 'When', 'Schick', \"'\"], ['Schick', \"'\", 's', 'utterly', 'majestic', 'second', 'soared', 'over', 'the', 'goalkeeper'], ['the', 'goalkeeper', ',', 'frustration', 'turned', 'to', 'exasperation', 'and', ',', 'eventually'], [',', 'eventually', ',', 'resignation', '.', 'ZZZsTEXT'], ['The', 'day', 'began', 'with', 'a', 'feverish', 'excitement', '.', 'Cans', 'of'], ['Cans', 'of', 'lager', 'were', 'consumed', 'at', 'breakfast', ';', 'establishments', 'rammed'], ['establishments', 'rammed', 'by', 'noon', '.', 'Schoolchildren', 'were', 'given', 'a', 'break'], ['a', 'break', 'to', 'watch', 'the', 'game', '.', 'Glasgow', 'hummed', 'and'], ['hummed', 'and', 'buzzed', 'in', 'a', 'way', 'it', 'has', 'not', 'done'], ['not', 'done', 'for', 'years', '.'], []]\n",
      "CPU times: user 647 µs, sys: 0 ns, total: 647 µs\n",
      "Wall time: 576 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sentences = [\n",
    "    f'''\n",
    "    {AAAsTITLE} EURO2020 {ZZZsTITLE}\n",
    "\n",
    "    {AAAsTEXT} When Patrik Schick planted his header beyond David Marshall, the place fell silent for the first time.\n",
    "    When Schick's utterly majestic second soared over the goalkeeper, \n",
    "    frustration turned to exasperation and, eventually, resignation. {ZZZsTEXT}\n",
    "    ''',\n",
    "    '''\n",
    "    The day began with a feverish excitement. \n",
    "    Cans of lager were consumed at breakfast; establishments rammed by noon. \n",
    "    Schoolchildren were given a break to watch the game. Glasgow hummed and buzzed in a way it has not done for years.\n",
    "    ''', \n",
    "    \"\"]\n",
    "\n",
    "pretokenizer = BertPreTokenizer()\n",
    "sentences = [text2words(s, pretokenizer=pretokenizer) for s in sentences]\n",
    "\n",
    "print(sentences)\n",
    "print()\n",
    "print(shorten_sentences(sentences, max_length=10, overlap=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-contribution",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def find_sublist(big_list, small_list):\n",
    "    all_positions = []\n",
    "    for i in range(len(big_list) - len(small_list) + 1):\n",
    "        if small_list == big_list[i:i+len(small_list)]:\n",
    "            all_positions.append(i)\n",
    "    \n",
    "    return all_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-cosmetic",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 15]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_list = ['If', 'the', 'thing', 'above', 'is', 'below', 'that', 'thing', 'which', 'is',\n",
    "            'not', 'as', 'high', 'up', 'on', 'the', 'thing', 'above', 'when', 'it', 'is', \n",
    "            'underneath', 'them.']\n",
    "small_list = ['the', 'thing', 'above']\n",
    "\n",
    "find_sublist(big_list, small_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-today",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Named Entity Recognition Data\n",
    "Or, Token Classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-designer",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def get_ner_classlabel():\n",
    "    '''\n",
    "    Labels for named entity recognition.\n",
    "        'O': Token not part of a phrase that mentions a dataset.\n",
    "        'I': Intermediate token of a phrase mentioning a dataset.\n",
    "        'B': First token of a phrase mentioning a dataset.\n",
    "    '''\n",
    "    return ClassLabel(names=['O', 'I', 'B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-wound",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassLabel(num_classes=3, names=['O', 'I', 'B'], names_file=None, id=None)\n",
      "[1, 0, 2] 1\n",
      "B ['B', 'I', 'O']\n"
     ]
    }
   ],
   "source": [
    "classlabel = get_ner_classlabel()\n",
    "print(classlabel)\n",
    "print(classlabel.str2int(['I', 'O', 'B']), classlabel.str2int('I'))\n",
    "print(classlabel.int2str(2), classlabel.int2str([2, 1, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-exclusion",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export    \n",
    "\n",
    "def tag_sentence(sentence, labels, classlabel=None): \n",
    "    '''\n",
    "    Args:\n",
    "        sentence (list): List of words.\n",
    "        labels (list): List of dataset labels.\n",
    "    '''\n",
    "    if (labels is not None and\n",
    "        any(' '.join(label) in ' '.join(sentence) for label in labels)):\n",
    "        \n",
    "        nes = [classlabel.str2int('O')] * len(sentence)\n",
    "        for label in labels:\n",
    "            all_pos = find_sublist(sentence, label)\n",
    "            for pos in all_pos:\n",
    "                nes[pos] = classlabel.str2int('B')\n",
    "                for i in range(pos+1, pos+len(label)):\n",
    "                    nes[i] = classlabel.str2int('I')\n",
    "\n",
    "        return True, list(zip(sentence, nes))\n",
    "        \n",
    "    else: \n",
    "        nes = [classlabel.str2int('O')] * len(sentence)\n",
    "        return False, list(zip(sentence, nes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-homeless",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A label is found in the sentence: True\n",
      "(token, tag) pairs:\n",
      "[('AAAsTEXT', 0), ('The', 2), ('International', 1), ('Standard', 0), ('Classification', 0), ('of', 0), ('Education', 0), (',', 0), ('known', 0), ('by', 0), ('its', 0), ('acronym', 0), ('ISCED', 0), (',', 0), ('was', 0), ('developed', 0), ('by', 0), ('the', 0), ('United', 2), ('Nations', 1), ('Educational', 1), (',', 0), ('Scientific', 0), (',', 0), ('and', 0), ('Cultural', 2), ('Organization', 1), ('during', 0), ('the', 0), ('late', 0), ('1960s', 0), ('and', 0), ('1970s', 0), ('ZZZsTEXT', 0)]\n"
     ]
    }
   ],
   "source": [
    "sentence = f'''\n",
    "    {AAAsTEXT} The International Standard Classification of Education, known by its acronym ISCED, \n",
    "    was developed by the United Nations Educational, Scientific, \n",
    "    and Cultural Organization during the late 1960s and 1970s {ZZZsTEXT}\n",
    "    '''\n",
    "labels = ['The International', 'Cultural Organization', 'United Nations Educational']\n",
    "\n",
    "pretokenizer = BertPreTokenizer()\n",
    "sentence = text2words(sentence, pretokenizer)\n",
    "labels = [text2words(label, pretokenizer) for label in labels]\n",
    "\n",
    "classlabel = get_ner_classlabel()\n",
    "found_any, token_tags = tag_sentence(sentence, labels, classlabel=classlabel)\n",
    "\n",
    "print('A label is found in the sentence:', found_any)\n",
    "print('(token, tag) pairs:')\n",
    "print(token_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-surgery",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A label is found in the sentence: False\n",
      "(token, tag) pairs:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"\"\n",
    "labels = ['The International', 'Cultural Organization', 'United Nations Educational']\n",
    "\n",
    "pretokenizer = BertPreTokenizer()\n",
    "sentence = text2words(sentence, pretokenizer)\n",
    "labels = [text2words(label, pretokenizer) for label in labels]\n",
    "\n",
    "classlabel = get_ner_classlabel()\n",
    "found_any, token_tags = tag_sentence(sentence, labels, classlabel=classlabel)\n",
    "\n",
    "print('A label is found in the sentence:', found_any)\n",
    "print('(token, tag) pairs:')\n",
    "print(token_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-substance",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def get_paper_ner_data(paper, labels, mark_title=False, mark_text=False,\n",
    "                       pretokenizer=BertPreTokenizer(), classlabel=None,\n",
    "                       sentence_definition='sentence', max_length=64, overlap=20, \n",
    "                       neg_keywords=['data', 'study']):\n",
    "    '''\n",
    "    Get NER data for a single paper.\n",
    "    \n",
    "    Args:\n",
    "        paper (list): Each element is a dict of form {'section_title': \"...\", 'text': \"...\"}.\n",
    "        labels (list): Each element is a string that is a dataset label.\n",
    "        \n",
    "    Returns:\n",
    "        ner_data (list): Each element is a list of tuples of the form:\n",
    "            [('It', 0), ('is', 0), ..., ('ADNI', 2), ('Dataset', 1), ...]\n",
    "    '''\n",
    "    labels = [text2words(label, pretokenizer) for label in labels]\n",
    "\n",
    "    sentences = extract_sentences(paper, sentence_definition=sentence_definition, \n",
    "                                  mark_title=mark_title, mark_text=mark_text)\n",
    "    sentences = [text2words(s, pretokenizer) for s in sentences]\n",
    "    sentences = shorten_sentences(sentences, max_length=max_length, overlap=overlap) \n",
    "    sentences = [sentence for sentence in sentences if len(' '.join(sentence)) > 10] # only accept sentences with length > 10 chars\n",
    "\n",
    "    cnt_pos, cnt_neg, ner_data = 0, 0, []\n",
    "    for sentence in sentences:\n",
    "        is_positive, tags = tag_sentence(sentence, labels, classlabel=classlabel)\n",
    "        if is_positive:\n",
    "            cnt_pos += 1\n",
    "            ner_data.append(tags)\n",
    "        elif neg_keywords:\n",
    "            if any(keyword in ' '.join(word.lower() for word in sentence) for keyword in neg_keywords): \n",
    "                ner_data.append(tags)\n",
    "                cnt_neg += 1\n",
    "        else:\n",
    "            ner_data.append(tags)\n",
    "            cnt_neg += 1\n",
    "            \n",
    "    return cnt_pos, cnt_neg, ner_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-announcement",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ADNI', \"Alzheimer's Disease Neuroimaging Initiative (ADNI)\"]\n",
      "1 11\n",
      "[360, 360, 360, 360, 360, 360, 360, 360, 360, 360, 360, 162]\n",
      "[('AAAsTITLE', 0), ('Abstract', 0), ('ZZZsTITLE', 0), ('AAAsTEXT', 0), ('We', 0), ('present', 0), ('a', 0), ('new', 0), ('automated', 0), ('system', 0), ('for', 0), ('the', 0), ('detection', 0), ('of', 0), ('brain', 0), ('magnetic', 0), ('resonance', 0), ('images', 0), ('(', 0), ('MRI', 0), (')', 0), ('affected', 0), ('by', 0), ('Alzheimer', 0), (\"'\", 0), ('s', 0), ('disease', 0), ('(', 0), ('AD', 0), (')', 0), ('.', 0), ('The', 0), ('MRI', 0), ('is', 0), ('analyzed', 0), ('by', 0), ('means', 0), ('of', 0), ('multiscale', 0), ('analysis', 0), ('(', 0), ('MSA', 0), (')', 0), ('to', 0), ('obtain', 0), ('its', 0), ('fractals', 0), ('at', 0), ('six', 0), ('different', 0), ('scales', 0), ('.', 0), ('The', 0), ('extracted', 0), ('fractals', 0), ('are', 0), ('used', 0), ('as', 0), ('features', 0), ('to', 0), ('differentiate', 0), ('healthy', 0), ('brain', 0), ('MRI', 0), ('from', 0), ('those', 0), ('of', 0), ('AD', 0), ('by', 0), ('a', 0), ('support', 0), ('vector', 0), ('machine', 0), ('(', 0), ('SVM', 0), (')', 0), ('classifier', 0), ('.', 0), ('The', 0), ('result', 0), ('of', 0), ('classifying', 0), ('93', 0), ('brain', 0), ('MRIs', 0), ('consisting', 0), ('of', 0), ('51', 0), ('images', 0), ('of', 0), ('healthy', 0), ('brains', 0), ('and', 0), ('42', 0), ('of', 0), ('brains', 0), ('affected', 0), ('by', 0), ('AD', 0), (',', 0), ('using', 0), ('leave', 0), ('-', 0), ('one', 0), ('-', 0), ('out', 0), ('crossvalidation', 0), ('method', 0), (',', 0), ('yielded', 0), ('99', 0), ('.', 0), ('18', 0), ('%', 0), ('±', 0), ('0', 0), ('.', 0), ('01', 0), ('classification', 0), ('accuracy', 0), (',', 0), ('100', 0), ('%', 0), ('sensitivity', 0), (',', 0), ('and', 0), ('98', 0), ('.', 0), ('20', 0), ('%', 0), ('±', 0), ('0', 0), ('.', 0), ('02', 0), ('specificity', 0), ('.', 0), ('These', 0), ('results', 0), ('and', 0), ('a', 0), ('processing', 0), ('time', 0), ('of', 0), ('5', 0), ('.', 0), ('64', 0), ('seconds', 0), ('indicate', 0), ('that', 0), ('the', 0), ('proposed', 0), ('approach', 0), ('may', 0), ('be', 0), ('an', 0), ('efficient', 0), ('diagnostic', 0), ('aid', 0), ('for', 0), ('radiologists', 0), ('in', 0), ('the', 0), ('screening', 0), ('for', 0), ('AD', 0), ('.', 0), ('ZZZsTEXT', 0), ('AAAsTITLE', 0), ('Introduction', 0), ('ZZZsTITLE', 0), ('AAAsTEXT', 0), ('Alzheimer', 0), (\"'\", 0), ('s', 0), ('disease', 0), ('(', 0), ('AD', 0), (')', 0), ('is', 0), ('a', 0), ('progressive', 0), ('and', 0), ('degenerative', 0), ('disease', 0), ('that', 0), ('affects', 0), ('brain', 0), ('cells', 0), (',', 0), ('and', 0), ('its', 0), ('early', 0), ('diagnosis', 0), ('has', 0), ('been', 0), ('essential', 0), ('for', 0), ('appropriate', 0), ('intervention', 0), ('by', 0), ('health', 0), ('professionals', 0), ('.', 0), ('Noninvasive', 0), ('in', 0), ('vivo', 0), ('neuroimaging', 0), ('techniques', 0), ('such', 0), ('as', 0), ('magnetic', 0), ('resonance', 0), ('imaging', 0), ('(', 0), ('MRI', 0), (')', 0), ('and', 0), ('positron', 0), ('emission', 0), ('tomography', 0), ('(', 0), ('PET', 0), (')', 0), ('are', 0), ('commonly', 0), ('used', 0), ('to', 0), ('diagnose', 0), ('and', 0), ('monitor', 0), ('the', 0), ('progression', 0), ('of', 0), ('the', 0), ('disease', 0), ('and', 0), ('the', 0), ('effect', 0), ('of', 0), ('treatment', 0), ('.', 0), ('In', 0), ('this', 0), ('regard', 0), (',', 0), ('the', 0), ('problem', 0), ('of', 0), ('developing', 0), ('computer', 0), ('aided', 0), ('diagnosis', 0), ('(', 0), ('CAD', 0), (')', 0), ('tools', 0), ('to', 0), ('distinguish', 0), ('images', 0), ('with', 0), ('AD', 0), ('from', 0), ('those', 0), ('of', 0), ('normal', 0), ('brains', 0), ('has', 0), ('been', 0), ('extensively', 0), ('addressed', 0), ('in', 0), ('the', 0), ('past', 0), ('years', 0), ('[', 0), ('1', 0), (']', 0), ('[', 0), ('2', 0), (']', 0), ('[', 0), ('3', 0), (']', 0), ('[', 0), ('4', 0), (']', 0), ('[', 0), ('5', 0), (']', 0), ('[', 0), ('6', 0), (']', 0), ('[', 0), ('7', 0), (']', 0), ('[', 0), ('8', 0), (']', 0), ('[', 0), ('9', 0), (']', 0), ('[', 0), ('10', 0), (']', 0), ('[', 0), ('11', 0), (']', 0), ('[', 0), ('12', 0), (']', 0), ('.', 0), ('A', 0), ('review', 0), ('of', 0), ('a', 0), ('recent', 0), ('work', 0), ('follows', 0), ('.', 0), ('Magnin', 0), ('et', 0), ('al', 0), ('.', 0), ('[', 0), ('1', 0), (']', 0), ('used', 0), ('the', 0), ('relative', 0), ('weight', 0), ('of', 0), ('gray', 0), ('matter', 0), ('versus', 0), ('white', 0), ('matter', 0), ('and', 0), ('cerebrospinal', 0), ('fluid', 0), ('in', 0), ('90', 0), ('regions', 0), ('of', 0), ('interests', 0), ('(', 0), ('ROI', 0), (')', 0), ('as', 0), ('features', 0), ('classified', 0), ('with', 0), ('SVM', 0), ('.', 0), ('Based', 0), ('on', 0), ('the', 0), ('bootstrap', 0), ('method', 0), (',', 0), ('the', 0)]\n"
     ]
    }
   ],
   "source": [
    "df = load_train_meta('/kaggle/input/coleridgeinitiative-show-us-the-data/train.csv', group_id=True).iloc[230:330]\n",
    "papers = load_papers('/kaggle/input/coleridgeinitiative-show-us-the-data/train/', df.Id)\n",
    "pretokenizer = BertPreTokenizer()\n",
    "classlabel = get_ner_classlabel()\n",
    "\n",
    "idx = 29\n",
    "paper = papers[df.Id.iloc[idx]]\n",
    "labels = df.dataset_label.iloc[idx].split('|')\n",
    "cnt_pos, cnt_neg, ner_data = get_paper_ner_data(paper, labels, mark_title=True, mark_text=True,\n",
    "                                                pretokenizer=pretokenizer, classlabel=classlabel,\n",
    "                                                sentence_definition='paper', max_length=360, overlap=20,\n",
    "                                                neg_keywords=None)\n",
    "print(labels)\n",
    "print(cnt_pos, cnt_neg)\n",
    "print([len(sample) for sample in ner_data])\n",
    "print(ner_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-uruguay",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def get_ner_data(papers, df=None, mark_title=False, mark_text=False,\n",
    "                 classlabel=None, pretokenizer=BertPreTokenizer(), \n",
    "                 sentence_definition='sentence', max_length=64, overlap=20, \n",
    "                 neg_keywords=['study', 'data'], shuffle=True):\n",
    "    '''\n",
    "    Get NER data for a list of papers.\n",
    "    \n",
    "    Args:\n",
    "        papers (dict): Like that returned by `load_papers`.\n",
    "        df (pd.DataFrame): Competition's train.csv or a subset of it.\n",
    "    Returns:\n",
    "        cnt_pos (int): Number of samples (or 'sentences') that are tagged or partly\n",
    "            tagged as datasets.\n",
    "        cnt_neg (int): Number of samples (or 'sentences') that are not tagged\n",
    "            or partly tagged as datasets.\n",
    "        ner_data (list): List of samples, or 'sentences'. Each element is of the form:\n",
    "            [('There', 0), ('has', 0), ('been', 0), ...]\n",
    "    '''\n",
    "    cnt_pos, cnt_neg = 0, 0 \n",
    "    ner_data = []\n",
    "\n",
    "    tqdm._instances.clear()\n",
    "    pbar = tqdm(total=len(df))\n",
    "    for i, id, dataset_label in df[['Id', 'dataset_label']].itertuples():\n",
    "        paper = papers[id]\n",
    "        labels = dataset_label.split('|')\n",
    "                \n",
    "        cnt_pos_, cnt_neg_, ner_data_ = get_paper_ner_data(\n",
    "            paper, labels, mark_title=mark_title, mark_text=mark_text,\n",
    "            classlabel=classlabel, pretokenizer=pretokenizer,\n",
    "            sentence_definition=sentence_definition, max_length=max_length, overlap=overlap, \n",
    "            neg_keywords=neg_keywords)\n",
    "        cnt_pos += cnt_pos_\n",
    "        cnt_neg += cnt_neg_\n",
    "        ner_data.extend(ner_data_)\n",
    "\n",
    "        pbar.update(1)\n",
    "        pbar.set_description(f\"Training data size: {cnt_pos} positives + {cnt_neg} negatives\")\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(ner_data)\n",
    "    return cnt_pos, cnt_neg, ner_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-fighter",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training data size: 26 positives + 141 negatives: 100%|██████████| 10/10 [00:00<00:00, 76.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postive count: 26.   Negative count: 141\n",
      "[('a', 0), ('standardized', 0), ('measure', 0), ('to', 0), ('facilitate', 0), ('comparisons', 0), ('across', 0), ('studies', 0), ('and', 0), ('outcomes', 0), ('.', 0), ('Eligibility', 0), ('A', 0), ('study', 0), ('is', 0), ('eligible', 0), ('for', 0), ('review', 0), ('if', 0), ('it', 0), ('falls', 0), ('within', 0), ('the', 0), ('scope', 0), ('of', 0), ('the', 0), ('review', 0), ('protocol', 0), ('and', 0), ('uses', 0), ('either', 0), ('an', 0), ('experimental', 0), ('or', 0), ('matched', 0), ('comparison', 0), ('group', 0), ('design', 0), ('.', 0), ('Equivalence', 0), ('A', 0), ('demonstration', 0), ('that', 0), ('the', 0), ('analysis', 0), ('sample', 0), ('groups', 0), ('are', 0), ('similar', 0), ('on', 0), ('observed', 0), ('characteristics', 0), ('defined', 0), ('in', 0), ('the', 0), ('review', 0), ('area', 0), ('protocol', 0), ('.', 0), ('Improvement', 0), ('index', 0), ('Along', 0), ('a', 0), ('percentile', 0), ('distribution', 0), ('of', 0), ('students', 0), (',', 0), ('the', 0), ('improvement', 0), ('index', 0), ('represents', 0), ('the', 0), ('gain', 0), ('or', 0), ('loss', 0), ('of', 0), ('the', 0), ('average', 0), ('student', 0), ('due', 0), ('to', 0), ('the', 0), ('intervention', 0), ('.', 0), ('As', 0), ('the', 0), ('average', 0), ('student', 0), ('starts', 0), ('at', 0), ('the', 0), ('50th', 0), ('percentile', 0), (',', 0), ('the', 0), ('measure', 0), ('ranges', 0), ('from', 0), ('-', 0), ('50', 0), ('to', 0), ('+', 0), ('50', 0), ('.', 0), ('ZZZsTEXT', 0), ('AAAsTITLE', 0), ('Multiple', 0), ('comparison', 0), ('adjustment', 0), ('ZZZsTITLE', 0), ('AAAsTEXT', 0), ('When', 0), ('a', 0), ('study', 0), ('includes', 0), ('multiple', 0), ('outcomes', 0), ('or', 0), ('comparison', 0), ('groups', 0), (',', 0), ('the', 0), ('WWC', 0), ('will', 0), ('adjust', 0), ('the', 0), ('statistical', 0), ('significance', 0), ('to', 0), ('account', 0), ('for', 0), ('the', 0), ('multiple', 0), ('comparisons', 0), (',', 0), ('if', 0), ('necessary', 0), ('.', 0), ('ZZZsTEXT', 0), ('AAAsTITLE', 0), ('Quasi', 0), ('-', 0), ('experimental', 0), ('design', 0), ('(', 0), ('QED', 0), (')', 0), ('ZZZsTITLE', 0), ('AAAsTEXT', 0), ('A', 0), ('quasi', 0), ('-', 0), ('experimental', 0), ('design', 0), ('(', 0), ('QED', 0), (')', 0), ('is', 0), ('a', 0), ('research', 0), ('design', 0), ('in', 0), ('which', 0), ('subjects', 0), ('are', 0), ('assigned', 0), ('to', 0), ('intervention', 0), ('and', 0), ('comparison', 0), ('groups', 0), ('through', 0), ('a', 0), ('process', 0), ('that', 0), ('is', 0), ('not', 0), ('random', 0), ('.', 0), ('ZZZsTEXT', 0), ('AAAsTITLE', 0), ('Randomized', 0), ('controlled', 0), ('trial', 0), ('(', 0), ('RCT', 0), (')', 0), ('ZZZsTITLE', 0), ('AAAsTEXT', 0), ('A', 0), ('randomized', 0), ('controlled', 0), ('trial', 0), ('(', 0), ('RCT', 0), (')', 0), ('is', 0), ('an', 0), ('experiment', 0), ('in', 0), ('which', 0), ('investigators', 0), ('randomly', 0), ('assign', 0), ('eligible', 0), ('participants', 0), ('into', 0), ('intervention', 0), ('and', 0), ('comparison', 0), ('groups', 0), ('.', 0), ('ZZZsTEXT', 0), ('AAAsTITLE', 0), ('Single', 0), ('-', 0), ('case', 0), ('design', 0), ('(', 0), ('SCD', 0), (')', 0), ('ZZZsTITLE', 0), ('AAAsTEXT', 0), ('A', 0), ('research', 0), ('approach', 0), ('in', 0), ('which', 0), ('an', 0), ('outcome', 0), ('variable', 0), ('is', 0), ('measured', 0), ('repeatedly', 0), ('within', 0), ('and', 0), ('across', 0), ('different', 0), ('conditions', 0), ('that', 0), ('are', 0), ('defined', 0), ('by', 0), ('the', 0), ('presence', 0), ('or', 0), ('absence', 0), ('of', 0), ('an', 0), ('intervention', 0), ('.', 0), ('ZZZsTEXT', 0), ('AAAsTITLE', 0), ('Standard', 0), ('deviation', 0), ('ZZZsTITLE', 0), ('AAAsTEXT', 0), ('The', 0), ('standard', 0), ('deviation', 0), ('of', 0), ('a', 0), ('measure', 0), ('shows', 0), ('how', 0), ('much', 0), ('variation', 0), ('exists', 0), ('across', 0), ('observations', 0), ('in', 0), ('the', 0), ('sample', 0), ('.', 0), ('A', 0), ('low', 0), ('standard', 0), ('deviation', 0), ('indicates', 0), ('that', 0), ('the', 0), ('observations', 0), ('in', 0), ('the', 0), ('sample', 0), ('tend', 0), ('to', 0), ('be', 0), ('very', 0), ('close', 0), ('to', 0), ('the', 0), ('mean', 0), (';', 0), ('a', 0), ('high', 0), ('standard', 0), ('deviation', 0), ('indicates', 0), ('that', 0), ('the', 0), ('observations', 0), ('in', 0), ('the', 0), ('sample', 0), ('are', 0), ('spread', 0), ('out', 0), ('over', 0)]\n",
      "CPU times: user 177 ms, sys: 13.4 ms, total: 190 ms\n",
      "Wall time: 222 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv('/kaggle/input/coleridgeinitiative-show-us-the-data/train.csv').iloc[:10]\n",
    "papers = load_papers('/kaggle/input/coleridgeinitiative-show-us-the-data/train/', df.Id)\n",
    "\n",
    "cnt_pos, cnt_neg, ner_data = get_ner_data(papers, df, mark_title=True, mark_text=True,\n",
    "                                          classlabel=get_ner_classlabel(), pretokenizer=BertPreTokenizer(),\n",
    "                                          sentence_definition='paper', max_length=310, overlap=20, \n",
    "                                          neg_keywords=None, shuffle=False)\n",
    "\n",
    "print(f'Postive count: {cnt_pos}.   Negative count: {cnt_neg}')\n",
    "print(ner_data[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-track",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def write_ner_json(ner_data, pth=Path('train_ner.json'), mode='w'):\n",
    "    '''\n",
    "    Save NER data to json file.\n",
    "    '''\n",
    "    with open(pth, mode=mode) as f:\n",
    "        for row in ner_data:\n",
    "            words, nes = list(zip(*row))\n",
    "            row_json = {'tokens' : words, 'ner_tags' : nes}\n",
    "            json.dump(row_json, f)\n",
    "            f.write('\\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-actor",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"tokens\": [\"There\", \"is\", \"no\", \"dataset\", \"here\"], \"ner_tags\": [0, 0, 0, 0, 0]}\r\n",
      "{\"tokens\": [\"Load\", \"the\", \"UN\", \"Trade\", \"Development\", \"into\", \"view\"], \"ner_tags\": [0, 0, 2, 1, 1, 0, 0]}\r\n"
     ]
    }
   ],
   "source": [
    "ner_data = [\n",
    "    [('There', 0), ('is', 0), ('no', 0), ('dataset', 0), ('here', 0)], \n",
    "    [('Load', 0), ('the', 0), ('UN', 2), ('Trade', 1), ('Development', 1), ('into', 0), ('view', 0)]\n",
    "]\n",
    "write_ner_json(ner_data, pth=Path('/kaggle/tmp_ner.json'))\n",
    "! cat /kaggle/tmp_ner.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-bottom",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def load_ner_datasets(data_files=None):\n",
    "    '''\n",
    "    Load NER data in json files to a `datasets` object.  In addition,\n",
    "    Append the NER ClassLabel for the `ner_tags` feature.\n",
    "    '''\n",
    "    datasets = load_dataset('json', data_files=data_files)\n",
    "    classlabel = get_ner_classlabel()\n",
    "    for split, dataset in datasets.items():\n",
    "        dataset.features['ner_tags'].feature = classlabel\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-worship",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/json/default-6eb4f2ce42a4fd8f/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fc75b4b97654c209249d8c537cd0d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ed9bcac8fc456199692c7cee746830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-6eb4f2ce42a4fd8f/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02. Subsequent calls will reuse this data.\n",
      "\n",
      "{'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'ner_tags': Sequence(feature=ClassLabel(num_classes=3, names=['O', 'I', 'B'], names_file=None, id=None), length=-1, id=None)}\n",
      "{'tokens': ['Load', 'the', 'UN', 'Trade', 'Development', 'into', 'view'], 'ner_tags': [0, 0, 2, 1, 1, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "datasets = load_ner_datasets(data_files={'train':'/kaggle/tmp_ner.json', 'valid':'/kaggle/tmp_ner.json'})\n",
    "print()\n",
    "print(datasets['valid'].features)\n",
    "print(datasets['train'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-greensboro",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def batched_write_ner_json(papers, df, pth=Path('train_ner.json'), batch_size=4_000, \n",
    "                           mark_title=False, mark_text=False,\n",
    "                           classlabel=get_ner_classlabel(), pretokenizer=BertPreTokenizer(),\n",
    "                           sentence_definition='sentence', max_length=64, overlap=20, \n",
    "                           neg_keywords=['study', 'data']):\n",
    "\n",
    "    for i in range(0, len(df), batch_size):\n",
    "        print(f'Batch {i // batch_size}...', end='')\n",
    "        t0 = time.time()\n",
    "        cnt_pos, cnt_neg, ner_data = get_ner_data(papers, df.iloc[i:i+batch_size], \n",
    "                                                  mark_title=mark_title, mark_text=mark_text,\n",
    "                                                  classlabel=classlabel, pretokenizer=pretokenizer,\n",
    "                                                  sentence_definition=sentence_definition, \n",
    "                                                  max_length=max_length, overlap=overlap, \n",
    "                                                  neg_keywords=neg_keywords)\n",
    "        write_ner_json(ner_data, pth=pth, mode='w' if i == 0 else 'a')\n",
    "        print(f'done in {(time.time() - t0) / 60} mins.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-parker",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training data size: 30 positives + 316 negatives:  13%|█▎        | 13/100 [00:00<00:01, 67.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training data size: 26 positives + 141 negatives: 100%|██████████| 10/10 [00:03<00:00,  2.51it/s]\n",
      "Training data size: 190 positives + 2579 negatives: 100%|██████████| 100/100 [00:01<00:00, 66.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.058188255627950033 mins.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4_000\n",
    "df = load_train_meta('/kaggle/input/coleridgeinitiative-show-us-the-data/train.csv', group_id=True).iloc[:100]\n",
    "papers = load_papers('/kaggle/input/coleridgeinitiative-show-us-the-data/train/', df.Id)\n",
    "\n",
    "batched_write_ner_json(papers, df, pth=Path('train_ner.json'), batch_size=batch_size, \n",
    "                       mark_title=True, mark_text=True,\n",
    "                       classlabel=get_ner_classlabel(), pretokenizer=BertPreTokenizer(),\n",
    "                       sentence_definition='section', max_length=360, overlap=20, neg_keywords=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-amendment",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.9M\ttrain_ner.json\r\n"
     ]
    }
   ],
   "source": [
    "! du -hs train_ner.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-liverpool",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/json/default-fb56182f16404797/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03120c28d2c0443eb285920a73cf72c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-fb56182f16404797/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02. Subsequent calls will reuse this data.\n",
      "{'tokens': ['with', 'them', 'before', 'the', 'data', 'can', 'be', 'released', ',', 'the', 'portal', 'points', 'them', 'to', 'the', 'resource', 'websites', 'in', 'case', 'they', 'want', 'to', 'access', 'the', 'data', '.', 'ZZZsTEXT'], 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "datasets = load_ner_datasets(data_files={'train':'train_ner.json'})\n",
    "print(datasets['train'][44])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-poison",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-franchise",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def create_tokenizer(model_checkpoint='distilbert-base-cased'):\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_checkpoint, \n",
    "        additional_special_tokens=[AAAsTITLE, ZZZsTITLE, AAAsTEXT, ZZZsTEXT])\n",
    "    \n",
    "    if model_checkpoint == 'roberta-base':\n",
    "        tokenizer.add_prefix_space = True\n",
    "    \n",
    "    assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)\n",
    "    \n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-penny",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5223ca08cff4bd98e7fad1aef4c4212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a924718b308437aafc682fe39b1e114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b196d52ddff4e1495561a8af6fee2d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "790f59c94d5d4936ae3b25c6ff8298d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355863.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [0, 50118, 50265, 43649, 1437, 50266, 50140, 50267, 1868, 9, 209, 893, 2152, 579, 2013, 17707, 1437, 50118, 3628, 11322, 11, 5, 28597, 7, 5, 1967, 4, 1437, 50268, 50118, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "{'input_ids': [0, 50265, 47638, 50266, 50267, 16991, 1116, 29902, 859, 7042, 30403, 3215, 29, 2013, 17707, 3628, 11322, 179, 627, 23411, 658, 560, 627, 90, 37535, 4, 50268, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "['<s>', 'Ċ', 'AAAsTITLE', 'ĠAbstract', 'Ġ', 'ZZZsTITLE', 'ĊĊ', 'AAAsTEXT', 'ĠBoth', 'Ġof', 'Ġthese', 'Ġteams', 'Ġsuffered', 'Ġs', 'art', 'orial', 'Ġ', 'Ċ', 'head', 'aches', 'Ġin', 'Ġthe', 'Ġbuildup', 'Ġto', 'Ġthe', 'Ġtournament', '.', 'Ġ', 'ZZZsTEXT', 'Ċ', '</s>']\n"
     ]
    }
   ],
   "source": [
    "text = '''\n",
    "AAAsTITLE Abstract ZZZsTITLE\n",
    "\n",
    "AAAsTEXT Both of these teams suffered sartorial \n",
    "headaches in the buildup to the tournament. ZZZsTEXT\n",
    "'''\n",
    "\n",
    "tokenizer = create_tokenizer(model_checkpoint='roberta-base')\n",
    "\n",
    "print(tokenizer(text))\n",
    "print(tokenizer(text.split(), is_split_into_words=True))\n",
    "print(tokenizer.convert_ids_to_tokens(tokenizer(text)['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-conservation",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training data size: 190 positives + 2579 negatives: 100%|██████████| 100/100 [00:13<00:00,  7.32it/s]\n",
      "Training data size: 230 positives + 1268 negatives: 100%|██████████| 100/100 [00:04<00:00, 20.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/json/default-b08de7591e8e0f2b/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13bc0bd410a44ed7a875eac072fba284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-b08de7591e8e0f2b/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f86babce410>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find a suitable original sample length, given a max model input length of 512\n",
    "\n",
    "max_input_length = 512\n",
    "max_length, overlap = 360, 20\n",
    "\n",
    "df = load_train_meta('/kaggle/input/coleridgeinitiative-show-us-the-data/train.csv', group_id=True)\n",
    "df = df.sample(100).reset_index(drop=True)\n",
    "papers = load_papers('/kaggle/input/coleridgeinitiative-show-us-the-data/train', df.Id)\n",
    "\n",
    "cnt_pos, cnt_neg, ner_data = get_ner_data(papers, df, mark_title=True, mark_text=True,\n",
    "                                          classlabel=get_ner_classlabel(), pretokenizer=BertPreTokenizer(), \n",
    "                                          sentence_definition='paper', max_length=max_length, overlap=overlap, \n",
    "                                          neg_keywords=['study', 'data'])\n",
    "write_ner_json(ner_data, pth='train_ner.json')\n",
    "\n",
    "datasets = load_ner_datasets(data_files={'train':'train_ner.json'})\n",
    "\n",
    "tokenizer = create_tokenizer(model_checkpoint='roberta-base')\n",
    "tokenized_input = tokenizer(datasets['train']['tokens'], truncation=False, is_split_into_words=True)\n",
    "\n",
    "original_sample_lengths = np.array([len(tokens) for tokens in datasets['train']['tokens']])\n",
    "tokenized_sample_lengths = np.array([len(input_ids) for input_ids in tokenized_input['input_ids']])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(original_sample_lengths, label='original lengths', linestyle='none', marker='o')\n",
    "ax.plot(tokenized_sample_lengths, label='tokenized lengths', linestyle='none', marker='x')\n",
    "ax.hlines(y=max_input_length, xmin=0, xmax=len(original_sample_lengths), color='red')\n",
    "ax.set_ylabel('length')\n",
    "ax.set_xlabel('sample index')\n",
    "ax.set_title('section lengths')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-small",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def tokenize_and_align_labels(examples, tokenizer=None, label_all_tokens=True):\n",
    "    '''\n",
    "    Adds a new field called 'labels' that are the NER tags to the tokenized input.\n",
    "    \n",
    "    Args:\n",
    "        tokenizer (transformers.AutoTokenizer): Tokenizer.\n",
    "        examples (datasets.arrow_dataset.Dataset): Dataset.\n",
    "        label_all_tokens (bool): If True, all sub-tokens are given the same tag as the \n",
    "            first sub-token, otherwise all but the first sub-token are given the tag\n",
    "            -100.\n",
    "    '''\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "    labels = []\n",
    "    word_ids_all = []\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "        word_ids_all.append(word_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    tokenized_inputs['word_ids'] = word_ids_all\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-working",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"tokens\": [\"There\", \"is\", \"no\", \"dataset\", \"here\"], \"ner_tags\": [0, 0, 0, 0, 0]}\r\n",
      "{\"tokens\": [\"Load\", \"the\", \"UN\", \"Trade\", \"Development\", \"into\", \"view\"], \"ner_tags\": [0, 0, 2, 1, 1, 0, 0]}\r\n",
      "Downloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/json/default-74665bfc7f072029/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ede2252a133443ddbcee7b98ba0e25f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9167e0e9cc18459fb38bec42068a3eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-74665bfc7f072029/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'input_ids': [[0, 970, 354, 2362, 36146, 281, 594, 10859, 2], [0, 47167, 627, 4154, 35996, 45297, 12473, 5877, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 0, 0, 0, 0, 0, 0, 0, -100], [-100, 0, 0, 2, 1, 1, 0, 0, -100]], 'word_ids': [[None, 0, 1, 2, 3, 3, 3, 4, None], [None, 0, 1, 2, 3, 4, 5, 6, None]]}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3faeb90480f4525a2a01054cdb7432c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78ecb02bbdbf4b3b90b0071a6a3c7c81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'input_ids': [[0, 970, 354, 2362, 36146, 281, 594, 10859, 2], [0, 47167, 627, 4154, 35996, 45297, 12473, 5877, 2]], 'labels': [[-100, 0, 0, 0, 0, 0, 0, 0, -100], [-100, 0, 0, 2, 1, 1, 0, 0, -100]], 'ner_tags': [[0, 0, 0, 0, 0], [0, 0, 2, 1, 1, 0, 0]], 'tokens': [['There', 'is', 'no', 'dataset', 'here'], ['Load', 'the', 'UN', 'Trade', 'Development', 'into', 'view']], 'word_ids': [[None, 0, 1, 2, 3, 3, 3, 4, None], [None, 0, 1, 2, 3, 4, 5, 6, None]]}\n",
      "{'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'ner_tags': Sequence(feature=ClassLabel(num_classes=3, names=['O', 'I', 'B'], names_file=None, id=None), length=-1, id=None), 'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'word_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}\n"
     ]
    }
   ],
   "source": [
    "ner_data = [\n",
    "    [('There', 0), ('is', 0), ('no', 0), ('dataset', 0), ('here', 0)], \n",
    "    [('Load', 0), ('the', 0), ('UN', 2), ('Trade', 1), ('Development', 1), ('into', 0), ('view', 0)]\n",
    "]\n",
    "\n",
    "write_ner_json(ner_data, pth=Path('/kaggle/tmp_ner.json'))\n",
    "! cat /kaggle/tmp_ner.json\n",
    "\n",
    "datasets = load_ner_datasets(data_files={'train':'/kaggle/tmp_ner.json', 'valid':'/kaggle/tmp_ner.json'})\n",
    "tokenizer = create_tokenizer(model_checkpoint='roberta-base')\n",
    "\n",
    "print()\n",
    "print(tokenize_and_align_labels(datasets['train'][:], tokenizer, label_all_tokens=True), end='\\n\\n')\n",
    "\n",
    "tokenized_datasets = datasets.map(\n",
    "    partial(tokenize_and_align_labels, tokenizer=tokenizer, label_all_tokens=True), batched=True)\n",
    "print(tokenized_datasets['valid'][:])\n",
    "print(tokenized_datasets['train'].features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-frontier",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save and load `datasets.dataset_dict.DatasetDict`\n",
    "tokenized_datasets.save_to_disk('testsave_datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-evening",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 970, 354, 2362, 36146, 281, 594, 10859, 2], [0, 47167, 627, 4154, 35996, 45297, 12473, 5877, 2]]\n",
      "[[0, 970, 354, 2362, 36146, 281, 594, 10859, 2], [0, 47167, 627, 4154, 35996, 45297, 12473, 5877, 2]]\n"
     ]
    }
   ],
   "source": [
    "print(datasets.load_from_disk('testsave_datasets')['train']['input_ids'])\n",
    "print(tokenized_datasets['train']['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-dynamics",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def remove_nonoriginal_outputs(outputs, word_ids):\n",
    "    '''\n",
    "    Remove elements that correspond to special tokens or subtokens,\n",
    "    retaining only those elements that correspond to a word in original\n",
    "    text.\n",
    "    \n",
    "    Args:\n",
    "        outputs (np.array): Each row are the label ids for the subtokens of\n",
    "            a sample, with -100 indicating ignored subtokens, special tokens,\n",
    "            or padding. \n",
    "        word_ids (list): Each element is a list of word ids which indicate the word\n",
    "            that each subtoken belongs to. Each element corresponds to each row in `outputs`,\n",
    "            though it could be shorter, since it's not padded like in `outputs`.\n",
    "        \n",
    "    Returns:\n",
    "        outputs (list): Each element is a list of label ids for the \n",
    "            words in an sample. \n",
    "    '''\n",
    "    assert len(outputs) == len(word_ids)\n",
    "    idxs = [[word_id.index(i) for i in set(word_id) if i is not None] \n",
    "            for word_id in word_ids]\n",
    "    outputs = [output[idx].tolist() for output, idx in zip(outputs, idxs)]\n",
    "    for output in outputs:\n",
    "        assert -100 not in output\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-thanks",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions\n",
      "BEFORE:\n",
      "[[2 1 0 1 0 1 1 0]\n",
      " [1 2 2 1 1 1 1 0]]\n",
      "AFTER:\n",
      "[[1, 1, 0], [2, 2, 1]]\n",
      "============================================================\n",
      "label_ids\n",
      "BEFORE:\n",
      "[[-100    0    0    2    1    2    1 -100]\n",
      " [-100    2    1 -100    0 -100 -100 -100]]\n",
      "AFTER:\n",
      "[[0, 2, 1], [2, 1, 0]]\n"
     ]
    }
   ],
   "source": [
    "classlabel = get_ner_classlabel()\n",
    "\n",
    "predictions = np.random.randn(2, 8, classlabel.num_classes)\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "label_ids = np.array([[-100, 0, 0,    2, 1,    2,    1, -100],\n",
    "                      [-100, 2, 1, -100, 0, -100, -100, -100]])\n",
    "\n",
    "word_ids = [[None, 0, 0, 1, 2, None],\n",
    "            [None, 0, 1, 1, 2, 2, None]]\n",
    "\n",
    "true_predictions = remove_nonoriginal_outputs(predictions, word_ids)\n",
    "true_label_ids   = remove_nonoriginal_outputs(label_ids,   word_ids)\n",
    "\n",
    "print('predictions')\n",
    "print('BEFORE:')\n",
    "print(predictions)\n",
    "print('AFTER:')\n",
    "print(true_predictions)\n",
    "print(60 * '=')\n",
    "print('label_ids')\n",
    "print('BEFORE:')\n",
    "print(label_ids)\n",
    "print('AFTER:')\n",
    "print(true_label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-saint",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-discussion",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def jaccard_similarity(s1, s2):\n",
    "    l1 = set(s1.split(\" \"))\n",
    "    l2 = set(s2.split(\" \"))\n",
    "    intersection = len(list(l1.intersection(l2)))\n",
    "    union = (len(l1) + len(l2)) - intersection\n",
    "    return float(intersection) / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-uganda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard_similarity('USGS Frog Counts Data', 'USGA Croc Counts Data') == 1 / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-plate",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "792d1d0dedcc4041bb78070cdc783c73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1961.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'_': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1}, 'overall_precision': 1.0, 'overall_recall': 1.0, 'overall_f1': 1.0, 'overall_accuracy': 1.0}\n",
      "{'_': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1}, 'overall_precision': 0.0, 'overall_recall': 0.0, 'overall_f1': 0.0, 'overall_accuracy': 0.16666666666666666}\n"
     ]
    }
   ],
   "source": [
    "metric = load_metric('seqeval')\n",
    "\n",
    "predictions = np.array([['O', 'O', 'B', 'I', 'I', 'O']])\n",
    "references = [['O', 'O', 'B', 'I', 'I', 'O']]\n",
    "print(metric.compute(predictions=predictions, references=references))\n",
    "\n",
    "predictions = [['O', 'O', 'B', 'I', 'I', 'O']]\n",
    "references = [['B', 'I', 'I', 'O', 'O', 'O']]\n",
    "print(metric.compute(predictions=predictions, references=references))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-calibration",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def compute_metrics(p, metric=None, word_ids=None, label_list=None):\n",
    "    '''\n",
    "    1. Remove predicted and ground-truth class ids of special and sub tokens.\n",
    "    2. Convert class ids to class labels. (int ---> str)\n",
    "    3. Compute metric.\n",
    "    \n",
    "    Args:\n",
    "        p (tuple): 2-tuple consisting of model prediction and ground-truth\n",
    "            labels.  These will contain elements corresponding to special \n",
    "            tokens and sub-tokens.\n",
    "        word_ids (list): Word IDs from the tokenizer's output, indicating\n",
    "            which original word each sub-token belongs to.\n",
    "    '''\n",
    "    predictions, label_ids = p\n",
    "    predictions = predictions.argmax(axis=2)\n",
    "\n",
    "    true_predictions = remove_nonoriginal_outputs(predictions, word_ids)\n",
    "    true_label_ids = remove_nonoriginal_outputs(label_ids, word_ids)\n",
    "    \n",
    "    true_predictions = [[label_list[p] for p in pred] for pred in true_predictions]\n",
    "    true_labels = [[label_list[i] for i in label_id] for label_id in true_label_ids]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-detroit",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 0 0]\n",
      " [1 1 1 2 2 1]]\n",
      "[[0 2 1 0 2 0]\n",
      " [0 2 2 1 1 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'accuracy': 0.0}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "max_example_length = 6\n",
    "\n",
    "predictions = np.random.randn(batch_size, max_example_length, classlabel.num_classes)\n",
    "label_ids = np.random.randint(low=0, high=classlabel.num_classes, \n",
    "                              size=(batch_size, max_example_length), dtype=np.int16)\n",
    "word_ids = [[None, 0, 0, 1, 2, None], \n",
    "            [None, 0, 1, None]]\n",
    "\n",
    "print(predictions.argmax(axis=2))\n",
    "print(label_ids)\n",
    "p = (predictions, label_ids)\n",
    "metric = load_metric('seqeval')\n",
    "compute_metrics(p, metric=metric, label_list=classlabel.names, word_ids=word_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-gateway",
   "metadata": {
    "tags": []
   },
   "source": [
    "# NER training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-example",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training data size: 1 positives + 24 negatives: 100%|██████████| 1/1 [00:00<00:00, 50.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train.  Positive count: 3.  Negative count: 62.\n",
      "Valid.  Positive count: 1.  Negative count: 24.\n",
      "Downloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/json/default-3ac5d3c26614f16f/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e758ba9336b4802bee7ea85594d0981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30985f5932ee4de0be3d9751eb4a5b31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-3ac5d3c26614f16f/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943e544fdeb04ef0bbea2b2a6814b82b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3a3f36cf2ef47bcaa143c286b689c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_meta = load_train_meta('/kaggle/input/coleridgeinitiative-show-us-the-data/train.csv').iloc[:3]\n",
    "papers = load_papers('/kaggle/input/coleridgeinitiative-show-us-the-data/train', train_meta.Id)\n",
    "\n",
    "valid_cutoff = int(.50 * len(train_meta))\n",
    "valid_meta = train_meta.iloc[:valid_cutoff].reset_index(drop=True)\n",
    "train_meta = train_meta.iloc[valid_cutoff:].reset_index(drop=True)\n",
    "\n",
    "classlabel = get_ner_classlabel()\n",
    "pretokenizer = BertPreTokenizer()\n",
    "\n",
    "train_cnt_pos, train_cnt_neg, train_ner_data = get_ner_data(\n",
    "    papers, df=train_meta, mark_title=True, mark_text=True,\n",
    "    classlabel=classlabel, pretokenizer=pretokenizer,\n",
    "    sentence_definition='section', max_length=360, overlap=20, neg_keywords=None)\n",
    "\n",
    "valid_cnt_pos, valid_cnt_neg, valid_ner_data = get_ner_data(\n",
    "    papers, df=valid_meta, mark_title=True, mark_text=True,\n",
    "    classlabel=classlabel, pretokenizer=pretokenizer, \n",
    "    sentence_definition='section', max_length=360, overlap=20, neg_keywords=None)\n",
    "\n",
    "print(f'Train.  Positive count: {train_cnt_pos}.  Negative count: {train_cnt_neg}.')\n",
    "print(f'Valid.  Positive count: {valid_cnt_pos}.  Negative count: {valid_cnt_neg}.')\n",
    "\n",
    "write_ner_json(train_ner_data, pth='train_ner.json')\n",
    "write_ner_json(valid_ner_data, pth='valid_ner.json')\n",
    "datasets = load_ner_datasets(data_files={'train':'train_ner.json', 'valid':'valid_ner.json'})\n",
    "\n",
    "model_checkpoint = 'roberta-base' \n",
    "tokenizer = create_tokenizer(model_checkpoint)\n",
    "tokenized_datasets = datasets.map(\n",
    "    partial(tokenize_and_align_labels, tokenizer=tokenizer, label_all_tokens=True), batched=True)\n",
    "\n",
    "tokenized_datasets.save_to_disk(f'datasetdict_{model_checkpoint}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-rental",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c52eb04fe3c34026996577877df1f21c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501200538.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForTokenClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Training data size: 230 positives + 1268 negatives: 100%|██████████| 100/100 [01:28<00:00,  1.13it/s]\n",
      "Training data size: 3 positives + 62 negatives: 100%|██████████| 2/2 [01:04<00:00, 32.03s/it]\n",
      "Training data size: 1 positives + 24 negatives: 100%|██████████| 1/1 [01:03<00:00, 63.99s/it]\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint, bs = 'roberta-base', 10\n",
    "# model_checkpoint, bs = 'distilbert-base-cased', 20\n",
    "# model_checkpoint, bs = 'xlm-roberta-base', 8\n",
    "\n",
    "tokenizer = create_tokenizer(model_checkpoint)\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=classlabel.num_classes)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "metric = load_metric('seqeval')\n",
    "\n",
    "tokenized_datasets = datasets.load_from_disk(f'datasetdict_{model_checkpoint}')\n",
    "word_ids = tokenized_datasets['valid']['word_ids']\n",
    "compute_metrics_ = partial(compute_metrics, metric=metric, label_list=classlabel.names, word_ids=word_ids)\n",
    "\n",
    "args = TrainingArguments(output_dir='test_training', num_train_epochs=2, \n",
    "                         learning_rate=2e-5, weight_decay=0.01,\n",
    "                         per_device_train_batch_size=bs, per_device_eval_batch_size=bs,\n",
    "                         evaluation_strategy='epoch', logging_steps=4, report_to='none', \n",
    "                         save_strategy='epoch', save_total_limit=6)\n",
    "\n",
    "trainer = Trainer(model=model, args=args, \n",
    "                  train_dataset=tokenized_datasets['train'], eval_dataset=tokenized_datasets['valid'], \n",
    "                  data_collator=data_collator, tokenizer=tokenizer, compute_metrics=compute_metrics_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-norway",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 29:36, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.637400</td>\n",
       "      <td>0.026127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.998334</td>\n",
       "      <td>97.967200</td>\n",
       "      <td>0.255000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>0.015419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.998334</td>\n",
       "      <td>96.254700</td>\n",
       "      <td>0.260000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=14, training_loss=0.2064669385020222, metrics={'train_runtime': 1898.7417, 'train_samples_per_second': 0.007, 'total_flos': 48424503348270.0, 'epoch': 2.0, 'init_mem_cpu_alloc_delta': 208896, 'init_mem_cpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 3181748224, 'train_mem_cpu_peaked_delta': 9574674432})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consistent-elephant",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8\r\n",
      "drwxr-xr-x 2 root root 4096 Jun 19 05:07 checkpoint-7\r\n",
      "drwxr-xr-x 2 root root 4096 Jun 19 05:23 checkpoint-14\r\n"
     ]
    }
   ],
   "source": [
    "! ls -lrt test_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-collector",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 13:46, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.014544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.998334</td>\n",
       "      <td>96.765800</td>\n",
       "      <td>0.258000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=21, training_loss=0.00444827051389785, metrics={'train_runtime': 964.2287, 'train_samples_per_second': 0.022, 'total_flos': 72701886742380.0, 'epoch': 3.0, 'init_mem_cpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 3388325888, 'train_mem_cpu_peaked_delta': 7161012224})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bs = 4 # xlm-roberta-base on CPU\n",
    "bs = 10 # distilbert-base-cased on CPU\n",
    "\n",
    "args = TrainingArguments(output_dir='test_training', num_train_epochs=3, \n",
    "                         learning_rate=2e-5, weight_decay=0.01,\n",
    "                         per_device_train_batch_size=bs, per_device_eval_batch_size=bs,\n",
    "                         evaluation_strategy='epoch', logging_steps=4, report_to='none', \n",
    "                         save_strategy='epoch', save_total_limit=6)\n",
    "\n",
    "trainer = Trainer(model=model, args=args, \n",
    "                  train_dataset=tokenized_datasets['train'], eval_dataset=tokenized_datasets['valid'], \n",
    "                  data_collator=data_collator, tokenizer=tokenizer, \n",
    "                  compute_metrics=compute_metrics_)\n",
    "trainer.train(resume_from_checkpoint='/kaggle/working/test_training/checkpoint-14/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-refund",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:58]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.014544151723384857,\n",
       " 'eval_precision': 0.0,\n",
       " 'eval_recall': 0.0,\n",
       " 'eval_f1': 0.0,\n",
       " 'eval_accuracy': 0.9983340274885465,\n",
       " 'eval_runtime': 96.5636,\n",
       " 'eval_samples_per_second': 0.259,\n",
       " 'epoch': 3.0,\n",
       " 'eval_mem_cpu_alloc_delta': 49152,\n",
       " 'eval_mem_cpu_peaked_delta': 0}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honest-latvia",
   "metadata": {
    "tags": []
   },
   "source": [
    "## NER inference\n",
    "\n",
    "**Turn off the Internet here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-baghdad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def get_ner_inference_data(papers, sample_submission, \n",
    "                           mark_title=False, mark_text=False,\n",
    "                           pretokenizer=BertPreTokenizer(), classlabel=get_ner_classlabel(), \n",
    "                           sentence_definition='sentence', max_length=64, overlap=20, \n",
    "                           min_length=10, contains_keywords=['data', 'study']):\n",
    "    '''\n",
    "    Args:\n",
    "        papers (dict): Each list in this dictionary consists of the section of a paper.\n",
    "        sample_submission (pd.DataFrame): Competition 'sample_submission.csv'.\n",
    "        max_length (int): Maximum number of words allowed in a sentence.\n",
    "        min_length (int): Mininum number of characters required in a sentence.\n",
    "        \n",
    "    Returns:\n",
    "        test_rows (list): Each list in this list is of the form: \n",
    "             [('goat', 0), ('win', 0), ...] and represents a sentence.  \n",
    "        paper_length (list): Number of sentences in each paper.\n",
    "    '''\n",
    "    test_rows = [] \n",
    "    paper_length = [] \n",
    "\n",
    "    for paper_id in sample_submission['Id']:\n",
    "        paper = papers[paper_id]\n",
    "\n",
    "        sentences = extract_sentences(paper, sentence_definition, mark_title, mark_text)\n",
    "        sentences = [text2words(s, pretokenizer=pretokenizer) for s in sentences]\n",
    "        sentences = shorten_sentences(sentences, max_length=max_length, overlap=overlap) \n",
    "        \n",
    "        if min_length > 0:\n",
    "            sentences = [\n",
    "                sentence for sentence in sentences if len(' '.join(sentence)) > min_length] \n",
    "            \n",
    "        if contains_keywords is not None:\n",
    "            sentences = [\n",
    "                sentence for sentence in sentences \n",
    "                if any(kw in ' '.join(word.lower() for word in sentence) for kw in contains_keywords)]\n",
    "\n",
    "        for sentence in sentences:\n",
    "            dummy_tags = [classlabel.str2int('O')]*len(sentence)\n",
    "            test_rows.append(list(zip(sentence, dummy_tags)))\n",
    "\n",
    "        paper_length.append(len(sentences))\n",
    "\n",
    "    print(f'total number of \"sentences\": {len(test_rows)}')\n",
    "    return test_rows, paper_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-debate",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of \"sentences\": 106\n",
      "[('AAAsTITLE', 0), ('Abstract', 0), ('ZZZsTITLE', 0), ('AAAsTEXT', 0), ('Cognitive', 0), ('deficits', 0), ('and', 0), ('reduced', 0), ('educational', 0), ('achievement', 0), ('are', 0), ('common', 0), ('in', 0), ('psychiatric', 0), ('illness', 0), (';', 0), ('understanding', 0), ('the', 0), ('genetic', 0), ('basis', 0), ('of', 0), ('cognitive', 0), ('and', 0), ('educational', 0), ('deficits', 0), ('may', 0), ('be', 0), ('informative', 0), ('about', 0), ('the', 0), ('etiology', 0), ('of', 0), ('psychiatric', 0), ('disorders', 0), ('.', 0), ('A', 0), ('recent', 0), (',', 0), ('large', 0), ('genomewide', 0), ('association', 0), ('study', 0), ('(', 0), ('GWAS', 0), (')', 0), ('reported', 0), ('a', 0), ('genome', 0), ('-', 0), ('wide', 0), ('significant', 0), ('locus', 0), ('for', 0), ('years', 0), ('of', 0), ('education', 0), (',', 0), ('which', 0), ('subsequently', 0), ('demonstrated', 0), ('association', 0), ('to', 0), ('general', 0), ('cognitive', 0), ('ability', 0), ('(', 0), ('\"', 0), ('g', 0), ('\"', 0), (')', 0), ('in', 0), ('overlapping', 0), ('cohorts', 0), ('.', 0), ('The', 0), ('current', 0), ('study', 0), ('was', 0), ('designed', 0), ('to', 0), ('test', 0), ('whether', 0), ('GWAS', 0), ('hits', 0), ('for', 0), ('educational', 0), ('attainment', 0), ('are', 0), ('involved', 0), ('in', 0), ('general', 0), ('cognitive', 0), ('ability', 0), ('in', 0), ('an', 0), ('independent', 0), (',', 0), ('large', 0), ('-', 0), ('scale', 0), ('collection', 0), ('of', 0), ('cohorts', 0), ('.', 0), ('Using', 0), ('cohorts', 0), ('in', 0), ('the', 0), ('Cognitive', 0), ('Genomics', 0), ('Consortium', 0), ('(', 0), ('COGENT', 0), (';', 0), ('up', 0), ('to', 0), ('20', 0), (',', 0), ('495', 0), ('healthy', 0), ('individuals', 0), (')', 0), (',', 0), ('we', 0), ('examined', 0), ('the', 0), ('relationship', 0), ('between', 0), ('g', 0), ('and', 0), ('variants', 0), ('associated', 0), ('with', 0), ('educational', 0), ('attainment', 0), ('.', 0), ('We', 0), ('next', 0), ('conducted', 0), ('meta', 0), ('-', 0), ('analyses', 0), ('with', 0), ('24', 0), (',', 0), ('189', 0), ('individuals', 0), ('with', 0), ('neurocognitive', 0), ('data', 0), ('from', 0), ('the', 0), ('educational', 0), ('attainment', 0), ('studies', 0), (',', 0), ('and', 0), ('then', 0), ('with', 0), ('53', 0), (',', 0), ('188', 0), ('largely', 0), ('independent', 0), ('individuals', 0), ('from', 0), ('a', 0), ('recent', 0), ('GWAS', 0), ('of', 0), ('cognition', 0), ('.', 0), ('A', 0), ('SNP', 0), ('(', 0), ('rs1906252', 0), (')', 0), ('located', 0), ('at', 0), ('chromosome', 0), ('6q16', 0), ('.', 0), ('1', 0), (',', 0), ('previously', 0), ('associated', 0), ('with', 0), ('years', 0), ('of', 0), ('schooling', 0), (',', 0), ('was', 0), ('significantly', 0), ('associated', 0), ('with', 0), ('g', 0), ('(', 0), ('P', 0), ('=', 0), ('1', 0), ('.', 0), ('47×10', 0), ('−4', 0), (')', 0), ('in', 0), ('COGENT', 0), ('.', 0), ('The', 0), ('first', 0), ('joint', 0), ('analysis', 0), ('of', 0), ('43', 0), (',', 0), ('381', 0), ('non', 0), ('-', 0), ('overlapping', 0), ('individuals', 0), ('for', 0), ('this', 0), ('a', 0), ('priori', 0), ('-', 0), ('designated', 0), ('locus', 0), ('was', 0), ('strongly', 0), ('significant', 0), ('(', 0), ('P', 0), ('=', 0), ('4', 0), ('.', 0), ('94×10', 0), ('−7', 0), (')', 0), (',', 0), ('and', 0), ('the', 0), ('second', 0), ('joint', 0), ('analysis', 0), ('of', 0), ('68', 0), (',', 0), ('159', 0), ('non', 0), ('-', 0), ('overlapping', 0), ('individuals', 0), ('was', 0), ('even', 0), ('more', 0), ('robust', 0), ('(', 0), ('P', 0), ('=', 0), ('1', 0), ('.', 0), ('65×10', 0), ('−9', 0), (')', 0), ('.', 0), ('These', 0), ('results', 0), ('provide', 0), ('independent', 0), ('replication', 0), (',', 0), ('in', 0), ('a', 0), ('large', 0), ('-', 0), ('scale', 0), ('dataset', 0), (',', 0), ('of', 0), ('a', 0), ('genetic', 0), ('locus', 0), ('associated', 0), ('with', 0), ('cognitive', 0), ('function', 0), ('and', 0), ('education', 0), ('.', 0), ('As', 0), ('sample', 0), ('sizes', 0), ('grow', 0), (',', 0), ('cognitive', 0), ('GWAS', 0), ('will', 0), ('identify', 0), ('increasing', 0), ('numbers', 0), ('of', 0), ('associated', 0), ('loci', 0), (',', 0), ('as', 0), ('has', 0), ('been', 0), ('accomplished', 0), ('in', 0), ('other', 0), ('polygenic', 0), ('quantitative', 0), ('traits', 0), (',', 0), ('which', 0), ('may', 0), ('be', 0), ('relevant', 0), ('to', 0), ('psychiatric', 0), ('illness', 0), ('.', 0), ('ZZZsTEXT', 0), ('AAAsTITLE', 0), ('Introduction', 0), ('ZZZsTITLE', 0), ('AAAsTEXT', 0), ('A', 0), ('general', 0), ('cognitive', 0), ('ability', 0), ('factor', 0), ('(', 0), ('also', 0), ('termed', 0), ('g', 0), (')', 0), ('typically', 0), ('captures', 0), ('just', 0), ('under', 0), ('half', 0), ('of', 0), ('the', 0), ('overall', 0), ('variance', 0), ('in', 0), ('performance', 0), ('on', 0), ('diverse', 0), ('laboratory', 0), ('measures', 0), ('of', 0), ('neurocognitive', 0), ('functioning', 0), ('.', 0), ('General', 0), ('performance', 0), ('on', 0), ('neurocognitive', 0), ('tests', 0)]\n",
      "[8, 52, 22, 24]\n"
     ]
    }
   ],
   "source": [
    "sample_submission = pd.read_csv('/kaggle/input/coleridgeinitiative-show-us-the-data/sample_submission.csv')\n",
    "papers = load_papers('/kaggle/input/coleridgeinitiative-show-us-the-data/test', sample_submission.Id)\n",
    "\n",
    "classlabel = get_ner_classlabel()\n",
    "pretokenizer = BertPreTokenizer()\n",
    "test_rows, paper_length = get_ner_inference_data(papers, sample_submission, \n",
    "                                                 mark_title=True, mark_text=True,\n",
    "                                                 classlabel=classlabel, pretokenizer=pretokenizer,\n",
    "                                                 sentence_definition='paper', max_length=360, overlap=20,\n",
    "                                                 min_length=0, contains_keywords=['data'])\n",
    "print(test_rows[0])\n",
    "print(paper_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-postcard",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def ner_predict(pth=None, tokenizer=None, model=None, metric=None, \n",
    "                per_device_train_batch_size=16, per_device_eval_batch_size=16):\n",
    "    classlabel = get_ner_classlabel()\n",
    "    datasets = load_ner_datasets(data_files={'test':pth})\n",
    "\n",
    "    print('Tokenizing testset...', end='')\n",
    "    t0 = time.time()\n",
    "    tokenized_datasets = datasets.map(\n",
    "        partial(tokenize_and_align_labels, tokenizer=tokenizer, label_all_tokens=True), \n",
    "        batched=True)\n",
    "    print(f'completed in {(time.time() - t0) / 60:.2f} mins.')\n",
    "    \n",
    "    print('Creating data collator...')\n",
    "    data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "    \n",
    "    print('Creating (dummy) training arguments...')\n",
    "    args = TrainingArguments(output_dir='test_ner', num_train_epochs=3, \n",
    "                             learning_rate=2e-5, weight_decay=0.01,\n",
    "                             per_device_train_batch_size=per_device_train_batch_size, \n",
    "                             per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "                             evaluation_strategy='epoch', logging_steps=4, report_to='none', \n",
    "                             save_strategy='epoch', save_total_limit=6)\n",
    "\n",
    "    print('Creating trainer...')\n",
    "    word_ids = tokenized_datasets['test']['word_ids']\n",
    "    compute_metrics_ = partial(compute_metrics, metric=metric, label_list=classlabel.names, word_ids=word_ids)\n",
    "    trainer = Trainer(model=model, args=args, \n",
    "                      train_dataset=tokenized_datasets['test'], eval_dataset=tokenized_datasets['test'], \n",
    "                      data_collator=data_collator, tokenizer=tokenizer, compute_metrics=compute_metrics_)\n",
    "\n",
    "    print('Predicting on test samples...')\n",
    "    t0 = time.time()\n",
    "    predictions, label_ids, _ = trainer.predict(tokenized_datasets['test'])\n",
    "    print(f'completed in {(time.time() - t0) / 60:.2f} mins.')\n",
    "    print('Argmaxing...')\n",
    "    t0 = time.time()\n",
    "    predictions = predictions.argmax(axis=2)\n",
    "    print(f'completed in {(time.time() - t0) / 60:.2f} mins.')\n",
    "    \n",
    "    print('Removing non-original outputs...', end='')\n",
    "    t0 = time.time()\n",
    "    predictions = remove_nonoriginal_outputs(predictions, word_ids)\n",
    "    label_ids   = remove_nonoriginal_outputs(label_ids, word_ids)\n",
    "    print(f'completed in {(time.time() - t0) / 60:.2f} mins.')\n",
    "    \n",
    "    return predictions, label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-cover",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This shows where to look for the cached metric `seqeval`.\n",
    "# metric = load_metric('/root/.cache/huggingface/modules/datasets_modules/metrics/seqeval/ec5b7242a8c40468d189ca0b2b10612578dbcad311b2a134c99e3ded58a0d6e3/seqeval.py')\n",
    "\n",
    "# Exporting the cached metric \n",
    "\n",
    "# %cd /root/.cache\n",
    "# ! zip -r huggingface_cache.zip huggingface/modules/datasets_modules/metrics/seqeval/ec5b7242a8c40468d189ca0b2b10612578dbcad311b2a134c99e3ded58a0d6e3/\n",
    "# %cd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-deficit",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/json/default-d53c998af712123f/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd835fa97b3b4c2b94ba0ef6eb9b3211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-d53c998af712123f/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02. Subsequent calls will reuse this data.\n",
      "Tokenizing testset..."
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "You need to instantiate RobertaTokenizerFast with add_prefix_space=True to use it with pretokenized inputs.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-a76798a662d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m predictions, label_ids = ner_predict(pth='test_ner.json', tokenizer=tokenizer, model=model, metric=metric, \n\u001b[0;32m---> 15\u001b[0;31m                                      per_device_train_batch_size=4, per_device_eval_batch_size=4)\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-68e71d7aee6a>\u001b[0m in \u001b[0;36mner_predict\u001b[0;34m(pth, tokenizer, model, metric, per_device_train_batch_size, per_device_eval_batch_size)\u001b[0m\n\u001b[1;32m      9\u001b[0m     tokenized_datasets = datasets.map(\n\u001b[1;32m     10\u001b[0m         \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize_and_align_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_all_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         batched=True)\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'completed in {(time.time() - t0) / 60:.2f} mins.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/dataset_dict.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, input_columns, batched, batch_size, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mnum_proc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_proc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 )\n\u001b[0;32m--> 449\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m             }\n\u001b[1;32m    451\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/dataset_dict.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mnum_proc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_proc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 )\n\u001b[0;32m--> 449\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m             }\n\u001b[1;32m    451\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint)\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0mtest_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbatched\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mtest_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbatched\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mupdate_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoes_function_return_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing finished, running the mapping function on the dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mdoes_function_return_dict\u001b[0;34m(inputs, indices)\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0mfn_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minput_columns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m             processed_inputs = (\n\u001b[0;32m-> 1378\u001b[0;31m                 \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwith_indices\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1379\u001b[0m             )\n\u001b[1;32m   1380\u001b[0m             \u001b[0mdoes_return_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-998fe77b3c3d>\u001b[0m in \u001b[0;36mtokenize_and_align_labels\u001b[0;34m(examples, tokenizer, label_all_tokens)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;34m-\u001b[0m\u001b[0;36m100.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     '''\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtokenized_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_split_into_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mword_ids_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2264\u001b[0m                 \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2265\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2266\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2267\u001b[0m             )\n\u001b[1;32m   2268\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mbatch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2449\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2450\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2451\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2452\u001b[0m         )\n\u001b[1;32m   2453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/gpt2/tokenization_gpt2_fast.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mis_split_into_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"is_split_into_words\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         assert self.add_prefix_space or not is_split_into_words, (\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0;34mf\"You need to instantiate {self.__class__.__name__} with add_prefix_space=True \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m             \u001b[0;34m\"to use it with pretokenized inputs.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         )\n",
      "\u001b[0;31mAssertionError\u001b[0m: You need to instantiate RobertaTokenizerFast with add_prefix_space=True to use it with pretokenized inputs."
     ]
    }
   ],
   "source": [
    "samples = ['''Archaeologists estimate the carvings are between 4,000 and 5,000 years old''', \n",
    "           ('''I could see that I was looking at a deer stag upside down, '''\n",
    "            '''and as I continued looking around, more animals appeared on the rock,” he said.''')]\n",
    "\n",
    "samples = [text2words(sample, pretokenizer=BertPreTokenizer()) for sample in samples]\n",
    "test_rows = [list(zip(sample, len(sample) * [0])) for sample in samples]\n",
    "write_ner_json(test_rows, pth='test_ner.json')\n",
    "\n",
    "model_checkpoint = 'test_training/checkpoint-21/'\n",
    "tokenizer = create_tokenizer(model_checkpoint=model_checkpoint)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint)\n",
    "metric = load_metric('/root/.cache/huggingface/modules/datasets_modules/metrics/seqeval/ec5b7242a8c40468d189ca0b2b10612578dbcad311b2a134c99e3ded58a0d6e3/seqeval.py')\n",
    "\n",
    "predictions, label_ids = ner_predict(pth='test_ner.json', tokenizer=tokenizer, model=model, metric=metric, \n",
    "                                     per_device_train_batch_size=4, per_device_eval_batch_size=4)\n",
    "\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    print(f'Sample {i}:', len(predictions[i]), len(label_ids[i]), len(samples[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-trial",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def batched_ner_predict(pth, tokenizer=None, model=None, metric=None, \n",
    "                        batch_size=64_000, \n",
    "                        per_device_train_batch_size=16, per_device_eval_batch_size=16):\n",
    "    '''\n",
    "    Do inference on dataset in batches.\n",
    "    '''\n",
    "    lines = open(pth, mode='r').readlines()\n",
    "    \n",
    "    pth_tmp = 'ner_predict_tmp.json'\n",
    "    predictions, label_ids = [], []\n",
    "    for ib in range(0, len(lines), batch_size):\n",
    "        with open(pth_tmp, mode='w') as f:\n",
    "            f.writelines(lines[ ib: ib + batch_size ])\n",
    "\n",
    "        predictions_, label_ids_ = ner_predict(\n",
    "            pth_tmp, tokenizer=tokenizer, model=model, metric=metric, \n",
    "            per_device_train_batch_size=per_device_train_batch_size, \n",
    "            per_device_eval_batch_size=per_device_eval_batch_size)\n",
    "        predictions.extend(predictions_)\n",
    "        label_ids.extend(label_ids_)\n",
    "    return predictions, label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-september",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/json/default-2cb3b605ce2249d0/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "719d0cfc5a4a4308965f0666675707af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-2cb3b605ce2249d0/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02. Subsequent calls will reuse this data.\n",
      "Tokenizing testset..."
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "You need to instantiate RobertaTokenizerFast with add_prefix_space=True to use it with pretokenized inputs.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-48a5f48187df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m predictions, label_ids = batched_ner_predict(\n\u001b[1;32m     17\u001b[0m     \u001b[0;34m'test_ner.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     per_device_train_batch_size=16, per_device_eval_batch_size=16)\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-5d51d886d32d>\u001b[0m in \u001b[0;36mbatched_ner_predict\u001b[0;34m(pth, tokenizer, model, metric, batch_size, per_device_train_batch_size, per_device_eval_batch_size)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mpth_tmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mper_device_train_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mper_device_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             per_device_eval_batch_size=per_device_eval_batch_size)\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mlabel_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_ids_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-68e71d7aee6a>\u001b[0m in \u001b[0;36mner_predict\u001b[0;34m(pth, tokenizer, model, metric, per_device_train_batch_size, per_device_eval_batch_size)\u001b[0m\n\u001b[1;32m      9\u001b[0m     tokenized_datasets = datasets.map(\n\u001b[1;32m     10\u001b[0m         \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize_and_align_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_all_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         batched=True)\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'completed in {(time.time() - t0) / 60:.2f} mins.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/dataset_dict.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, input_columns, batched, batch_size, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mnum_proc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_proc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 )\n\u001b[0;32m--> 449\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m             }\n\u001b[1;32m    451\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/dataset_dict.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mnum_proc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_proc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 )\n\u001b[0;32m--> 449\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m             }\n\u001b[1;32m    451\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint)\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0mtest_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbatched\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mtest_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbatched\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mupdate_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoes_function_return_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing finished, running the mapping function on the dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mdoes_function_return_dict\u001b[0;34m(inputs, indices)\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0mfn_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minput_columns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m             processed_inputs = (\n\u001b[0;32m-> 1378\u001b[0;31m                 \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwith_indices\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1379\u001b[0m             )\n\u001b[1;32m   1380\u001b[0m             \u001b[0mdoes_return_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-998fe77b3c3d>\u001b[0m in \u001b[0;36mtokenize_and_align_labels\u001b[0;34m(examples, tokenizer, label_all_tokens)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;34m-\u001b[0m\u001b[0;36m100.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     '''\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtokenized_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_split_into_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mword_ids_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2264\u001b[0m                 \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2265\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2266\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2267\u001b[0m             )\n\u001b[1;32m   2268\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mbatch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2449\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2450\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2451\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2452\u001b[0m         )\n\u001b[1;32m   2453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/gpt2/tokenization_gpt2_fast.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mis_split_into_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"is_split_into_words\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         assert self.add_prefix_space or not is_split_into_words, (\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0;34mf\"You need to instantiate {self.__class__.__name__} with add_prefix_space=True \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m             \u001b[0;34m\"to use it with pretokenized inputs.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         )\n",
      "\u001b[0;31mAssertionError\u001b[0m: You need to instantiate RobertaTokenizerFast with add_prefix_space=True to use it with pretokenized inputs."
     ]
    }
   ],
   "source": [
    "samples = ['''Archaeologists estimate the carvings are between 4,000 and 5,000 years old''', \n",
    "           ('''I could see that I was looking at a deer stag upside down, '''\n",
    "            '''and as I continued looking around, more animals appeared on the rock,” he said.'''),\n",
    "           '''The RNN model we are about to build has LSTM cells as basic hidden units.''', \n",
    "           '''YouTube series, the Crooner Sessions. Now he gets his musical pals together in real life for ''']\n",
    "\n",
    "samples = [text2words(sample, pretokenizer=BertPreTokenizer()) for sample in samples]\n",
    "test_rows = [list(zip(sample, len(sample) * [0])) for sample in samples]\n",
    "write_ner_json(test_rows, pth='test_ner.json')\n",
    "\n",
    "model_checkpoint = 'test_training/checkpoint-21/'\n",
    "tokenizer = create_tokenizer(model_checkpoint=model_checkpoint)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint)\n",
    "metric = load_metric('/root/.cache/huggingface/modules/datasets_modules/metrics/seqeval/ec5b7242a8c40468d189ca0b2b10612578dbcad311b2a134c99e3ded58a0d6e3/seqeval.py')\n",
    "\n",
    "predictions, label_ids = batched_ner_predict(\n",
    "    'test_ner.json', tokenizer=tokenizer, model=model, metric=metric, batch_size=2, \n",
    "    per_device_train_batch_size=16, per_device_eval_batch_size=16)\n",
    "\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    print(f'Sample {i}:', len(predictions[i]), len(label_ids[i]), len(samples[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-letters",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def get_paper_dataset_labels(pth, paper_length, predictions):\n",
    "    '''\n",
    "    Args:\n",
    "        pth (Path, str): Path to json file containing NER data.  Each row is \n",
    "            of form: {'tokens': ['Studying', 'human'], 'ner_tags': [0, 0, ...]}.\n",
    "    \n",
    "    Returns:\n",
    "        paper_dataset_labels (list): Each element is a set consisting of labels predicted\n",
    "            by the model.\n",
    "    '''\n",
    "    test_sentences = [json.loads(sample)['tokens'] for sample in open(pth).readlines()]\n",
    "    \n",
    "    paper_dataset_labels = [] # store all dataset labels for each publication\n",
    "    for ipaper in range(len(paper_length)):\n",
    "        istart = sum(paper_length[:ipaper])\n",
    "        iend = istart + paper_length[ipaper]\n",
    "        \n",
    "        labels = set()\n",
    "        for sentence, pred in zip(test_sentences[istart:iend], predictions[istart:iend]):\n",
    "            curr_phrase = ''\n",
    "            for word, tag in zip(sentence, pred):\n",
    "                if tag == 'B': # start a new phrase\n",
    "                    if curr_phrase:\n",
    "                        labels.add(curr_phrase)\n",
    "                        curr_phrase = ''\n",
    "                    curr_phrase = word\n",
    "                elif tag == 'I' and curr_phrase: # continue the phrase\n",
    "                    curr_phrase += ' ' + word\n",
    "                else: # end last phrase (if any)\n",
    "                    if curr_phrase:\n",
    "                        labels.add(curr_phrase)\n",
    "                        curr_phrase = ''\n",
    "            # check if the label is the suffix of the sentence\n",
    "            if curr_phrase:\n",
    "                labels.add(curr_phrase)\n",
    "                curr_phrase = ''\n",
    "\n",
    "        # record dataset labels for this publication\n",
    "        paper_dataset_labels.append(labels)\n",
    "\n",
    "    return paper_dataset_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-globe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Tigers EcoNAX dataset', 'present all the'}, {'WGS Equality Definitiveness Dataset'}]\n"
     ]
    }
   ],
   "source": [
    "sentences = ['They do not present all the features', \n",
    "             'Despite the pretraining on the Tigers EcoNAX dataset',\n",
    "             'Weirdly there has been lots of studies based on WGS Equality Definitiveness Dataset']\n",
    "paper_length = [2, 1]\n",
    "test_rows = [[(word, 0) for word in sentence.split()] for sentence in sentences]\n",
    "predictions = [['O', 'O', 'O', 'B', 'I', 'I', 'O'],\n",
    "               ['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I'],\n",
    "               ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I']]\n",
    "for i, row in enumerate(test_rows):\n",
    "    assert len(row) == len(predictions[i])\n",
    "\n",
    "write_ner_json(test_rows, pth='test_ner.json')\n",
    "\n",
    "paper_dataset_labels = get_paper_dataset_labels('test_ner.json', paper_length, predictions)\n",
    "print(paper_dataset_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-hazard",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Literal matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-chemical",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def create_knowledge_bank(pth):\n",
    "    '''\n",
    "    Args:\n",
    "        pth (str): Path to meta data like 'train.csv', which\n",
    "        needs to have columns: 'dataset_title', 'dataset_label', and 'cleaned_label'.\n",
    "        \n",
    "    Returns:\n",
    "        all_labels (set): All possible strings associated with a dataset from the meta data.\n",
    "    '''\n",
    "    df = load_train_meta(pth, group_id=False)\n",
    "    all_labels = set()\n",
    "    for label_1, label_2, label_3 in df[['dataset_title', 'dataset_label', 'cleaned_label']].itertuples(index=False):\n",
    "        all_labels.add(str(label_1).lower())\n",
    "        all_labels.add(str(label_2).lower())\n",
    "        all_labels.add(str(label_3).lower())\n",
    "    return all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-applicant",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating knowledge bank...completed in 0.0909 s.\n",
      "180\n",
      "['2019 ncov complete genome sequences', '2019 ncov genome sequence', '2019 ncov genome sequences', '2019-ncov complete genome sequences', '2019-ncov genome sequence', '2019-ncov genome sequences', 'adni', 'advanced national seismic system (anss) comprehensive catalog (comcat)', 'advanced national seismic system anss comprehensive catalog comcat ', 'advanced national seismic system comprehensive catalog']\n"
     ]
    }
   ],
   "source": [
    "pth = Path('/kaggle/input/coleridgeinitiative-show-us-the-data/train.csv')\n",
    "\n",
    "print('Creating knowledge bank...', end='')\n",
    "t0 = time.time()\n",
    "knowledge_bank = create_knowledge_bank(pth)\n",
    "print(f'completed in {time.time() - t0:.4f} s.')\n",
    "\n",
    "print(len(knowledge_bank))\n",
    "print(sorted(knowledge_bank)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-index",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def literal_match(paper, all_labels):\n",
    "    '''\n",
    "    Args:\n",
    "        paper ()\n",
    "    '''\n",
    "    text_1 = '. '.join(section['text'] for section in paper).lower()\n",
    "    text_2 = clean_training_text(text_1, lower=True, total_clean=True)\n",
    "    \n",
    "    labels = set()\n",
    "    for label in all_labels:\n",
    "        if label in text_1 or label in text_2:\n",
    "            labels.add(clean_training_text(label, lower=True, total_clean=True))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-lighter",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'alzheimer s disease neuroimaging initiative adni', 'adni'}, {'trends in international mathematics and science study', 'common core of data', 'nces common core of data'}, {'sea lake and overland surges from hurricanes', 'noaa storm surge inundation', 'slosh model'}, {'rural urban continuum codes'}]\n"
     ]
    }
   ],
   "source": [
    "pth = Path('/kaggle/input/coleridgeinitiative-show-us-the-data/train.csv')\n",
    "knowledge_bank = create_knowledge_bank(pth)\n",
    "\n",
    "sample_submission = pd.read_csv('/kaggle/input/coleridgeinitiative-show-us-the-data/sample_submission.csv')\n",
    "papers = load_papers('/kaggle/input/coleridgeinitiative-show-us-the-data/test/', sample_submission.Id)\n",
    "\n",
    "literal_preds = [literal_match(papers[paper_id], knowledge_bank) for paper_id in sample_submission.Id]\n",
    "print(literal_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-domain",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Overall prediction for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-finder",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def combine_matching_and_model(literal_preds, paper_dataset_labels):\n",
    "    '''\n",
    "    Args:\n",
    "        literal_preds (list): Each element is a set, containing predicted labels for a paper\n",
    "            using literal matching.\n",
    "        paper_dataset_labels (list): Each element is a set, containing predicted labels for \n",
    "            a paper using trained model.\n",
    "    Returns:\n",
    "        filtered_dataset_labels (list): Each element is a string, containing \n",
    "            labels seperated by '|'.  \n",
    "            \n",
    "    Notes:\n",
    "        Combine literal matching predictions and model predictions. \n",
    "        Literal match predictions are appended IN FRONT of the model predictions,\n",
    "        because literal matches will be kept when removing labels that are too\n",
    "        similar to each other.\n",
    "    '''\n",
    "    all_labels = [list(literal_match) + list(model_pred) \n",
    "                  for literal_match, model_pred in zip(literal_preds, paper_dataset_labels)]\n",
    "    return all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-settle",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['mongolian racing cars', 'reallife headphones', 'dataset', 'data'],\n",
       " ['hifi dataset', 'headphones collection data'],\n",
       " ['rhs flowers fertiliser index',\n",
       "  'deep sea rock salts',\n",
       "  'rhs fertiliser index'],\n",
       " ['moma artists catalogue', 'housing market', 'moma artists']]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "literal_preds = [\n",
    "    {'mongolian racing cars', 'reallife headphones'}, \n",
    "    {},\n",
    "    {'rhs flowers fertiliser index'}, \n",
    "    {'moma artists catalogue'}]\n",
    "\n",
    "paper_dataset_labels = [\n",
    "    {'data', 'dataset'}, \n",
    "    {'hifi dataset', 'headphones collection data'}, \n",
    "    {'deep sea rock salts', 'rhs fertiliser index'}, \n",
    "    {'moma artists', 'housing market'}]\n",
    "\n",
    "combine_matching_and_model(literal_preds, paper_dataset_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-paintball",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def filter_dataset_labels(all_labels, max_similarity=0.75):\n",
    "    '''\n",
    "    When several labels for a paper are too similar, keep just one of them,\n",
    "    the one that appears FIRST.\n",
    "    \n",
    "    Args:\n",
    "        all_labels (list, set): Each element is a list of labels (str).\n",
    "        \n",
    "    Returns:\n",
    "        filtered_dataset_labels (list): Each element is a string, containing \n",
    "            labels seperated by '|'.\n",
    "    '''\n",
    "    filtered_dataset_labels = []\n",
    "\n",
    "    for labels in all_labels:\n",
    "        filtered = []\n",
    "\n",
    "        for label in labels:\n",
    "            label = clean_training_text(label, lower=True)\n",
    "            if len(filtered) == 0 or all(jaccard_similarity(label, got_label) < max_similarity \n",
    "                                         for got_label in filtered):\n",
    "                filtered.append(label)\n",
    "\n",
    "        filtered_dataset_labels.append('|'.join(filtered))\n",
    "    return filtered_dataset_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-council",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['moma artists catalogue|moma artists|housing market', 'rhs flowers fertiliser index|deep sea rock salts|rhs fertiliser index']\n",
      "\n",
      "['moma artists catalogue|moma artists|housing market', 'rhs flowers fertiliser index|deep sea rock salts']\n"
     ]
    }
   ],
   "source": [
    "all_labels = [\n",
    "    ['moma artists catalogue', 'moma artists', 'housing market'],\n",
    "    ['rhs flowers fertiliser index', 'deep sea rock salts', 'rhs fertiliser index']]\n",
    "print(filter_dataset_labels(all_labels, max_similarity=.9))\n",
    "\n",
    "print()\n",
    "\n",
    "all_labels = [\n",
    "    {'moma artists catalogue', 'moma artists', 'housing market'},\n",
    "    {'rhs flowers fertiliser index', 'deep sea rock salts', 'rhs fertiliser index'}]\n",
    "print(filter_dataset_labels(all_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-season",
   "metadata": {
    "tags": []
   },
   "source": [
    "Inference script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-status",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing NER inference data...\n",
      "total number of \"sentences\": 289\n",
      "Loading model, tokenizer, and metric...\n",
      "Predicting on each sentence...\n",
      "Downloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/json/default-bb25954f4e3f0e3e/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16cdf5ffd1c242a99173f9add98b371b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-bb25954f4e3f0e3e/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02. Subsequent calls will reuse this data.\n",
      "Tokenizing testset..."
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "You need to instantiate RobertaTokenizerFast with add_prefix_space=True to use it with pretokenized inputs.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-54658f11f2c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m predictions, label_ids = batched_ner_predict(\n\u001b[1;32m     23\u001b[0m     \u001b[0;34m'test_ner.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64_000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     per_device_train_batch_size=20, per_device_eval_batch_size=20)\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclasslabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint2str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mlabel_ids\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclasslabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint2str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabel_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-5d51d886d32d>\u001b[0m in \u001b[0;36mbatched_ner_predict\u001b[0;34m(pth, tokenizer, model, metric, batch_size, per_device_train_batch_size, per_device_eval_batch_size)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mpth_tmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mper_device_train_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mper_device_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             per_device_eval_batch_size=per_device_eval_batch_size)\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mlabel_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_ids_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-68e71d7aee6a>\u001b[0m in \u001b[0;36mner_predict\u001b[0;34m(pth, tokenizer, model, metric, per_device_train_batch_size, per_device_eval_batch_size)\u001b[0m\n\u001b[1;32m      9\u001b[0m     tokenized_datasets = datasets.map(\n\u001b[1;32m     10\u001b[0m         \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize_and_align_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_all_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         batched=True)\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'completed in {(time.time() - t0) / 60:.2f} mins.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/dataset_dict.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, input_columns, batched, batch_size, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mnum_proc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_proc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 )\n\u001b[0;32m--> 449\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m             }\n\u001b[1;32m    451\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/dataset_dict.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mnum_proc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_proc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 )\n\u001b[0;32m--> 449\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m             }\n\u001b[1;32m    451\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint)\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0mtest_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbatched\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mtest_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbatched\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mupdate_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoes_function_return_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing finished, running the mapping function on the dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mdoes_function_return_dict\u001b[0;34m(inputs, indices)\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0mfn_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minput_columns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m             processed_inputs = (\n\u001b[0;32m-> 1378\u001b[0;31m                 \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwith_indices\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1379\u001b[0m             )\n\u001b[1;32m   1380\u001b[0m             \u001b[0mdoes_return_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-998fe77b3c3d>\u001b[0m in \u001b[0;36mtokenize_and_align_labels\u001b[0;34m(examples, tokenizer, label_all_tokens)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;34m-\u001b[0m\u001b[0;36m100.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     '''\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtokenized_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_split_into_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mword_ids_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2264\u001b[0m                 \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2265\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2266\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2267\u001b[0m             )\n\u001b[1;32m   2268\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mbatch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2449\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2450\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2451\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2452\u001b[0m         )\n\u001b[1;32m   2453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/gpt2/tokenization_gpt2_fast.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mis_split_into_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"is_split_into_words\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         assert self.add_prefix_space or not is_split_into_words, (\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0;34mf\"You need to instantiate {self.__class__.__name__} with add_prefix_space=True \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m             \u001b[0;34m\"to use it with pretokenized inputs.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         )\n",
      "\u001b[0;31mAssertionError\u001b[0m: You need to instantiate RobertaTokenizerFast with add_prefix_space=True to use it with pretokenized inputs."
     ]
    }
   ],
   "source": [
    "! cp ../input/huggingface-cache/huggingface/modules/datasets_modules/metrics/seqeval/ec5b7242a8c40468d189ca0b2b10612578dbcad311b2a134c99e3ded58a0d6e3/seqeval.py .\n",
    "\n",
    "model_checkpoint = './test_training/checkpoint-21'\n",
    "\n",
    "print('Preparing NER inference data...')\n",
    "sample_submission = pd.read_csv('/kaggle/input/coleridgeinitiative-show-us-the-data/sample_submission.csv')\n",
    "papers = load_papers('/kaggle/input/coleridgeinitiative-show-us-the-data/test/', sample_submission.Id)\n",
    "classlabel = get_ner_classlabel()\n",
    "pretokenizer = BertPreTokenizer()\n",
    "test_rows, paper_length = get_ner_inference_data(papers, sample_submission, \n",
    "                                                 classlabel=classlabel, pretokenizer=pretokenizer,\n",
    "                                                 sentence_definition='section', max_length=300, overlap=20,\n",
    "                                                 min_length=0, contains_keywords=None)\n",
    "write_ner_json(test_rows, pth='test_ner.json')\n",
    "\n",
    "print('Loading model, tokenizer, and metric...')\n",
    "tokenizer = create_tokenizer(model_checkpoint=model_checkpoint)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint)\n",
    "metric = load_metric('seqeval.py')\n",
    "\n",
    "print('Predicting on each sentence...')\n",
    "predictions, label_ids = batched_ner_predict(\n",
    "    'test_ner.json', tokenizer=tokenizer, model=model, metric=metric, batch_size=64_000, \n",
    "    per_device_train_batch_size=20, per_device_eval_batch_size=20)\n",
    "predictions = [[classlabel.int2str(p) for p in pred] for pred in predictions]\n",
    "label_ids   = [[classlabel.int2str(l) for l in label] for label in label_ids]\n",
    "\n",
    "print('Getting predicted labels for each article...')\n",
    "paper_dataset_labels = get_paper_dataset_labels('test_ner.json', paper_length, predictions)\n",
    "\n",
    "print('String matching...')\n",
    "knowledge_bank = create_knowledge_bank('/kaggle/input/coleridgeinitiative-show-us-the-data/train.csv')\n",
    "literal_preds = []\n",
    "for paper_id in sample_submission.Id:\n",
    "    literal_preds.append(literal_match(papers[paper_id], knowledge_bank))\n",
    "\n",
    "print('Combining literal matches and model predictions...')\n",
    "all_labels = combine_matching_and_model(literal_preds, paper_dataset_labels)\n",
    "\n",
    "print('Keeping just one of labels that are too similar to each other...')\n",
    "filtered_dataset_labels = filter_dataset_labels(all_labels)\n",
    "\n",
    "sample_submission['PredictionString'] = filtered_dataset_labels\n",
    "\n",
    "sample_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-december",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: submission.csv: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "! cat submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becoming-relief",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-backup",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/json/default-8bf2ac7e4c4577b4/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8998b416cb84d5ab921d9800bbcaec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-8bf2ac7e4c4577b4/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02. Subsequent calls will reuse this data.\n",
      "Tokenizing testset..."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19b52b1dc8dc42f3aa904a9db7571aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "completed in 0.00 mins.\n",
      "Creating data collator...\n",
      "Creating (dummy) training arguments...\n",
      "Creating trainer...\n",
      "Predicting on test samples...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed in 0.58 mins.\n",
      "Argmaxing...\n",
      "completed in 0.00 mins.\n",
      "Removing non-original outputs...completed in 0.00 mins.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = '../input/showusdata-distilbert-base-cased-ner/training_results_distilbert-base-cased/checkpoint-56997'\n",
    "pth_valid_json = '../input/showus-data-ner-jsons/valid_ner.json'\n",
    "\n",
    "ner_data_valid = random.sample(open(pth_valid_json).readlines(), 20)\n",
    "ner_data_valid = [json.loads(sample) for sample in ner_data_valid]\n",
    "ner_data_valid = [list(zip(sample['tokens'], sample['ner_tags'])) for sample in ner_data_valid]\n",
    "write_ner_json(ner_data_valid, pth='valid_ner.json')\n",
    "\n",
    "tokenizer = create_tokenizer(model_checkpoint=model_checkpoint)\n",
    "classlabel = get_ner_classlabel()\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=classlabel.num_classes)\n",
    "metric = load_metric('seqeval')\n",
    "\n",
    "predictions, label_ids = ner_predict(pth='valid_ner.json', tokenizer=tokenizer, model=model, metric=metric, \n",
    "                                     per_device_train_batch_size=4, per_device_eval_batch_size=4)\n",
    "predictions = [[classlabel.int2str(p) for p in pred] for pred in predictions]\n",
    "label_ids   = [[classlabel.int2str(l) for l in label] for label in label_ids]\n",
    "\n",
    "paper_dataset_labels = get_paper_dataset_labels('valid_ner.json', len(predictions) * [1], predictions)\n",
    "gt_paper_dataset_labels = get_paper_dataset_labels('valid_ner.json', len(label_ids) * [1], label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-gambling",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ADNI'} {'ADNI'}\n",
      "{'ADNI'} {'ADNI'}\n"
     ]
    }
   ],
   "source": [
    "for predicted_labels, gt_labels in zip(paper_dataset_labels, gt_paper_dataset_labels):\n",
    "    if gt_labels:\n",
    "        print(predicted_labels, gt_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-contact",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
       " 'overall_precision': 1.0,\n",
       " 'overall_recall': 1.0,\n",
       " 'overall_f1': 1.0,\n",
       " 'overall_accuracy': 1.0}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.compute(predictions=predictions, references=label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-final",
   "metadata": {
    "tags": []
   },
   "source": [
    "# References\n",
    "- https://www.kaggle.com/tungmphung/pytorch-bert-for-named-entity-recognition/notebook\n",
    "- https://www.kaggle.com/tungmphung/coleridge-matching-bert-ner/notebook\n",
    "- https://github.com/huggingface/notebooks/blob/master/examples/token_classification.ipynb\n",
    "- https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin\n",
    "- https://huggingface.co/docs/datasets/loading_metrics.html\n",
    "- [Python strings and memory](https://rushter.com/blog/python-strings-and-memory/)\n",
    "- [Grandmaster Series – Building World-Class NLP Models with Transformers and Hugging Face](https://www.kaggle.com/c/commonlitreadabilityprize/discussion/245004)\n",
    "- https://huggingface.co/transformers/tokenizer_summary.html\n",
    "- https://discuss.huggingface.co/t/t5-seq2seq-custom-fine-tuning/1497/4\n",
    "- https://www.kaggle.com/c/google-quest-challenge/discussion/123770"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-utility",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
