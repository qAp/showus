{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# showus"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#default_exp showus"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Processing /kaggle/input/nlp-packages/datasets/datasets/fsspec-2021.4.0-py3-none-any.whl\nInstalling collected packages: fsspec\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 0.8.7\n    Uninstalling fsspec-0.8.7:\n      Successfully uninstalled fsspec-0.8.7\nSuccessfully installed fsspec-2021.4.0\nLooking in links: file:///kaggle/input/coleridge-packages/packages/datasets\nProcessing /kaggle/input/coleridge-packages/packages/datasets/datasets-1.5.0-py3-none-any.whl\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.19.5)\nProcessing /kaggle/input/coleridge-packages/packages/datasets/tqdm-4.49.0-py2.py3-none-any.whl\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.7/site-packages (from datasets) (2021.4.0)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.25.1)\nProcessing /kaggle/input/coleridge-packages/packages/datasets/xxhash-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (3.4.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.2.3)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.3)\nRequirement already satisfied: pyarrow>=0.17.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (3.0.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.11.1)\nProcessing /kaggle/input/coleridge-packages/packages/datasets/huggingface_hub-0.0.7-py3-none-any.whl\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2020.12.5)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.10)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (4.0.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.4)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.7.4.3)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.4.1)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.1)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2021.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\nInstalling collected packages: tqdm, xxhash, huggingface-hub, datasets\n  Attempting uninstall: tqdm\n    Found existing installation: tqdm 4.59.0\n    Uninstalling tqdm-4.59.0:\n      Successfully uninstalled tqdm-4.59.0\nSuccessfully installed datasets-1.5.0 huggingface-hub-0.0.7 tqdm-4.49.0 xxhash-2.0.0\nProcessing /kaggle/input/coleridge-packages/seqeval-1.2.2-py3-none-any.whl\nRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from seqeval==1.2.2) (1.19.5)\nRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.7/site-packages (from seqeval==1.2.2) (0.24.1)\nRequirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (1.5.4)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (1.0.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (2.1.0)\nInstalling collected packages: seqeval\nSuccessfully installed seqeval-1.2.2\nProcessing /kaggle/input/coleridge-packages/tokenizers-0.10.1-cp37-cp37m-manylinux1_x86_64.whl\nInstalling collected packages: tokenizers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.10.2\n    Uninstalling tokenizers-0.10.2:\n      Successfully uninstalled tokenizers-0.10.2\nSuccessfully installed tokenizers-0.10.1\nProcessing /kaggle/input/coleridge-packages/transformers-4.5.0.dev0-py3-none-any.whl\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (2021.3.17)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (1.19.5)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (4.49.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (3.4.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (20.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (3.0.12)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (0.0.45)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (2.25.1)\nRequirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (0.10.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers==4.5.0.dev0) (3.4.1)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers==4.5.0.dev0) (3.7.4.3)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers==4.5.0.dev0) (2.4.7)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.5.0.dev0) (2020.12.5)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.5.0.dev0) (4.0.0)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.5.0.dev0) (2.10)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.5.0.dev0) (1.26.4)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.5.0.dev0) (7.1.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.5.0.dev0) (1.15.0)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.5.0.dev0) (1.0.1)\nInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.5.1\n    Uninstalling transformers-4.5.1:\n      Successfully uninstalled transformers-4.5.1\nSuccessfully installed transformers-4.5.0.dev0\n"
    }
   ],
   "source": "! pip install /kaggle/input/nlp-packages/datasets/datasets/fsspec-2021.4.0-py3-none-any.whl\n! pip install datasets --no-index --find-links=file:///kaggle/input/coleridge-packages/packages/datasets\n! pip install ../input/coleridge-packages/seqeval-1.2.2-py3-none-any.whl\n! pip install ../input/coleridge-packages/tokenizers-0.10.1-cp37-cp37m-manylinux1_x86_64.whl\n! pip install ../input/coleridge-packages/transformers-4.5.0.dev0-py3-none-any.whl"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#export\nimport os, sys, shutil, time\nfrom tqdm import tqdm\nfrom pathlib import Path\nimport itertools\nfrom functools import partial\nimport re\nimport json\nimport random\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom tokenizers.pre_tokenizers import BertPreTokenizer\nfrom datasets import load_dataset, ClassLabel, load_metric\nimport transformers, seqeval\nfrom transformers import AutoTokenizer, DataCollatorForTokenClassification\nfrom transformers import AutoModelForTokenClassification\nfrom transformers import TrainingArguments, Trainer\n\nimport matplotlib.pyplot as plt\nfrom IPython.display import display"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Utilities"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#export\nPath.ls = lambda pth: list(pth.iterdir())"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Data I/O"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#export\ndef load_train_meta(pth, group_id=True):\n    '''\n    Load competition meta data.\n    \n    Args:\n        pth (str, Path): Path to the provided 'train.csv'.\n        group_id (bool): If True, gather all labels for each paper into\n            the same row in output dataframe.\n    \n    Returns:\n        df (pd.DataFrame): The meta data in competition 'train.csv'.  If\n            group_id is True, each paper has just one corresponding row.\n    '''\n    df = pd.read_csv(pth)\n    if group_id:\n        df = df.groupby('Id').agg({'pub_title': 'first', \n                                   'dataset_title': '|'.join, \n                                   'dataset_label': '|'.join, \n                                   'cleaned_label': '|'.join}).reset_index()\n    return df"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "14316 19661\n['Baltimore Longitudinal Study of Aging (BLSA)|Baltimore Longitudinal Study of Aging'\n 'Beginning Postsecondary Students Longitudinal Study|Education Longitudinal Study|Beginning Postsecondary Students'\n \"ADNI|Alzheimer's Disease Neuroimaging Initiative (ADNI)\"\n \"ADNI|Alzheimer's Disease Neuroimaging Initiative (ADNI)\"\n \"ADNI|Alzheimer's Disease Neuroimaging Initiative (ADNI)\"\n \"ADNI|Alzheimer's Disease Neuroimaging Initiative (ADNI)\"\n \"ADNI|Alzheimer's Disease Neuroimaging Initiative (ADNI)\"\n 'Baltimore Longitudinal Study of Aging (BLSA)|Baltimore Longitudinal Study of Aging'\n \"ADNI|Alzheimer's Disease Neuroimaging Initiative (ADNI)\"\n 'Beginning Postsecondary Student|Beginning Postsecondary Students']\n"
    }
   ],
   "source": "pth = Path('/kaggle/input/coleridgeinitiative-show-us-the-data/train.csv')\ndf = load_train_meta(pth, group_id=True)\ndf_nogroup = load_train_meta(pth, group_id=False)\nprint(len(df), len(df_nogroup))\ndup_ids = df_nogroup[df_nogroup.Id.duplicated()].Id.unique()\nprint(df[df.Id.isin(dup_ids)].dataset_label.values[-10:])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#export\ndef load_papers(dir_json, paper_ids):\n    '''\n    Load the papers provided.\n    \n    Args: \n        dir_json (str, Path): Path to the directory in which each\n            json file contains the text for a paper.\n        paper_ids (iter): IDs of the papers to load.\n        \n    Returns:\n        papers (dict): Each key is a paper ID.  Each value is a list\n            containing the sections in the paper.\n    '''\n    papers = {}\n    for paper_id in paper_ids:\n        with open(f'{dir_json}/{paper_id}.json', 'r') as f:\n            paper = json.load(f)\n            papers[paper_id] = paper\n    return papers"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<class 'dict'>\n{'section_title': 'Abstract', 'text': 'Background and Purpose-Ischemic stroke (IS) is a multifactorial disorder with strong evidence from twin, family, and animal model studies suggesting a genetic influence on risk and prognosis. Several candidate genes for IS have been proposed, but few have been replicated. We investigated the contribution of 67 candidate genes (369 single nucleotide polymorphisms [SNPs]) on the risk of IS in a North American population of European descent. Methods-Two independent studies were performed. In the first, 342 SNPs from 52 candidate genes were genotyped in 307 IS cases and 324 control subjects. The SNPs significantly associated with IS were tested for replication in another cohort of 583 IS cases and 270 control subjects. In the second study, 212 SNPs from 62 candidate genes were analyzed in 710 IS cases with subtyping available and 3751 control subjects. Results-None of the candidate genes (SNPs) were significantly associated with IS risk independent of known stroke risk factors after correction for multiple hypotheses testing. Conclusion-These results are consistent with previous meta-analyses that demonstrate an absence of genetic association of variants in plausible candidate genes with IS risk. Our study suggests that the effect of the investigated SNPs may be weak or restricted to specific populations or IS subtypes. Key Words: candidate genes Ⅲ genetics Ⅲ ischemic stroke S troke is a multifactorial disorder or complex trait for which it is not possible to demonstrate classical patterns of inheritance. Ischemic stroke (IS) is a common neurological disease and a leading cause of severe disability and death in Western countries. 1 Approximately 85% to 90% of strokes are ischemic. 2, 3 Strong evidence from twin, family, and animal model studies, however, have consistently suggested a genetic influence on stroke risk and prognosis. 4 The genetic etiology of IS is likely to be complex with many loci modulating pathophysiological processes and conferring a small to moderate risk.\\nThe most practical and widely used approach to identify common alleles influencing stroke has been candidate gene association analysis. The published genomewide association studies of IS 5, 6 have provided candidate loci of interest, although independent replication is required to establish the most convincing of these (12p13.33) as a definite risk locus for disease. Although several candidate genes for IS have been investigated by case-control analysis, few associations have been consistently replicated. We performed a casecontrol study in which cases (participants with an ischemic stroke) were compared with control subjects (participants free of a history of vascular events). We tested a total of 67 IS candidate genes (369 single nucleotide polymorphisms [SNPs]) that have been considered as potential genetic risk factors in vascular diseases for a role in stroke risk.\\nAll samples used for Study 1 and Study 2 are of European descent. 10 In the replication phase, unrelated European descent neurologically normal control samples from different sites within the United States were from the Coriell repository. Each subject underwent a detailed medical history interview that included family history. Samples were not included if a first-degree relative had a history of the following neurological diseases: Alzheimer disease, amyotrophic lateral sclerosis, ataxia, autism, bipolar disorder, brain aneurysm, dementia, dystonia, and Parkinson disease. Sum scores on the Folstein Mini Mental State Examination 11 ranged from 26 to 30. For more details, see http://ccr.coriell.org/ninds/controls/controls.html. Table 1 shows the demographic and clinical data in stroke subjects and control subjects in each phase of Study 1.\\nCandidate genes were chosen based on evidence of association from previous studies of IS and according to biological plausibility, including the presence of genes involved in lipid metabolism, coagulation cascade, nitric oxide production, homocysteine metabolism, the renin-angiotensin system, and other stroke risk factors. Tagging SNPs were chosen for each candidate. Loci for the SNP mapping panel are described in the Supplemental Table (available at http://stroke.ahajournals.org).\\nIn the discovery phase, genotyping was performed using the Illumina GoldenGate assay. DNA samples (5 L) were genotyped according to the manufacturer\\'s instructions on an Illumina BeadStation 500G Golden Gate genotyping platform using a custom panel (GS0006623-OPA) of 364 candidate and ancestry informative SNPs.\\nIn the replication phase, high-throughput SNP genotyping was performed using the 5Ј nuclease allelic discrimination assay (TaqMan assay) on an ABI PRISM 7900HT Sequence Detection System. The assay includes the forward target-specific polymerase chain reaction primer, the reverse primer, and the TaqMan MGB probes labeled with 2 special dyes: FAM and VIC.\\nCases and control subjects were pooled and distributed across plates. We also randomly selected 134 individuals from the discovery phase and genotyped them for these SNPs using the TaqMan assays to ensure the 2 methods used in the different phases generated the same genotypes for each individual (concordance rate 99.9%).\\nGenotypes were assigned in separate cluster files using Beadstudio Version 2.0 genotyping software. Genotypes with GenCall scores Ͼ0.25 were called. SNPs were excluded if SNPs had call rates Ͻ95% in cases or control subjects or the SNP genotyping was considered poor quality. Any samples with a call rate Ͻ95% of the SNPs were excluded from the analysis.\\nAll genotype assignments were performed blind with regard to clinical data.\\nTests of significance between cases and control subjects were performed using 2-sample tests for binomial proportions (using a 2 test of independence). Fisher exact test was used when appropriate. For comparison of age (continuous) among case-control groups, a 2-sample t test for independent samples was performed. For each SNP, tests of deviations from Hardy-Weinberg expectations were performed using the methods described by Wigginton et al. 12 SNPs were dropped if the Hardy-Weinberg equilibrium probability value in the control group was Ͻ0.05 and minor allele frequency was Ͻ1% in the population.\\nFor tests of association with individual SNPs between cases and control subjects, a series of generalized estimating equations were used that permitted inclusion of recognized stroke risk factors as covariates (age, sex, hypertension status, presence of atrial fibrillation, history of myocardial infarction, smoking status, presence of diabetes mellitus, and family history of stroke). Probability values were computed using the 2 degrees-of-freedom generalized test of association. When the generalized test of association was significant (PϽ0.05), additional models were tested that assumed an underlying (37) 1 (50) 223 (56) 175 (44) 48 (52) 1 (100) 0.0149\\nHypertension, n (%) 50 (54) 1 (50) 232 (59) 78 (29) 67 (72) 1 (100) Ͻ0.001\\nDiabetes mellitus, n (%) 16 (17) 1 (50) 58 (15) 21 (8) 27 (29) 0 (0) Ͻ0.001\\nSmoking, n (%) 55 (60) 2 (100) 235 (61) 108 (40) 91 (98) 1 (100) Ͻ0.001\\nHeart disease, n (%) 29 (32) 1 (50) 17 (4) 31 (12) 20 (22) Tests for association with stroke risk were computed using the expectation-maximization algorithm. Statistical significance was assessed using a permutation test of the likelihood ratio statistic.\\nAt the time of completion of Study 1, genotyping from 710 IS cases with subtype data available and 3751 control subjects in Ͼ500 000 SNPs was obtained. We re-examined associations with the Study 1 candidate genes (SNPs) as well as others previously reported to be significantly associated with IS in published meta-analyses or studies with replication. [13] [14] [15] [16] [17] [18] [19] [20] [21] We also examined SNPs contained in these genes or close to these genes (within 1 MB) that have not been reported in the literature but were included in the genotyping assays used here.\\nIschemic Stroke samples came from ISGS, SWISS, and the Coriell repository. Control samples were selected from individuals who had participated in genomewide association studies performed by our group: 787 samples from the neurogenetics collection at the Coriell cell repository and 728 from the Baltimore Longitudinal Study of Aging (BLSA). In addition, 2236 samples were available from the Cancer Genetic Marker of Susceptibility Study (CGEMS). Details of CGEMS and BLSA collection of cohorts have been previously described. 22, 23 Briefly, CGEMS is a 3-year initiative of the National Cancer Institute that conducts genomewide association studies to identify common gene variations increasing the risk for cancer. On approval of a Data Access Request, we obtained raw genotype data from 1142 women from the Nurses Health Study and 1094 men from the Prostate, Lung, Colon and Ovarian Cancer Screening Trial. BLSA is a long-term study designed in 1958 to trace the effects of aging in humans. The BLSA study recruited individuals aged 17 to 96 years to participate in the assessment of health and physical and psychological performance. The average length of follow-up was 7.5 years with participants evaluated every 2 years in the Gerontology Research Center of the National Institutes of Health. Samples from individuals that developed IS, Alzheimer disease, Parkinson disease, or any other neurological conditions were not included. Table 2 shows the demographic and clinical data in stroke subjects and control subjects for each cohort used in Study 2. The Figure shows a study schematic.\\nAll DNA samples were obtained from individuals who were neurologically normal, of non-Hispanic European descent, had given signed informed consent, and for whom clinical phenotype data were available.\\nSamples were excluded because demographic data or analysis of genetic background and/or pairwise identity-by-descent estimation examined by PLINK (http://pngu.mgh.harvard.edu/Ϸpurcell/plink/) showed these samples not belonging to the European descent population or with a level of relatedness higher than expected. The source of the sample was also used as another covariate to correct for possible stratification.\\nA stepwise series of analyses was performed. Initially, the outcome (stroke case-control status) was a function solely of SNP and source of the sample (baseline model). This analysis was followed by models that included age, sex, hypertension, diabetes, heart disease, and smoking as covariates (independent predictors). Association between the investigated polymorphisms and risk of stroke were analyzed by means of logistic regression. The influence of multiple testing was evaluated using false discovery rate. All statistical analyses were done with PLINK.\\nPower calculations were generated using a log-additive model of risk, 5% Type 1 error rate, and 80% power. For a minor allele frequency of 0.15, the detectable OR in the discovery phase of Study 1 was 1.51; the detectable OR in the replication phase of Study 1 was 1.47; and the detectable OR in Study 2 was 1.24. Participants in both studies were enrolled prospectively under Institutional Review Board-approved protocols at participating institutions and all subjects gave written informed consent.\\nResults\\nAfter quality filtering, 342 SNPs in 307 IS cases and 324 control subjects were evaluated. Each SNP was tested independently for association with IS. After adjustment for stroke risk factors (age, sex, race, and other stroke risk factors), 7 SNPs were significantly associated with IS risk (PϽ0.05). After Bonferroni correction, none of these SNPs remained significant. Because the Bonferroni correction is overly conservative, these 7 SNPs were genotyped in an independent cohort of 853 samples (583 patients with IS and 270 control subjects). After adjustment for stroke risk factors, none of the SNPs were significantly associated with IS. The summary statistics associated with these 7 SNPs are shown in Table 3 . We tested these SNPs for association to the main subtypes of IS. After adjustment by Bonferroni correction, only the SNP rs1799983 was associated with the \"other\" IS subtype (additive model OR 1.56; 95% CI, 1.25 to 1.94; Pϭ0.0003).\\nThe program PLINK was used to test for population stratification. All IS cases and control subjects were determined to have the same genetic structure.\\nTwo hundred twelve SNPs from 62 genes that have been reported to be significantly associated with IS and were included in published meta-analyses or studies with replication, or SNPs investigated in our first study (using Golden Gate assay), were contained in the used Illumina Infinium BeadChips and passed our control quality criteria (call rate Ͼ95%, Hardy-Weinberg equilibrium PϾ1.0ϫ10 Ϫ7 , minor allele frequency Ͼ1%). None of the SNPs in the candidate genes were significantly associated with IS after different measures of correction (Bonferroni, false discovery rate).\\nAnalysis was performed in a subgroup of 710 IS and 1495 control subjects (samples from ISGS, SWISS, BLSA, and Coriell repository) that had complete stroke phenotypes. None of the SNPs in the candidate genes were significantly associated with IS after false discovery rate correction. We also examined other SNPs contained in these genes or within 1 MB of these genes not reported in the literature. None of the SNPs were significant after correcting for multiple tests. Given that samples coming from the BLSA study were followed up by at least 7.5 years, we can be more certain that these samples remained free of stroke. Thus, we further restricted these analyses to IS samples and control subjects from BLSA. None of the SNPs were significantly associated with risk for IS. The Supplemental Table shows SNPs that have been analyzed by our group or in published meta-analyses or studies with replication in European descent populations post-2005 13-21 and their results. Table 4 shows genetic common variants that have been found to be significantly associated with IS in meta-analyses or studies with replication. Table 5 shows details of the current study and other studies that did not find any association.\\nAssociation studies are becoming a common approach to mapping variants that affect IS. Although some studies, including some meta-analyses, indicate an association between the risk of stroke and certain SNPs, many other studies show lack of reproducibility. In this study, a series of highly plausible candidate genes were selected for intensive and comprehensive genetic study. No evidence for association with either IS or stroke subtype was observed. C-HWE indicates Hardy-Weinberg equilibrium in control subjects; 2DF, 2-degrees-of-freedom generalized test of association; DOM, dominant model; ADD, additive model; REC, recessive model; bp, base pair; SNP, single nucleotide polymorphism; PPARG, peroxisome proliferator-activated receptor gamma; F13A1, coagulation factor XIII, A1 polypeptide; NOS3, nitric oxide synthase 3 (endothelial cell); MMP3, matrix metallopeptidase 3 (stromelysin 1, progelatinase); LIPC, lipase, hepatic.\\nby guest on August 4, 2017\\nhttp://stroke.ahajournals.org/\\nThe potential reasons that have been discussed for this lack of reproducibility are reduced to 3 potential causes: a falsepositive association is correctly not replicated; a true association fails to be replicated in an underpowered follow-up study (false-negative); or a true association in one population is not true in a second population because of heterogeneity in genetic or environmental background. 24 In the case of stroke, most studies that have identified polymorphisms related with IS are underpowered studies with a sample size not Ͼ300 patients. Until recently, the larger-scale studies came from meta-analysis. Casas et al performed meta-analyses of 120 stroke candidate gene case-control studies and a total of 51 polymorphisms in 32 genes. Statistically significant associations with IS were identified for factor V Leiden Arg506Gln, methylenetetrahydrofolate reductase C677T, prothrombin G20210A, and angiotensin-converting enzyme insertion/deletion. 15 Wang et al evaluated the association between 105 polymorphisms in 64 inflammatory and cardiovascular systemrelated genes and IS. None of these SNPs remained statistically significant after false discovery rate correction. Only when the data were stratified on hypertension status, 2 polymorphisms on LTA were significantly associated with IS in nonhypertensive subjects. The data were not adjusted for other stroke risk factors such as diabetes or heart disease. 14 Other meta-analyses restricted to one or more common variant from one gene reported an association with IS for GP1BA 16 or a nonassociation for plasminogen activator inhibitor-1, tumor necrosis factor-␣, and ITGA2. 18 -20 Although meta-analyses facilitate the overall interpretation of association, they also need to be interpreted with caution. Some meta-analyses do not include stroke risk factors as covariates and the sample sizes remain small when correctly taking into account differences in ethnicity and/or inclusion study criteria (inclusion of children and adults, patients with transient ischemic attack, and so on). W indicates white; IS, ischemic stroke; C, control subjects; Ch, cholesterol; HT, hypertension; D, diabetes; SM, smoking; GP1BA, glycoprotein Ib (platelet), alpha polypeptide; LTA, lymphotoxin alpha (tumor necrosis factor superfamily, member 1); NOS3, nitric oxide synthase 3 (endothelial cell); PAI1, plasminogen activator inhibitor type 1; F5, coagulation factor V (proaccelerin, labile factor); MTHFR, 5,10-methylenetetrahydrofolate reductase (NADPH); F2, coagulation factor II (thrombin); ACE, angiotensin I converting enzyme (peptidyl-dipeptidase A) 1. In an attempt to clarify these associations and avoid false-positive associations, we decided to conduct a casecontrol study and used an independent cohort as a replication study of the other. In uncorrected analysis for multiple testing, 7 polymorphisms were associated with IS in the first stage after adjustment for stroke risk factors. None of these polymorphisms were associated with IS in the replication study. In a second larger study, we investigated the same genes (192 SNPs in common) with the same results: modest, albeit nonsignificant, associations.\\nBerger et al investigated a total of 106 SNPs located in 63 candidate genes for potential associations with ischemic stroke in 2 independent case-control studies from a German population. All genes tested were related to pathways important in the pathophysiology of cardiovascular and inflammatory diseases. Only the glu298asp polymorphism in the nitric oxide synthase-3 gene was reported to be replicated in the second study. The association was independent of age, sex, hypertension, diabetes, and hypercholesterolemia in both studies. In the present study, a first association with the same SNP and IS was not replicated in the second cohort. Analysis of data of the genomewide association scan did not show an association either. Only in analysis by stroke subtype using the full sample did the glu298asp polymorphism become associated with increased risk of unknown stroke subtype independent of other stroke risk factors and while using Bonferroni correction. 13 The study presented here also has some limitations. The size of the studied population in the first stage using the Golden Gate assay is relatively small and therefore underpowered to find genes with small effects influencing risk for IS. The inclusion of one second set of cases-control subjects as replication of the most significant SNPs rules out falsepositive associations but does not rule out the possibility of false-negative or Type II error associations. However, analysis of many of these SNPs in a larger cohort and a review of the literature suggests that the majority of these SNPs have no significant effect for stroke risk in white populations.\\nThe development and application of genomewide association studies represents a significant opportunity for stroke research and provides an opportunity to test the common disease common variant hypothesis in this disorder. Two genomewide association studies for stroke have been published thus far, a pilot study of modest size published by us in 2007 5 that failed to find any risk alleles of large effect and a recent study published by Ikram and colleagues that suggests a significant association between a locus at 12p13.33 with stroke. This locus was not present in the panel of loci selected for testing here; however, this locus clearly warrants replication in an independent study to confirm or refute this as an unequivocal risk factor for stroke.\\nIn summary, 7 polymorphisms have been reported to be associated with IS after meta-analysis or replication; however, all of these SNPs have been investigated in at least one other large study in which no association with IS was reported. Differences in inclusion and exclusion criteria selection, type of statistical evaluation, covariates, correction for multiple testing, and inclusion of different patient populations may explain these discrepancies. This study indicates that any association that may exist is likely to be weak or perhaps restricted to specific populations or IS subtypes.'}\n"
    }
   ],
   "source": "df = load_train_meta('/kaggle/input/coleridgeinitiative-show-us-the-data/train.csv', group_id=True).iloc[-10:]\npapers = load_papers('/kaggle/input/coleridgeinitiative-show-us-the-data/train/', df.Id)\nprint(type(papers))\nprint(\n    papers[ np.random.choice(df.Id.values) ][0]\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Data processing"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#export\n\n# Special tokens\nAAAsTITLE = 'AAAsTITLE'  # Start of section title\nZZZsTITLE = 'ZZZsTITLE'  # End of section title\nAAAsTEXT = 'AAAsTEXT'    # Start of section text\nZZZsTEXT = 'ZZZsTEXT'    # End of section text"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#export\n\ndef load_section(section, mark_title=False, mark_text=False):\n    '''\n    Args:\n        section (dict): e.g. {'section_title': 'Method of Analysis', \n                              'text'         : 'For this study, ...'}\n        mark_title (bool): If True, will mark the start and end of \n            the section title with 'AAAsTITLE' and 'ZZZsTITLE', respectively.\n        mark_text (bool): If True, will mark the start and end of\n            the section text with 'AAAsTEXT' and 'ZZZsTEXT', respectively.\n    Returns:\n        out (str): Text of the section. \n    '''\n    title, text  = section['section_title'], section['text']\n    \n    out = ''\n    \n    if title:\n        if mark_title:\n            out = f\"{AAAsTITLE} {title} {ZZZsTITLE}\"\n        else:\n            out = title\n    \n    if text:\n        if mark_text:\n            out += f\"\\n\\n{AAAsTEXT} {text} {ZZZsTEXT}\"\n        else:\n            out += f\"\\n\\n{text}\"\n            \n    return out\n\n\ndef load_paper(paper, mark_title=False, mark_text=False):\n    '''\n    Load text for the paper.\n    '''\n    sections = (load_section(section, mark_title, mark_text) for section in paper)\n    return '\\n\\n'.join(sections)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Dataset labels: ADNI|Alzheimer's Disease Neuroimaging Initiative (ADNI)\n\nAAAsTITLE Introduction ZZZsTITLE\n\nCerebrovascular pathologies affecting small arteries and arterioles are common findings in the aged brain [1] [2] [3] and are often seen in brains of persons with dementia. [4] [5] [6] [7] Here, we focused on brain arteriolosclerosis (B-ASC), a subtype of cerebral small vessel pathology characterized by degenerative wall thickening of arterioles. [8] [9] [10] The true prevalence of B-ASC is unknown but has been observed in 39-80% of autopsied elderly individuals. 11, 12 The pathologic changes of B-ASC include hypertrophy and/or death of vascular smooth muscle cells and extracellular deposition of elastin and collagen. 1, 2, 13, 14 In the present study, we sought to better understand the risk factors and global cognitive status associated with B-ASC pathology among aged individuals.\nHypertension and diabetes are presumed risk factors for arteriolosclerosis (ASC) in the brain and other organs. Chronic hypertension is associated with ASC pathology in the brain, kidney, and other organs. [15] [16] [17] Hypertensive animal models have thicker cerebral arteriolar walls, larger vessel cross-sectional areas, and smaller inner arteriolar diameters compared to control animals. 18, 19 Diabetic patients have thicker subcutaneous gluteal arteriolar walls and larger cross-sectional areas compared to controls. 20, 21 Diabetic animal models have thicker retinal capillary walls 22 and renal arteriolar glomerular basement membranes 23 compared to controls. In addition to clinical risk factors, recent studies suggest that a single nucleotide polymorphism (SNP) located in ABCC9, ATP-binding cassette sub-family C member 9, may be a genetic risk factor for B-ASC pathology in older elderly individuals. Evidence in support of the link between an ABCC9 SNP and B-ASC pathology are as follows: (1) The rs704180 SNP located in ABCC9 is associated with hippocampal sclerosis of aging (HS-Aging), 24 ,25 a neurodegenerative disease affecting individuals >80 years at death. 8, 26 (2) Individuals with HS-Aging have worse B-ASC pathology compared to individuals without HS-Aging pathology. 8 ( 3) The gene product of ABCC9 is a subunit of ATP-sensitive potassium channels found in vascular smooth muscle cells, including arterioles. 27 Thus, by extension, ABCC9 gene variants may constitute a risk factor for B-ASC pathology in elderly individuals. However, this credible hypothesis has not been tested previously.\nAs the clinical and genetic risk factors for B-ASC are imperfectly understood, so is the cognitive impairment associated with this pathology. Studies on the global cognitive status of patients with B-ASC have included the analyses of Mini Mental State Examination (MMSE) scores, 28 Clinical Dementia Rating Scale (CDR) scores, 29 and CDR Sum of Boxes (CDRSUM) scores. 30 The MMSE is an assessment tool used in measuring global cognitive function, 31 while the CDR is a measure of a person's ability to accomplish activities of daily living. 32, 33 The CDRSUM score is derived by summing scores from all CDR domains. 34 Prior analyses of data from 334 elderly individuals did not reveal an association between B-ASC pathology and MMSE scores. 28 However, in an autopsy study with 52 cases, widespread B-ASC pathology in cases with Alzheimer's disease (AD) was associated with worse global CDR scores. 29 Similarly, in an autopsy study using 715 AD cases with CDRSUM information, researchers found that high B-ASC severity was associated with worse CDRSUM scores. 30 Conflicting results from these studies may be due to a number of experimental factors including small sample size (statistical power), particular cognitive domains affected by small blood vessel pathologies, frequent presence of comorbid pathologies, and parameters that vary in different parts of the human aging spectrum.\nIn order to gain insight into B-ASC risk factors and global cognitive status while factoring in other dementia-associated pathologies, we analyzed a subset of individuals from the National Alzheimer's Disease Coordinating Center (NACC) data set. Because there is evidence of distinct neurodegenerative outcomes and clinical-pathological correlation differences between the ''younger-old'' and ''oldest-old'' persons, [35] [36] [37] [38] [39] [40] [41] we analyzed groups separately according to ages at death:-< 80 years and !80 years. The goals of the study were to determine if autopsy-verified B-ASC is associated with global cognitive status, to assess the association between vascular risk factors and B-ASC pathology, and to determine the relationship between ABCC9 HS-Aging risk genotype and B-ASC pathology. In order to further test the association between the ABCC9 HS-Aging risk genotype and B-ASC pathology, we studied the relationship between the ABCC9 HS-Aging risk genotype and cerebral blood flow (CBF) (a possible in vivo manifestation of B-ASC pathology). Genetic and neuroimaging data on a sub-sample of individuals from the Alzheimer's Disease Neuroimaging Initiative (ADNI) data set were used to test this association.\n\n==================================================\nAbstract\n\nAAAsTEXT Risk factors and cognitive sequelae of brain arteriolosclerosis pathology are not fully understood. To address this, we used multimodal data from the National Alzheimer's Coordinating Center and Alzheimer's Disease Neuroimaging Initiative data sets. Previous studies showed evidence of distinct neurodegenerative disease outcomes and clinicalpathological correlations in the ''oldest-old'' compared to younger cohorts. Therefore, using the National Alzheimer's Coordinating Center data set, we analyzed clinical and neuropathological data from two groups according to ages at death: < 80 years (n ¼ 1008) and !80 years (n ¼ 1382). In both age groups, severe brain arteriolosclerosis was associated with worse performances on global cognition tests. Hypertension (but not diabetes) was a brain arteriolosclerosis risk factor in the younger group. In the ! 80 years age at death group, an ABCC9 gene variant (rs704180), previously associated with aging-related hippocampal sclerosis, was also associated with brain arteriolosclerosis. A post-hoc arterial spin labeling neuroimaging experiment indicated that ABCC9 genotype is associated with cerebral blood flow impairment; in a convenience sample from Alzheimer's Disease Neuroimaging Initiative (n ¼ 15, homozygous individuals), non-risk genotype carriers showed higher global cerebral blood flow compared to risk genotype carriers. We conclude that brain arteriolosclerosis is associated with altered cognitive status and a novel vascular genetic risk factor. ZZZsTEXT\n\nIntroduction\n\nAAAsTEXT Cerebrovascular pathologies affecting small arteries and arterioles are common findings in the aged brain [1] [2] [3] and are often seen in brains of persons with dementia. [4] [5] [6] [7] Here, we focused on brain arteriolosclerosis (B-ASC), a subtype of cerebral small vessel pathology characterized by degenerative wall thickening of arterioles. [8] [9] [10] The true prevalence of B-ASC is unknown but has been observed in 39-80% of autopsied elderly individuals. 11, 12 The pathologic changes of B-ASC include hypertrophy and/or death of vascular smooth muscle cells and extracellular deposition of elastin and collagen. 1, 2, 13, 14 In the present study, we sought to better understand the risk factors and global cognitive status associated with B-ASC pathology among aged individuals.\nHypertension and diabetes are presumed risk factors for arteriolosclerosis (ASC) in the brain and other organs. Chronic hypertension is associated with ASC pathology in the brain, kidney, and other organs. [15] [16] [17] Hypertensive animal models have thicker cerebral arteriolar walls, larger vessel cross-sectional areas, and smaller inner arteriolar diameters compared to control animals. 18, 19 Diabetic patients have thicker subcutaneous gluteal arteriolar walls and larger cross-sectional areas compared to controls. 20, 21 Diabetic animal models have thicker retinal capillary walls 22 and renal arteriolar glomerular basement membranes 23 compared to controls. In addition to clinical risk factors, recent studies suggest that a single nucleotide polymorphism (SNP) located in ABCC9, ATP-binding cassette sub-family C member 9, may be a genetic risk factor for B-ASC pathology in older elderly individuals. Evidence in support of the link between an ABCC9 SNP and B-ASC pathology are as follows: (1) The rs704180 SNP located in ABCC9 is associated with hippocampal sclerosis of aging (HS-Aging), 24 ,25 a neurodegenerative disease affecting individuals >80 years at death. 8, 26 (2) Individuals with HS-Aging have worse B-ASC pathology compared to individuals without HS-Aging pathology. 8 ( 3) The gene product of ABCC9 is a subunit of ATP-sensitive potassium channels found in vascular smooth muscle cells, including arterioles. 27 Thus, by extension, ABCC9 gene variants may constitute a risk factor for B-ASC pathology in elderly individuals. However, this credible hypothesis has not been tested previously.\nAs the clinical and genetic risk factors for B-ASC are imperfectly understood, so is the cognitive impairment associated with this pathology. Studies on the global cognitive status of patients with B-ASC have included the analyses of Mini Mental State Examination (MMSE) scores, 28 Clinical Dementia Rating Scale (CDR) scores, 29 and CDR Sum of Boxes (CDRSUM) scores. 30 The MMSE is an assessment tool used in measuring global cognitive function, 31 while the CDR is a measure of a person's ability to accomplish activities of daily living. 32, 33 The CDRSUM score is derived by summing scores from all CDR domains. 34 Prior analyses of data from 334 elderly individuals did not reveal an association between B-ASC pathology and MMSE scores. 28 However, in an autopsy study with 52 cases, widespread B-ASC pathology in cases with Alzheimer's disease (AD) was associated with worse global CDR scores. 29 Similarly, in an autopsy study using 715 AD cases with CDRSUM information, researchers found that high B-ASC severity w\n"
    }
   ],
   "source": "df = load_train_meta('/kaggle/input/coleridgeinitiative-show-us-the-data/train.csv', group_id=True).iloc[:10]\npapers = load_papers('/kaggle/input/coleridgeinitiative-show-us-the-data/train', df.Id)\n\nidx_paper, idx_section = 3, 1\npaper   = papers[df.Id.iloc[idx_paper]]\nsection = paper[idx_section]\n\nprint('Dataset labels:', df.iloc[idx_paper].dataset_label)\nprint()\nprint(load_section(section, mark_title=True, mark_text=False), end='\\n\\n')\nprint(50 * '=')\nprint(load_paper(paper, mark_title=False, mark_text=True)[:5_000])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#export\n\ndef text2words(text, pretokenizer=BertPreTokenizer()):\n    '''\n    Pre-tokenizes a piece of text.  BertPreTokenizer tokenizes by space and \n    punctuation.\n    \n    Args:\n        text (str): Text to split into words by space and punctuations.\n        pretokenizer (tokenizers.pre_tokenizers.BertPreTokenizer): \n            Pre-tokenizer to use to split text into words.\n    Returns:\n        List of words in text.\n    '''\n    tokenized_text = pretokenizer.pre_tokenize_str(text)\n    if tokenized_text:\n        tokenized_text, _ = zip(*tokenized_text)\n    return list(tokenized_text)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "A long diag is caught on chest and burst by Kuzaev, but the ball runs away from him before he can cross. \nThat was good football though, and I really like the way Russia are approaching this game.\n\n['A', 'long', 'diag', 'is', 'caught', 'on', 'chest', 'and', 'burst', 'by', 'Kuzaev', ',', 'but', 'the', 'ball', 'runs', 'away', 'from', 'him', 'before', 'he', 'can', 'cross', '.', 'That', 'was', 'good', 'football', 'though', ',', 'and', 'I', 'really', 'like', 'the', 'way', 'Russia', 'are', 'approaching', 'this', 'game', '.']\n[]\n"
    }
   ],
   "source": "text = '''A long diag is caught on chest and burst by Kuzaev, but the ball runs away from him before he can cross. \nThat was good football though, and I really like the way Russia are approaching this game.\n'''\nprint(text)\n\npretokenizer = BertPreTokenizer()\nprint(text2words(text, pretokenizer=pretokenizer))\n\nprint(text2words(''))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#export\ndef clean_training_text(txt, lower=False, total_clean=False):\n    \"\"\"\n    Competition's evaluation: `lower=True` and `total_clean=False`.\n    \"\"\"\n    txt = str(txt).lower() if lower else str(txt)\n    txt = re.sub('[^A-Za-z0-9]+', ' ', txt).strip()\n    if total_clean:\n        txt = re.sub(' +', ' ', txt)\n    return txt"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "kaggle This competition awards 90 000\nAASECTIONTITLE Abstract ZZSECTIONTITLE AASECTIONTEXT This paper is about datasets ZZSECTIONTEXT\nhopkld 7 11 002\n"
    }
   ],
   "source": "print(clean_training_text('@kaggle This competition awards $90,000!!!!.'))\nprint(clean_training_text('''AASECTIONTITLE Abstract ZZSECTIONTITLE \\n AASECTIONTEXT This paper is about datasets. ZZSECTIONTEXT'''))\nprint(clean_training_text('HoPKLd + 7 !  11,002', total_clean=True, lower=True))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#export\n\ndef extract_sentences(paper, sentence_definition='sentence', \n                      mark_title=False, mark_text=False):\n    '''\n    Returns:\n        sentences (list): List of sentences.  Each sentence is a string.\n    '''\n    if sentence_definition == 'sentence':\n        sentences = [sentence for s in paper \n                     for sentence in s['text'].split('.') if s['text']]\n        \n    elif sentence_definition == 'section':\n        sentences = [load_section(s, mark_title=mark_title, mark_text=mark_text) \n                     for s in paper if s['section_title'] or s['text']]\n        \n    elif sentence_definition == 'paper':\n        sentences = [load_paper(paper, mark_title=mark_title, mark_text=mark_text)]\n        \n    return sentences"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "AAAsTITLE Abstract ZZZsTITLE\n\nBackground and Purpose: Neuropsychiatric symptoms (NPS) are frequently encountered in patients with Alzheimer's disease (AD). Focal grey matter atrophy has been linked to NPS development. Cerebrovascular disease can cause focal lesions and is common among AD patients. As cerebrovascular disease can be detected on MRI as white matter hyperintensities (WMH), this study evaluated WMH burden in mild cognitive impairment (MCI), AD and normal controls and determined their relationship with NPS. Methods: NPS were assessed using the Neuropsychiatric Inventory and grouped into subsyndromes. WMH were measured using an automatic segmentation technique and mean deformation-based morphometry was used to measure atrophy of grey matter regions. Results: WMHs and grey matter atrophy both contributed significantly to NPS subsyndromes in MCI and AD subjects, however, WMH burden played a greater role. Conclusions: This study could provide a better understanding of the pathophysiology of NPS in AD.\n"
    }
   ],
   "source": "df = load_train_meta('/kaggle/input/coleridgeinitiative-show-us-the-data/train.csv', group_id=True).iloc[100:110]\npapers = load_papers('/kaggle/input/coleridgeinitiative-show-us-the-data/train', df.Id)\n\nidx = 6\n\npaper = papers[df.Id.iloc[idx]]\nsentences = extract_sentences(paper, sentence_definition='section', mark_title=True, mark_text=False)\n\nprint(sentences[0])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#export\n\ndef shorten_sentences(sentences, max_length=64, overlap=20):\n    '''\n    Args:\n        sentences (list): List of sentences. Each sentence is list of words.\n        max_length (int): Maximum number of words allowed for each sentence.\n        overlap (int): If a sentence exceeds `max_length`, we split it to multiple sentences with \n            this amount of overlapping.\n    '''\n    \n    short_sentences = []\n    for sentence in sentences:\n        if len(sentence) > max_length:\n            for p in range(0, len(sentence), max_length - overlap):\n                short_sentences.append(sentence[p:p+max_length])\n        else:\n            short_sentences.append(sentence)\n    return short_sentences"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[['AAAsTITLE', 'EURO2020', 'ZZZsTITLE', 'AAAsTEXT', 'When', 'Patrik', 'Schick', 'planted', 'his', 'header', 'beyond', 'David', 'Marshall', ',', 'the', 'place', 'fell', 'silent', 'for', 'the', 'first', 'time', '.', 'When', 'Schick', \"'\", 's', 'utterly', 'majestic', 'second', 'soared', 'over', 'the', 'goalkeeper', ',', 'frustration', 'turned', 'to', 'exasperation', 'and', ',', 'eventually', ',', 'resignation', '.', 'ZZZsTEXT'], ['The', 'day', 'began', 'with', 'a', 'feverish', 'excitement', '.', 'Cans', 'of', 'lager', 'were', 'consumed', 'at', 'breakfast', ';', 'establishments', 'rammed', 'by', 'noon', '.', 'Schoolchildren', 'were', 'given', 'a', 'break', 'to', 'watch', 'the', 'game', '.', 'Glasgow', 'hummed', 'and', 'buzzed', 'in', 'a', 'way', 'it', 'has', 'not', 'done', 'for', 'years', '.'], []]\n\n[['AAAsTITLE', 'EURO2020', 'ZZZsTITLE', 'AAAsTEXT', 'When', 'Patrik', 'Schick', 'planted', 'his', 'header'], ['his', 'header', 'beyond', 'David', 'Marshall', ',', 'the', 'place', 'fell', 'silent'], ['fell', 'silent', 'for', 'the', 'first', 'time', '.', 'When', 'Schick', \"'\"], ['Schick', \"'\", 's', 'utterly', 'majestic', 'second', 'soared', 'over', 'the', 'goalkeeper'], ['the', 'goalkeeper', ',', 'frustration', 'turned', 'to', 'exasperation', 'and', ',', 'eventually'], [',', 'eventually', ',', 'resignation', '.', 'ZZZsTEXT'], ['The', 'day', 'began', 'with', 'a', 'feverish', 'excitement', '.', 'Cans', 'of'], ['Cans', 'of', 'lager', 'were', 'consumed', 'at', 'breakfast', ';', 'establishments', 'rammed'], ['establishments', 'rammed', 'by', 'noon', '.', 'Schoolchildren', 'were', 'given', 'a', 'break'], ['a', 'break', 'to', 'watch', 'the', 'game', '.', 'Glasgow', 'hummed', 'and'], ['hummed', 'and', 'buzzed', 'in', 'a', 'way', 'it', 'has', 'not', 'done'], ['not', 'done', 'for', 'years', '.'], []]\nCPU times: user 629 µs, sys: 0 ns, total: 629 µs\nWall time: 575 µs\n"
    }
   ],
   "source": "%%time\n\nsentences = [\n    f'''\n    {AAAsTITLE} EURO2020 {ZZZsTITLE}\n\n    {AAAsTEXT} When Patrik Schick planted his header beyond David Marshall, the place fell silent for the first time.\n    When Schick's utterly majestic second soared over the goalkeeper, \n    frustration turned to exasperation and, eventually, resignation. {ZZZsTEXT}\n    ''',\n    '''\n    The day began with a feverish excitement. \n    Cans of lager were consumed at breakfast; establishments rammed by noon. \n    Schoolchildren were given a break to watch the game. Glasgow hummed and buzzed in a way it has not done for years.\n    ''', \n    \"\"]\n\npretokenizer = BertPreTokenizer()\nsentences = [text2words(s, pretokenizer=pretokenizer) for s in sentences]\n\nprint(sentences)\nprint()\nprint(shorten_sentences(sentences, max_length=10, overlap=2))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#export\ndef find_sublist(big_list, small_list):\n    all_positions = []\n    for i in range(len(big_list) - len(small_list) + 1):\n        if small_list == big_list[i:i+len(small_list)]:\n            all_positions.append(i)\n    \n    return all_positions"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[1, 15]"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "big_list = ['If', 'the', 'thing', 'above', 'is', 'below', 'that', 'thing', 'which', 'is',\n            'not', 'as', 'high', 'up', 'on', 'the', 'thing', 'above', 'when', 'it', 'is', \n            'underneath', 'them.']\nsmall_list = ['the', 'thing', 'above']\n\nfind_sublist(big_list, small_list)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Named Entity Recognition Data\nOr, Token Classification."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#export\ndef get_ner_classlabel():\n    '''\n    Labels for named entity recognition.\n        'O': Token not part of a phrase that mentions a dataset.\n        'I': Intermediate token of a phrase mentioning a dataset.\n        'B': First token of a phrase mentioning a dataset.\n    '''\n    return ClassLabel(names=['O', 'I', 'B'])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "ClassLabel(num_classes=3, names=['O', 'I', 'B'], names_file=None, id=None)\n[1, 0, 2] 1\nB ['B', 'I', 'O']\n"
    }
   ],
   "source": "classlabel = get_ner_classlabel()\nprint(classlabel)\nprint(classlabel.str2int(['I', 'O', 'B']), classlabel.str2int('I'))\nprint(classlabel.int2str(2), classlabel.int2str([2, 1, 0]))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#export    \n\ndef tag_sentence(sentence, labels, classlabel=None): \n    '''\n    Args:\n        sentence (list): List of words.\n        labels (list): List of dataset labels.\n    '''\n    if (labels is not None and\n        any(' '.join(label) in ' '.join(sentence) for label in labels)):\n        \n        nes = [classlabel.str2int('O')] * len(sentence)\n        for label in labels:\n            all_pos = find_sublist(sentence, label)\n            for pos in all_pos:\n                nes[pos] = classlabel.str2int('B')\n                for i in range(pos+1, pos+len(label)):\n                    nes[i] = classlabel.str2int('I')\n\n        return True, list(zip(sentence, nes))\n        \n    else: \n        nes = [classlabel.str2int('O')] * len(sentence)\n        return False, list(zip(sentence, nes))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "A label is found in the sentence: True\n(token, tag) pairs:\n[('AAAsTEXT', 0), ('The', 2), ('International', 1), ('Standard', 0), ('Classification', 0), ('of', 0), ('Education', 0), (',', 0), ('known', 0), ('by', 0), ('its', 0), ('acronym', 0), ('ISCED', 0), (',', 0), ('was', 0), ('developed', 0), ('by', 0), ('the', 0), ('United', 2), ('Nations', 1), ('Educational', 1), (',', 0), ('Scientific', 0), (',', 0), ('and', 0), ('Cultural', 2), ('Organization', 1), ('during', 0), ('the', 0), ('late', 0), ('1960s', 0), ('and', 0), ('1970s', 0), ('ZZZsTEXT', 0)]\n"
    }
   ],
   "source": "sentence = f'''\n    {AAAsTEXT} The International Standard Classification of Education, known by its acronym ISCED, \n    was developed by the United Nations Educational, Scientific, \n    and Cultural Organization during the late 1960s and 1970s {ZZZsTEXT}\n    '''\nlabels = ['The International', 'Cultural Organization', 'United Nations Educational']\n\npretokenizer = BertPreTokenizer()\nsentence = text2words(sentence, pretokenizer)\nlabels = [text2words(label, pretokenizer) for label in labels]\n\nclasslabel = get_ner_classlabel()\nfound_any, token_tags = tag_sentence(sentence, labels, classlabel=classlabel)\n\nprint('A label is found in the sentence:', found_any)\nprint('(token, tag) pairs:')\nprint(token_tags)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "A label is found in the sentence: False\n(token, tag) pairs:\n[]\n"
    }
   ],
   "source": "sentence = \"\"\nlabels = ['The International', 'Cultural Organization', 'United Nations Educational']\n\npretokenizer = BertPreTokenizer()\nsentence = text2words(sentence, pretokenizer)\nlabels = [text2words(label, pretokenizer) for label in labels]\n\nclasslabel = get_ner_classlabel()\nfound_any, token_tags = tag_sentence(sentence, labels, classlabel=classlabel)\n\nprint('A label is found in the sentence:', found_any)\nprint('(token, tag) pairs:')\nprint(token_tags)\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#export\n\ndef get_paper_ner_data(paper, labels, mark_title=False, mark_text=False,\n                       pretokenizer=BertPreTokenizer(), classlabel=get_ner_classlabel(),\n                       sentence_definition='sentence', max_length=64, overlap=20, \n                       neg_keywords=['data', 'study'], neg_sample_prob=None):\n    '''\n    Get NER data for a single paper.\n    \n    Args:\n        paper (list): Each element is a dict of form {'section_title': \"...\", 'text': \"...\"}.\n        labels (list): Each element is a string that is a dataset label.\n        neg_keywords (None, iter): Keywords which a negative sample needs to have.\n        neg_sample_prob (None, float): Probability with which to keep a negative sample.\n        \n    Returns:\n        ner_data (list): Each element is a list of tuples of the form:\n            [('It', 0), ('is', 0), ..., ('ADNI', 2), ('Dataset', 1), ...]\n    '''\n    labels = [text2words(label, pretokenizer) for label in labels]\n\n    sentences = extract_sentences(paper, sentence_definition=sentence_definition, \n                                  mark_title=mark_title, mark_text=mark_text)\n    sentences = [text2words(s, pretokenizer) for s in sentences]\n    sentences = shorten_sentences(sentences, max_length=max_length, overlap=overlap) \n    sentences = [sentence for sentence in sentences if len(' '.join(sentence)) > 10] # only accept sentences with length > 10 chars\n\n    cnt_pos, cnt_neg, ner_data = 0, 0, []\n    for sentence in sentences:\n        is_positive, tags = tag_sentence(sentence, labels, classlabel=classlabel)\n        if is_positive:\n            cnt_pos += 1\n            ner_data.append(tags)\n        elif neg_keywords:\n            if any(keyword in ' '.join(word.lower() for word in sentence) for keyword in neg_keywords): \n                ner_data.append(tags)\n                cnt_neg += 1\n        elif neg_sample_prob is not None:\n            if np.random.rand() < neg_sample_prob:\n                ner_data.append(tags)\n                cnt_neg += 1\n        else:\n            ner_data.append(tags)\n            cnt_neg += 1\n            \n    return cnt_pos, cnt_neg, ner_data"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['ADNI', \"Alzheimer's Disease Neuroimaging Initiative (ADNI)\"]\n1 4\n[360, 360, 360, 360, 162]\n[('a', 0), ('simple', 0), ('three', 0), ('-', 0), ('step', 0), ('algorithm', 0), ('.', 0), ('First', 0), (',', 0), ('the', 0), ('brain', 0), ('MRI', 0), ('is', 0), ('transformed', 0), ('into', 0), ('a', 0), ('one', 0), ('-', 0), ('dimensional', 0), ('(', 0), ('1D', 0), (')', 0), ('signal', 0), ('by', 0), ('row', 0), ('concatenation', 0), ('.', 0), ('Then', 0), (',', 0), ('a', 0), ('three', 0), ('-', 0), ('component', 0), ('feature', 0), ('vector', 0), ('is', 0), ('extracted', 0), ('from', 0), ('the', 0), ('1D', 0), ('signal', 0), ('to', 0), ('characterize', 0), ('its', 0), ('local', 0), ('and', 0), ('global', 0), ('fractal', 0), ('features', 0), ('as', 0), ('expressed', 0), ('by', 0), ('Hurst', 0), (\"'\", 0), ('s', 0), ('exponent', 0), ('and', 0), ('the', 0), ('two', 0), ('results', 0), ('from', 0), ('the', 0), ('detrended', 0), ('fluctuation', 0), ('analysis', 0), ('(', 0), ('DFA', 0), (')', 0), ('[', 0), ('13', 0), (']', 0), ('of', 0), ('the', 0), ('cumulated', 0), ('1D', 0), ('signal', 0), (':', 0), ('the', 0), ('scaling', 0), ('exponent', 0), ('and', 0), ('the', 0), ('total', 0), ('detrended', 0), ('fluctuation', 0), ('energy', 0), ('(', 0), ('Hurst', 0), (\"'\", 0), ('s', 0), ('exponent', 0), ('allows', 0), ('the', 0), ('evaluation', 0), ('of', 0), ('how', 0), ('a', 0), ('signal', 0), ('is', 0), ('self', 0)]\n"
    }
   ],
   "source": "df = load_train_meta('/kaggle/input/coleridgeinitiative-show-us-the-data/train.csv', group_id=True).iloc[230:330]\npapers = load_papers('/kaggle/input/coleridgeinitiative-show-us-the-data/train/', df.Id)\npretokenizer = BertPreTokenizer()\nclasslabel = get_ner_classlabel()\n\nidx = 29\npaper = papers[df.Id.iloc[idx]]\nlabels = df.dataset_label.iloc[idx].split('|')\ncnt_pos, cnt_neg, ner_data = get_paper_ner_data(paper, labels, mark_title=True, mark_text=True,\n                                                pretokenizer=pretokenizer, classlabel=classlabel,\n                                                sentence_definition='paper', max_length=360, overlap=20,\n                                                neg_keywords=None, neg_sample_prob=.3)\nprint(labels)\nprint(cnt_pos, cnt_neg)\nprint([len(sample) for sample in ner_data])\nprint(ner_data[0][:100])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#export\ndef get_ner_data(papers, df=None, mark_title=False, mark_text=False,\n                 classlabel=None, pretokenizer=BertPreTokenizer(), \n                 sentence_definition='sentence', max_length=64, overlap=20, \n                 neg_keywords=['study', 'data'], neg_sample_prob=None,\n                 shuffle=True):\n    '''\n    Get NER data for a list of papers.\n    \n    Args:\n        papers (dict): Like that returned by `load_papers`.\n        df (pd.DataFrame): Competition's train.csv or a subset of it.\n    Returns:\n        cnt_pos (int): Number of samples (or 'sentences') that are tagged or partly\n            tagged as datasets.\n        cnt_neg (int): Number of samples (or 'sentences') that are not tagged\n            or partly tagged as datasets.\n        ner_data (list): List of samples, or 'sentences'. Each element is of the form:\n            [('There', 0), ('has', 0), ('been', 0), ...]\n    '''\n    cnt_pos, cnt_neg = 0, 0 \n    ner_data = []\n\n    tqdm._instances.clear()\n    pbar = tqdm(total=len(df))\n    for i, id, dataset_label in df[['Id', 'dataset_label']].itertuples():\n        paper = papers[id]\n        labels = dataset_label.split('|')\n                \n        cnt_pos_, cnt_neg_, ner_data_ = get_paper_ner_data(\n            paper, labels, mark_title=mark_title, mark_text=mark_text,\n            classlabel=classlabel, pretokenizer=pretokenizer,\n            sentence_definition=sentence_definition, max_length=max_length, overlap=overlap, \n            neg_keywords=neg_keywords, neg_sample_prob=neg_sample_prob)\n        cnt_pos += cnt_pos_\n        cnt_neg += cnt_neg_\n        ner_data.extend(ner_data_)\n\n        pbar.update(1)\n        pbar.set_description(f\"Training data size: {cnt_pos} positives + {cnt_neg} negatives\")\n\n    if shuffle:\n        random.shuffle(ner_data)\n    return cnt_pos, cnt_neg, ner_data"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Training data size: 26 positives + 32 negatives: 100%|██████████| 10/10 [00:00<00:00, 66.43it/s]"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Postive count: 26.   Negative count: 32\n[('AAAsTITLE', 0), ('Differences', 0), ('in', 0), ('Outcomes', 0), ('for', 0), ('Female', 0), ('and', 0), ('Male', 0), ('Students', 0), ('in', 0), ('Special', 0), ('Education', 0), ('ZZZsTITLE', 0), ('AAAsTITLE', 0), ('P', 0), ('olicy', 0), ('reform', 0), ('initiatives', 0), (',', 0), ('such', 0), ('as', 0), ('the', 0), ('No', 0), ('Child', 0), ('Left', 0), ('Behind', 0), ('(', 0), ('NCLB', 0), (')', 0), ('Act', 0), ('of', 0), ('2001', 0), ('and', 0), ('the', 0), ('President', 0), (\"'\", 0), ('s', 0), ('Commission', 0), ('on', 0), ('Excellence', 0), ('in', 0), ('Special', 0), ('Education', 0), ('ZZZsTITLE', 0), ('AAAsTEXT', 0), (',', 0), ('stress', 0), ('satisfactory', 0), ('outcomes', 0), ('for', 0), ('all', 0), ('youth', 0), (',', 0), ('including', 0), ('those', 0), ('who', 0), ('have', 0), ('traditionally', 0), ('been', 0), ('underserved', 0), ('and', 0), ('those', 0), ('who', 0), ('do', 0), ('not', 0), ('readily', 0), ('achieve', 0), ('adult', 0), ('milestones', 0), ('of', 0), ('independence', 0), ('and', 0), ('productivity', 0), ('.', 0), ('Despite', 0), ('increasing', 0), ('evidence', 0), ('that', 0), ('all', 0), ('students', 0), ('have', 0), ('access', 0), ('to', 0), ('comparable', 0), ('experiences', 0), ('and', 0), ('services', 0), ('during', 0), ('school', 0), (',', 0), ('studies', 0), ('have', 0), ('reported', 0), ('that', 0), ('girls', 0), ('who', 0), ('received', 0), ('special', 0), ('education', 0), ('have', 0)]\nCPU times: user 224 ms, sys: 9.85 ms, total: 233 ms\nWall time: 286 ms\n"
    }
   ],
   "source": "%%time\ndf = pd.read_csv('/kaggle/input/coleridgeinitiative-show-us-the-data/train.csv').iloc[:10]\npapers = load_papers('/kaggle/input/coleridgeinitiative-show-us-the-data/train/', df.Id)\n\ncnt_pos, cnt_neg, ner_data = get_ner_data(papers, df, mark_title=True, mark_text=True,\n                                          classlabel=get_ner_classlabel(), pretokenizer=BertPreTokenizer(),\n                                          sentence_definition='paper', max_length=310, overlap=20, \n                                          neg_keywords=None, neg_sample_prob=.2,\n                                          shuffle=False)\n\nprint(f'Postive count: {cnt_pos}.   Negative count: {cnt_neg}')\nprint(ner_data[6][:100])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#export\ndef write_ner_json(ner_data, pth=Path('train_ner.json'), mode='w'):\n    '''\n    Save NER data to json file.\n    '''\n    with open(pth, mode=mode) as f:\n        for row in ner_data:\n            words, nes = list(zip(*row))\n            row_json = {'tokens' : words, 'ner_tags' : nes}\n            json.dump(row_json, f)\n            f.write('\\n')    "
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "{\"tokens\": [\"There\", \"is\", \"no\", \"dataset\", \"here\"], \"ner_tags\": [0, 0, 0, 0, 0]}\n{\"tokens\": [\"Load\", \"the\", \"UN\", \"Trade\", \"Development\", \"into\", \"view\"], \"ner_tags\": [0, 0, 2, 1, 1, 0, 0]}\n"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Training data size: 26 positives + 32 negatives: 100%|██████████| 10/10 [00:19<00:00, 66.43it/s]"
    }
   ],
   "source": "ner_data = [\n    [('There', 0), ('is', 0), ('no', 0), ('dataset', 0), ('here', 0)], \n    [('Load', 0), ('the', 0), ('UN', 2), ('Trade', 1), ('Development', 1), ('into', 0), ('view', 0)]\n]\nwrite_ner_json(ner_data, pth=Path('/kaggle/tmp_ner.json'))\n! cat /kaggle/tmp_ner.json"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#export\ndef load_ner_datasets(data_files=None):\n    '''\n    Load NER data in json files to a `datasets` object.  In addition,\n    Append the NER ClassLabel for the `ner_tags` feature.\n    '''\n    datasets = load_dataset('json', data_files=data_files)\n    classlabel = get_ner_classlabel()\n    for split, dataset in datasets.items():\n        dataset.features['ner_tags'].feature = classlabel\n    return datasets"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Downloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/json/default-a9e162d849c1948f/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02...\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-a9e162d849c1948f/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02. Subsequent calls will reuse this data.\n\n{'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'ner_tags': Sequence(feature=ClassLabel(num_classes=3, names=['O', 'I', 'B'], names_file=None, id=None), length=-1, id=None)}\n{'tokens': ['Load', 'the', 'UN', 'Trade', 'Development', 'into', 'view'], 'ner_tags': [0, 0, 2, 1, 1, 0, 0]}\n"
    }
   ],
   "source": "datasets = load_ner_datasets(data_files={'train':'/kaggle/tmp_ner.json', 'valid':'/kaggle/tmp_ner.json'})\nprint()\nprint(datasets['valid'].features)\nprint(datasets['train'][1])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#export\n\ndef batched_write_ner_json(papers, df, pth=Path('train_ner.json'), batch_size=4_000, \n                           mark_title=False, mark_text=False,\n                           classlabel=get_ner_classlabel(), pretokenizer=BertPreTokenizer(),\n                           sentence_definition='sentence', max_length=64, overlap=20, \n                           neg_keywords=['study', 'data'], neg_sample_prob=None):\n\n    for i in range(0, len(df), batch_size):\n        print(f'Batch {i // batch_size}...', end='')\n        t0 = time.time()\n        cnt_pos, cnt_neg, ner_data = get_ner_data(\n            papers, df.iloc[i:i+batch_size], \n            mark_title=mark_title, mark_text=mark_text,\n            classlabel=classlabel, pretokenizer=pretokenizer,\n            sentence_definition=sentence_definition, max_length=max_length, overlap=overlap, \n            neg_keywords=neg_keywords, neg_sample_prob=neg_sample_prob)\n        write_ner_json(ner_data, pth=pth, mode='w' if i == 0 else 'a')\n        print(f'done in {(time.time() - t0) / 60} mins.')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Training data size: 20 positives + 63 negatives:  12%|█▏        | 12/100 [00:00<00:01, 55.95it/s]"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Batch 0..."
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Training data size: 26 positives + 32 negatives: 100%|██████████| 10/10 [00:29<00:00,  2.99s/it]s]\nTraining data size: 190 positives + 532 negatives: 100%|██████████| 100/100 [00:02<00:00, 59.84it/s]"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "done in 0.04080033699671427 mins.\n"
    }
   ],
   "source": "batch_size = 4_000\ndf = load_train_meta('/kaggle/input/coleridgeinitiative-show-us-the-data/train.csv', group_id=True).iloc[:100]\npapers = load_papers('/kaggle/input/coleridgeinitiative-show-us-the-data/train/', df.Id)\n\nbatched_write_ner_json(papers, df, pth=Path('train_ner.json'), batch_size=batch_size, \n                       mark_title=True, mark_text=True,\n                       classlabel=get_ner_classlabel(), pretokenizer=BertPreTokenizer(),\n                       sentence_definition='section', max_length=360, overlap=20, \n                       neg_keywords=None, neg_sample_prob=.2)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2.2M\ttrain_ner.json\n"
    }
   ],
   "source": "! du -hs train_ner.json"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Downloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/json/default-a06943dd76dac199/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02...\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-a06943dd76dac199/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02. Subsequent calls will reuse this data.\n{'tokens': ['colleagues', \"'\", '(', '2012', ')', 'examination', 'of', 'two', 'longitudinal', 'datasets', 'revealed', 'that', 'fractions', 'and', 'division', 'knowledge', 'in', 'fifth', 'grade', 'were', 'uniquely', 'predictive', 'of', 'high', 'school', 'algebra', 'proficiency', ',', 'even', 'after', 'accounting', 'for', 'domain', 'general', 'cognitive', 'functioning', ',', 'reading', 'ability', ',', 'and', 'whole', 'number', 'skills', '.', 'Although', 'both', 'division', 'skills', 'and', 'fractions', 'skills', 'were', 'found', 'to', 'be', 'predictive', ',', 'they', 'are', 'closely', 'related', 'concepts', ',', 'as', 'a', 'fraction', 'is', 'a', 'representation', 'of', 'a', 'division', 'problem', '(', 'e', '.', 'g', '.', '3', '/', '4', 'can', 'be', 'thought', 'of', 'as', '3', 'divided', 'by', '4', ')', '.', 'Further', ',', 'fifth', 'graders', \"'\", 'whole', 'number', 'addition', ',', 'subtraction', ',', 'and', 'multiplication', 'were', 'less', 'predictive', 'of', 'high', 'school', 'algebraic', 'ability', '.', 'Similar', 'shorter', '-', 'term', 'relations', 'between', 'fraction', 'knowledge', 'and', 'later', 'mathematics', 'learning', 'have', 'been', 'reported', 'elsewhere', '(', 'Booth', '&', 'Newton', ',', '2012', ')', ',', 'and', 'Bailey', 'and', 'colleagues', '(', '2014a', ')', 'found', 'that', 'first', '-', 'grade', 'proficiency', 'with', 'whole', 'numbers', 'predicted', 'eighth', 'grade', 'proficiency', 'with', 'fractions', '.', 'ZZZsTEXT'], 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
    }
   ],
   "source": "datasets = load_ner_datasets(data_files={'train':'train_ner.json'})\nprint(datasets['train'][20])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Tokenization"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Training data size: 190 positives + 532 negatives: 100%|██████████| 100/100 [00:21<00:00, 59.84it/s]"
    }
   ],
   "source": "#export\ndef create_tokenizer(model_checkpoint='distilbert-base-cased'):\n    \n    tokenizer = AutoTokenizer.from_pretrained(\n        model_checkpoint, \n        additional_special_tokens=[AAAsTITLE, ZZZsTITLE, AAAsTEXT, ZZZsTEXT])\n\n    try:\n        tokenizer([\"This\", \"text\", \"is\", \"already\", \"split\"], truncation=True, is_split_into_words=True)\n    except AssertionError:\n        tokenizer.add_prefix_space = True    \n    \n    assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)\n    \n    return tokenizer"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6bb6c2da6cb4386a24ff65d9e89f816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_…"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c675652860e54c11a5697739de5ff352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f269f84a891452b83fa66124ac83c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "960e5f99fe3d47799a4e1115a0c46787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355863.0, style=ProgressStyle(descript…"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "{'input_ids': [0, 50118, 50265, 43649, 1437, 50266, 50140, 50267, 1868, 9, 209, 893, 2152, 579, 2013, 17707, 1437, 50118, 3628, 11322, 11, 5, 28597, 7, 5, 1967, 4, 1437, 50268, 50118, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n{'input_ids': [0, 50265, 47638, 50266, 50267, 16991, 1116, 29902, 859, 7042, 30403, 3215, 29, 2013, 17707, 3628, 11322, 179, 627, 23411, 658, 560, 627, 90, 37535, 4, 50268, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n['<s>', 'Ċ', 'AAAsTITLE', 'ĠAbstract', 'Ġ', 'ZZZsTITLE', 'ĊĊ', 'AAAsTEXT', 'ĠBoth', 'Ġof', 'Ġthese', 'Ġteams', 'Ġsuffered', 'Ġs', 'art', 'orial', 'Ġ', 'Ċ', 'head', 'aches', 'Ġin', 'Ġthe', 'Ġbuildup', 'Ġto', 'Ġthe', 'Ġtournament', '.', 'Ġ', 'ZZZsTEXT', 'Ċ', '</s>']\n"
    }
   ],
   "source": "text = '''\nAAAsTITLE Abstract ZZZsTITLE\n\nAAAsTEXT Both of these teams suffered sartorial \nheadaches in the buildup to the tournament. ZZZsTEXT\n'''\n\ntokenizer = create_tokenizer(model_checkpoint='roberta-base')\n\nprint(tokenizer(text))\nprint(tokenizer(text.split(), is_split_into_words=True))\nprint(tokenizer.convert_ids_to_tokens(tokenizer(text)['input_ids']))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Training data size: 190 positives + 532 negatives: 100%|██████████| 100/100 [00:32<00:00,  3.10it/s]\nTraining data size: 205 positives + 547 negatives: 100%|██████████| 100/100 [00:03<00:00, 20.20it/s]"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Downloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/json/default-63edb32088714296/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02...\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-63edb32088714296/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02. Subsequent calls will reuse this data.\n"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\nToken indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n"
    },
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x7f3b8072fd90>"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 720x432 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": "# Find a suitable original sample length, given a max model input length of 512\n\nmax_input_length = 512\nmax_length, overlap = 300, 20\n\ndf = load_train_meta('/kaggle/input/coleridgeinitiative-show-us-the-data/train.csv', group_id=True)\ndf = df.sample(100).reset_index(drop=True)\npapers = load_papers('/kaggle/input/coleridgeinitiative-show-us-the-data/train', df.Id)\n\ncnt_pos, cnt_neg, ner_data = get_ner_data(papers, df, mark_title=True, mark_text=True,\n                                          classlabel=get_ner_classlabel(), pretokenizer=BertPreTokenizer(), \n                                          sentence_definition='paper', max_length=max_length, overlap=overlap, \n                                          neg_keywords=None, neg_sample_prob=.2)\nwrite_ner_json(ner_data, pth='train_ner.json')\n\ndatasets = load_ner_datasets(data_files={'train':'train_ner.json'})\n\ntokenizer = create_tokenizer(model_checkpoint='roberta-base')\ntokenized_input = tokenizer(datasets['train']['tokens'], truncation=False, is_split_into_words=True)\n\noriginal_sample_lengths = np.array([len(tokens) for tokens in datasets['train']['tokens']])\ntokenized_sample_lengths = np.array([len(input_ids) for input_ids in tokenized_input['input_ids']])\n\nfig, ax = plt.subplots(figsize=(10, 6))\nax.plot(original_sample_lengths, label='original lengths', linestyle='none', marker='o')\nax.plot(tokenized_sample_lengths, label='tokenized lengths', linestyle='none', marker='x')\nax.hlines(y=max_input_length, xmin=0, xmax=len(original_sample_lengths), color='red')\nax.set_ylabel('length')\nax.set_xlabel('sample index')\nax.set_title('section lengths')\nax.legend()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#export\ndef tokenize_and_align_labels(examples, tokenizer=None, label_all_tokens=True):\n    '''\n    Adds a new field called 'labels' that are the NER tags to the tokenized input.\n    \n    Args:\n        tokenizer (transformers.AutoTokenizer): Tokenizer.\n        examples (datasets.arrow_dataset.Dataset): Dataset.\n        label_all_tokens (bool): If True, all sub-tokens are given the same tag as the \n            first sub-token, otherwise all but the first sub-token are given the tag\n            -100.\n    '''\n    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n    labels = []\n    word_ids_all = []\n    for i, label in enumerate(examples[\"ner_tags\"]):\n        word_ids = tokenized_inputs.word_ids(batch_index=i)\n        previous_word_idx = None\n        label_ids = []\n        for word_idx in word_ids:\n            if word_idx is None:\n                label_ids.append(-100)\n            elif word_idx != previous_word_idx:\n                label_ids.append(label[word_idx])\n            else:\n                label_ids.append(label[word_idx] if label_all_tokens else -100)\n            previous_word_idx = word_idx\n\n        labels.append(label_ids)\n        word_ids_all.append(word_ids)\n\n    tokenized_inputs[\"labels\"] = labels\n    tokenized_inputs['word_ids'] = word_ids_all\n    return tokenized_inputs"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "{\"tokens\": [\"There\", \"is\", \"no\", \"dataset\", \"here\"], \"ner_tags\": [0, 0, 0, 0, 0]}\n{\"tokens\": [\"Load\", \"the\", \"UN\", \"Trade\", \"Development\", \"into\", \"view\"], \"ner_tags\": [0, 0, 2, 1, 1, 0, 0]}\nDownloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/json/default-3d25c0540d60e9f6/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02...\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-3d25c0540d60e9f6/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02. Subsequent calls will reuse this data.\n"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n{'input_ids': [[0, 970, 354, 2362, 36146, 281, 594, 10859, 2], [0, 47167, 627, 4154, 35996, 45297, 12473, 5877, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 0, 0, 0, 0, 0, 0, 0, -100], [-100, 0, 0, 2, 1, 1, 0, 0, -100]], 'word_ids': [[None, 0, 1, 2, 3, 3, 3, 4, None], [None, 0, 1, 2, 3, 4, 5, 6, None]]}\n\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba6150b6ddab4500870fa9222823d5fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5eb463a42f847bf8c7d8fb23136434b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n{'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'input_ids': [[0, 970, 354, 2362, 36146, 281, 594, 10859, 2], [0, 47167, 627, 4154, 35996, 45297, 12473, 5877, 2]], 'labels': [[-100, 0, 0, 0, 0, 0, 0, 0, -100], [-100, 0, 0, 2, 1, 1, 0, 0, -100]], 'ner_tags': [[0, 0, 0, 0, 0], [0, 0, 2, 1, 1, 0, 0]], 'tokens': [['There', 'is', 'no', 'dataset', 'here'], ['Load', 'the', 'UN', 'Trade', 'Development', 'into', 'view']], 'word_ids': [[None, 0, 1, 2, 3, 3, 3, 4, None], [None, 0, 1, 2, 3, 4, 5, 6, None]]}\n{'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'ner_tags': Sequence(feature=ClassLabel(num_classes=3, names=['O', 'I', 'B'], names_file=None, id=None), length=-1, id=None), 'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'word_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}\n"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Training data size: 205 positives + 547 negatives: 100%|██████████| 100/100 [00:19<00:00, 20.20it/s]"
    }
   ],
   "source": "ner_data = [\n    [('There', 0), ('is', 0), ('no', 0), ('dataset', 0), ('here', 0)], \n    [('Load', 0), ('the', 0), ('UN', 2), ('Trade', 1), ('Development', 1), ('into', 0), ('view', 0)]\n]\n\nwrite_ner_json(ner_data, pth=Path('/kaggle/tmp_ner.json'))\n! cat /kaggle/tmp_ner.json\n\ndatasets = load_ner_datasets(data_files={'train':'/kaggle/tmp_ner.json', 'valid':'/kaggle/tmp_ner.json'})\ntokenizer = create_tokenizer(model_checkpoint='roberta-base')\n\nprint()\nprint(tokenize_and_align_labels(datasets['train'][:], tokenizer, label_all_tokens=True), end='\\n\\n')\n\ntokenized_datasets = datasets.map(\n    partial(tokenize_and_align_labels, tokenizer=tokenizer, label_all_tokens=True), batched=True)\nprint(tokenized_datasets['valid'][:])\nprint(tokenized_datasets['train'].features)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Save and load `datasets.dataset_dict.DatasetDict`\ntokenized_datasets.save_to_disk('testsave_datasets')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[0, 970, 354, 2362, 36146, 281, 594, 10859, 2], [0, 47167, 627, 4154, 35996, 45297, 12473, 5877, 2]]\n[[0, 970, 354, 2362, 36146, 281, 594, 10859, 2], [0, 47167, 627, 4154, 35996, 45297, 12473, 5877, 2]]\n"
    }
   ],
   "source": "print(datasets.load_from_disk('testsave_datasets')['train']['input_ids'])\nprint(tokenized_datasets['train']['input_ids'])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#export\ndef remove_nonoriginal_outputs(outputs, word_ids):\n    '''\n    Remove elements that correspond to special tokens or subtokens,\n    retaining only those elements that correspond to a word in original\n    text.\n    \n    Args:\n        outputs (np.array): Each row are the label ids for the subtokens of\n            a sample, with -100 indicating ignored subtokens, special tokens,\n            or padding. \n        word_ids (list): Each element is a list of word ids which indicate the word\n            that each subtoken belongs to. Each element corresponds to each row in `outputs`,\n            though it could be shorter, since it's not padded like in `outputs`.\n        \n    Returns:\n        outputs (list): Each element is a list of label ids for the \n            words in an sample. \n    '''\n    assert len(outputs) == len(word_ids)\n    idxs = [[word_id.index(i) for i in set(word_id) if i is not None] \n            for word_id in word_ids]\n    outputs = [output[idx].tolist() for output, idx in zip(outputs, idxs)]\n    for output in outputs:\n        assert -100 not in output\n    return outputs"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "predictions\nBEFORE:\n[[0 2 0 0 1 2 1 2]\n [0 2 0 2 2 0 1 2]]\nAFTER:\n[[2, 0, 1], [2, 0, 2]]\n============================================================\nlabel_ids\nBEFORE:\n[[-100    0    0    2    1    2    1 -100]\n [-100    2    1 -100    0 -100 -100 -100]]\nAFTER:\n[[0, 2, 1], [2, 1, 0]]\n"
    }
   ],
   "source": "classlabel = get_ner_classlabel()\n\npredictions = np.random.randn(2, 8, classlabel.num_classes)\npredictions = np.argmax(predictions, axis=2)\n\nlabel_ids = np.array([[-100, 0, 0,    2, 1,    2,    1, -100],\n                      [-100, 2, 1, -100, 0, -100, -100, -100]])\n\nword_ids = [[None, 0, 0, 1, 2, None],\n            [None, 0, 1, 1, 2, 2, None]]\n\ntrue_predictions = remove_nonoriginal_outputs(predictions, word_ids)\ntrue_label_ids   = remove_nonoriginal_outputs(label_ids,   word_ids)\n\nprint('predictions')\nprint('BEFORE:')\nprint(predictions)\nprint('AFTER:')\nprint(true_predictions)\nprint(60 * '=')\nprint('label_ids')\nprint('BEFORE:')\nprint(label_ids)\nprint('AFTER:')\nprint(true_label_ids)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Evaluation"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#export\ndef jaccard_similarity(s1, s2):\n    l1 = set(s1.split(\" \"))\n    l2 = set(s2.split(\" \"))\n    intersection = len(list(l1.intersection(l2)))\n    union = (len(l1) + len(l2)) - intersection\n    return float(intersection) / union"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "jaccard_similarity('USGS Frog Counts Data', 'USGA Croc Counts Data') == 1 / 3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c3199ccc03497b8b2e5cea291f5288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1961.0, style=ProgressStyle(description…"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n{'_': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1}, 'overall_precision': 1.0, 'overall_recall': 1.0, 'overall_f1': 1.0, 'overall_accuracy': 1.0}\n{'_': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1}, 'overall_precision': 0.0, 'overall_recall': 0.0, 'overall_f1': 0.0, 'overall_accuracy': 0.16666666666666666}\n"
    }
   ],
   "source": "metric = load_metric('seqeval')\n\npredictions = np.array([['O', 'O', 'B', 'I', 'I', 'O']])\nreferences = [['O', 'O', 'B', 'I', 'I', 'O']]\nprint(metric.compute(predictions=predictions, references=references))\n\npredictions = [['O', 'O', 'B', 'I', 'I', 'O']]\nreferences = [['B', 'I', 'I', 'O', 'O', 'O']]\nprint(metric.compute(predictions=predictions, references=references))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#export\ndef compute_metrics(p, metric=None, word_ids=None, label_list=None):\n    '''\n    1. Remove predicted and ground-truth class ids of special and sub tokens.\n    2. Convert class ids to class labels. (int ---> str)\n    3. Compute metric.\n    \n    Args:\n        p (tuple): 2-tuple consisting of model prediction and ground-truth\n            labels.  These will contain elements corresponding to special \n            tokens and sub-tokens.\n        word_ids (list): Word IDs from the tokenizer's output, indicating\n            which original word each sub-token belongs to.\n    '''\n    predictions, label_ids = p\n    predictions = predictions.argmax(axis=2)\n\n    true_predictions = remove_nonoriginal_outputs(predictions, word_ids)\n    true_label_ids = remove_nonoriginal_outputs(label_ids, word_ids)\n    \n    true_predictions = [[label_list[p] for p in pred] for pred in true_predictions]\n    true_labels = [[label_list[i] for i in label_id] for label_id in true_label_ids]\n\n    results = metric.compute(predictions=true_predictions, references=true_labels)\n    return {\n        \"precision\": results[\"overall_precision\"],\n        \"recall\": results[\"overall_recall\"],\n        \"f1\": results[\"overall_f1\"],\n        \"accuracy\": results[\"overall_accuracy\"],\n    }"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[2 0 1 0 2 2]\n [0 0 0 1 2 2]]\n[[1 2 0 1 0 0]\n [2 2 0 2 2 0]]\n"
    },
    {
     "data": {
      "text/plain": "{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'accuracy': 0.2}"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "batch_size = 2\nmax_example_length = 6\n\npredictions = np.random.randn(batch_size, max_example_length, classlabel.num_classes)\nlabel_ids = np.random.randint(low=0, high=classlabel.num_classes, \n                              size=(batch_size, max_example_length), dtype=np.int16)\nword_ids = [[None, 0, 0, 1, 2, None], \n            [None, 0, 1, None]]\n\nprint(predictions.argmax(axis=2))\nprint(label_ids)\np = (predictions, label_ids)\nmetric = load_metric('seqeval')\ncompute_metrics(p, metric=metric, label_list=classlabel.names, word_ids=word_ids)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# NER training"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Training data size: 2 positives + 26 negatives: 100%|██████████| 2/2 [00:00<00:00, 48.32it/s]"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train.  Positive count: 8.  Negative count: 29.\nValid.  Positive count: 2.  Negative count: 26.\nDownloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/json/default-7b5894af0bcaa2f9/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02...\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-7b5894af0bcaa2f9/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02. Subsequent calls will reuse this data.\n"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f09bf1eb4d4505b5bcfb92333941d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de336c451b604aefb0d5d0b4857ff85a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n"
    }
   ],
   "source": "train_meta = load_train_meta('/kaggle/input/coleridgeinitiative-show-us-the-data/train.csv').iloc[:4]\npapers = load_papers('/kaggle/input/coleridgeinitiative-show-us-the-data/train', train_meta.Id)\n\nvalid_cutoff = int(.50 * len(train_meta))\nvalid_meta = train_meta.iloc[:valid_cutoff].reset_index(drop=True)\ntrain_meta = train_meta.iloc[valid_cutoff:].reset_index(drop=True)\n\nclasslabel = get_ner_classlabel()\npretokenizer = BertPreTokenizer()\n\ntrain_cnt_pos, train_cnt_neg, train_ner_data = get_ner_data(\n    papers, df=train_meta, mark_title=True, mark_text=True,\n    classlabel=classlabel, pretokenizer=pretokenizer,\n    sentence_definition='paper', max_length=360, overlap=20, \n    neg_keywords=None, neg_sample_prob=.8)\n\nvalid_cnt_pos, valid_cnt_neg, valid_ner_data = get_ner_data(\n    papers, df=valid_meta, mark_title=True, mark_text=True,\n    classlabel=classlabel, pretokenizer=pretokenizer, \n    sentence_definition='paper', max_length=360, overlap=20, \n    neg_keywords=None, neg_sample_prob=.8)\n\nprint(f'Train.  Positive count: {train_cnt_pos}.  Negative count: {train_cnt_neg}.')\nprint(f'Valid.  Positive count: {valid_cnt_pos}.  Negative count: {valid_cnt_neg}.')\n\nwrite_ner_json(train_ner_data, pth='train_ner.json')\nwrite_ner_json(valid_ner_data, pth='valid_ner.json')\ndatasets = load_ner_datasets(data_files={'train':'train_ner.json', 'valid':'valid_ner.json'})\n\nmodel_checkpoint = 'distilbert-base-cased' \ntokenizer = create_tokenizer(model_checkpoint)\ntokenized_datasets = datasets.map(\n    partial(tokenize_and_align_labels, tokenizer=tokenizer, label_all_tokens=True), batched=True)\n\ntokenized_datasets.save_to_disk(f'datasetdict_{model_checkpoint}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\nSome weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForTokenClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nTraining data size: 8 positives + 29 negatives: 100%|██████████| 2/2 [00:22<00:00, 11.05s/it]\nTraining data size: 2 positives + 26 negatives: 100%|██████████| 2/2 [00:22<00:00, 11.02s/it]\n"
    }
   ],
   "source": "# model_checkpoint, bs = 'roberta-base', 10\nmodel_checkpoint, bs = 'distilbert-base-cased', 20\n# model_checkpoint, bs = 'xlm-roberta-base', 8\n\ntokenizer = create_tokenizer(model_checkpoint)\ndata_collator = DataCollatorForTokenClassification(tokenizer)\nmodel = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=classlabel.num_classes)\nmodel.resize_token_embeddings(len(tokenizer))\nmetric = load_metric('seqeval')\n\ntokenized_datasets = datasets.load_from_disk(f'datasetdict_{model_checkpoint}')\nword_ids = tokenized_datasets['valid']['word_ids']\ncompute_metrics_ = partial(compute_metrics, metric=metric, label_list=classlabel.names, word_ids=word_ids)\n\nargs = TrainingArguments(output_dir='test_training', num_train_epochs=2, \n                         learning_rate=2e-5, weight_decay=0.01,\n                         per_device_train_batch_size=bs, per_device_eval_batch_size=bs,\n                         evaluation_strategy='epoch', logging_steps=4, report_to='none', \n                         save_strategy='epoch', save_total_limit=6)\n\ntrainer = Trainer(model=model, args=args, \n                  train_dataset=tokenized_datasets['train'], eval_dataset=tokenized_datasets['valid'], \n                  data_collator=data_collator, tokenizer=tokenizer, compute_metrics=compute_metrics_)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n        </style>\n      \n      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4/4 02:36, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n      <th>Runtime</th>\n      <th>Samples Per Second</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.754978</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.912785</td>\n      <td>15.600500</td>\n      <td>1.795000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.860200</td>\n      <td>0.601280</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.983929</td>\n      <td>16.503200</td>\n      <td>1.697000</td>\n    </tr>\n  </tbody>\n</table><p>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=4, training_loss=0.8602162599563599, metrics={'train_runtime': 202.2169, 'train_samples_per_second': 0.02, 'total_flos': 13720950618696.0, 'epoch': 2.0, 'init_mem_cpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 1020010496, 'train_mem_cpu_peaked_delta': 3014529024})"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "trainer.train()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "total 8\ndrwxr-xr-x 2 root root 4096 Jun 27 03:11 checkpoint-2\ndrwxr-xr-x 2 root root 4096 Jun 27 03:13 checkpoint-4\n"
    }
   ],
   "source": "! ls -lrt test_training"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n        </style>\n      \n      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [8/8 02:26, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n      <th>Runtime</th>\n      <th>Samples Per Second</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>3</td>\n      <td>0.860200</td>\n      <td>0.524652</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.992937</td>\n      <td>15.438600</td>\n      <td>1.814000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.501500</td>\n      <td>0.449455</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.996008</td>\n      <td>15.188200</td>\n      <td>1.844000</td>\n    </tr>\n  </tbody>\n</table><p>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=8, training_loss=0.2507514953613281, metrics={'train_runtime': 189.3398, 'train_samples_per_second': 0.042, 'total_flos': 27401218751808.0, 'epoch': 4.0, 'init_mem_cpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 920997888, 'train_mem_cpu_peaked_delta': 1367539712})"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "# bs = 4 # xlm-roberta-base on CPU\nbs = 20 # distilbert-base-cased on CPU\n\nargs = TrainingArguments(output_dir='test_training', num_train_epochs=4, \n                         learning_rate=2e-5, weight_decay=0.01,\n                         per_device_train_batch_size=bs, per_device_eval_batch_size=bs,\n                         evaluation_strategy='epoch', logging_steps=4, report_to='none', \n                         save_strategy='epoch', save_total_limit=6)\n\ntrainer = Trainer(model=model, args=args, \n                  train_dataset=tokenized_datasets['train'], eval_dataset=tokenized_datasets['valid'], \n                  data_collator=data_collator, tokenizer=tokenizer, \n                  compute_metrics=compute_metrics_)\ntrainer.train(resume_from_checkpoint='/kaggle/working/test_training/checkpoint-4/')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n        </style>\n      \n      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2/2 00:04]\n    </div>\n    ",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "{'eval_loss': 0.4494549632072449,\n 'eval_precision': 0.0,\n 'eval_recall': 0.0,\n 'eval_f1': 0.0,\n 'eval_accuracy': 0.9960077797113318,\n 'eval_runtime': 16.3267,\n 'eval_samples_per_second': 1.715,\n 'epoch': 4.0,\n 'eval_mem_cpu_alloc_delta': 397312,\n 'eval_mem_cpu_peaked_delta': 0}"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "trainer.evaluate()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## NER inference\n\n**Turn off the Internet here**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#export\ndef get_ner_inference_data(papers, sample_submission, \n                           mark_title=False, mark_text=False,\n                           pretokenizer=BertPreTokenizer(), classlabel=get_ner_classlabel(), \n                           sentence_definition='sentence', max_length=64, overlap=20, \n                           min_length=10, contains_keywords=['data', 'study']):\n    '''\n    Args:\n        papers (dict): Each list in this dictionary consists of the section of a paper.\n        sample_submission (pd.DataFrame): Competition 'sample_submission.csv'.\n        max_length (int): Maximum number of words allowed in a sentence.\n        min_length (int): Mininum number of characters required in a sentence.\n        \n    Returns:\n        test_rows (list): Each list in this list is of the form: \n             [('goat', 0), ('win', 0), ...] and represents a sentence.  \n        paper_length (list): Number of sentences in each paper.\n    '''\n    test_rows = [] \n    paper_length = [] \n\n    for paper_id in sample_submission['Id']:\n        paper = papers[paper_id]\n\n        sentences = extract_sentences(paper, sentence_definition, mark_title, mark_text)\n        sentences = [text2words(s, pretokenizer=pretokenizer) for s in sentences]\n        sentences = shorten_sentences(sentences, max_length=max_length, overlap=overlap) \n        \n        if min_length > 0:\n            sentences = [\n                sentence for sentence in sentences if len(' '.join(sentence)) > min_length] \n            \n        if contains_keywords is not None:\n            sentences = [\n                sentence for sentence in sentences \n                if any(kw in ' '.join(word.lower() for word in sentence) for kw in contains_keywords)]\n\n        for sentence in sentences:\n            dummy_tags = [classlabel.str2int('O')]*len(sentence)\n            test_rows.append(list(zip(sentence, dummy_tags)))\n\n        paper_length.append(len(sentences))\n\n    print(f'total number of \"sentences\": {len(test_rows)}')\n    return test_rows, paper_length"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "total number of \"sentences\": 196\n[('AAAsTITLE', 0), ('Abstract', 0), ('ZZZsTITLE', 0), ('AAAsTEXT', 0), ('Cognitive', 0), ('deficits', 0), ('and', 0), ('reduced', 0), ('educational', 0), ('achievement', 0), ('are', 0), ('common', 0), ('in', 0), ('psychiatric', 0), ('illness', 0), (';', 0), ('understanding', 0), ('the', 0), ('genetic', 0), ('basis', 0), ('of', 0), ('cognitive', 0), ('and', 0), ('educational', 0), ('deficits', 0), ('may', 0), ('be', 0), ('informative', 0), ('about', 0), ('the', 0), ('etiology', 0), ('of', 0), ('psychiatric', 0), ('disorders', 0), ('.', 0), ('A', 0), ('recent', 0), (',', 0), ('large', 0), ('genomewide', 0), ('association', 0), ('study', 0), ('(', 0), ('GWAS', 0), (')', 0), ('reported', 0), ('a', 0), ('genome', 0), ('-', 0), ('wide', 0), ('significant', 0), ('locus', 0), ('for', 0), ('years', 0), ('of', 0), ('education', 0), (',', 0), ('which', 0), ('subsequently', 0), ('demonstrated', 0), ('association', 0), ('to', 0), ('general', 0), ('cognitive', 0), ('ability', 0), ('(', 0), ('\"', 0), ('g', 0), ('\"', 0), (')', 0), ('in', 0), ('overlapping', 0), ('cohorts', 0), ('.', 0), ('The', 0), ('current', 0), ('study', 0), ('was', 0), ('designed', 0), ('to', 0), ('test', 0), ('whether', 0), ('GWAS', 0), ('hits', 0), ('for', 0), ('educational', 0), ('attainment', 0), ('are', 0), ('involved', 0), ('in', 0), ('general', 0), ('cognitive', 0), ('ability', 0), ('in', 0), ('an', 0), ('independent', 0), (',', 0), ('large', 0), ('-', 0), ('scale', 0), ('collection', 0), ('of', 0), ('cohorts', 0), ('.', 0), ('Using', 0), ('cohorts', 0), ('in', 0), ('the', 0), ('Cognitive', 0), ('Genomics', 0), ('Consortium', 0), ('(', 0), ('COGENT', 0), (';', 0), ('up', 0), ('to', 0), ('20', 0), (',', 0), ('495', 0), ('healthy', 0), ('individuals', 0), (')', 0), (',', 0), ('we', 0), ('examined', 0), ('the', 0), ('relationship', 0), ('between', 0), ('g', 0), ('and', 0), ('variants', 0), ('associated', 0), ('with', 0), ('educational', 0), ('attainment', 0), ('.', 0), ('We', 0), ('next', 0), ('conducted', 0), ('meta', 0), ('-', 0), ('analyses', 0), ('with', 0), ('24', 0), (',', 0), ('189', 0), ('individuals', 0), ('with', 0), ('neurocognitive', 0), ('data', 0), ('from', 0), ('the', 0), ('educational', 0), ('attainment', 0), ('studies', 0), (',', 0), ('and', 0), ('then', 0), ('with', 0), ('53', 0), (',', 0), ('188', 0), ('largely', 0), ('independent', 0), ('individuals', 0), ('from', 0), ('a', 0), ('recent', 0), ('GWAS', 0), ('of', 0), ('cognition', 0), ('.', 0), ('A', 0), ('SNP', 0), ('(', 0), ('rs1906252', 0), (')', 0), ('located', 0), ('at', 0), ('chromosome', 0), ('6q16', 0), ('.', 0), ('1', 0), (',', 0), ('previously', 0), ('associated', 0), ('with', 0), ('years', 0), ('of', 0), ('schooling', 0), (',', 0), ('was', 0), ('significantly', 0), ('associated', 0), ('with', 0), ('g', 0), ('(', 0), ('P', 0), ('=', 0), ('1', 0), ('.', 0), ('47×10', 0), ('−4', 0), (')', 0), ('in', 0), ('COGENT', 0), ('.', 0), ('The', 0), ('first', 0), ('joint', 0), ('analysis', 0), ('of', 0), ('43', 0), (',', 0), ('381', 0), ('non', 0), ('-', 0), ('overlapping', 0), ('individuals', 0), ('for', 0), ('this', 0), ('a', 0), ('priori', 0), ('-', 0), ('designated', 0), ('locus', 0), ('was', 0), ('strongly', 0), ('significant', 0), ('(', 0), ('P', 0), ('=', 0), ('4', 0), ('.', 0), ('94×10', 0), ('−7', 0), (')', 0), (',', 0), ('and', 0), ('the', 0), ('second', 0), ('joint', 0), ('analysis', 0), ('of', 0), ('68', 0), (',', 0), ('159', 0), ('non', 0), ('-', 0), ('overlapping', 0), ('individuals', 0), ('was', 0), ('even', 0), ('more', 0), ('robust', 0), ('(', 0), ('P', 0), ('=', 0), ('1', 0), ('.', 0), ('65×10', 0), ('−9', 0), (')', 0), ('.', 0), ('These', 0), ('results', 0), ('provide', 0), ('independent', 0), ('replication', 0), (',', 0), ('in', 0), ('a', 0), ('large', 0), ('-', 0), ('scale', 0), ('dataset', 0), (',', 0), ('of', 0), ('a', 0), ('genetic', 0), ('locus', 0), ('associated', 0), ('with', 0), ('cognitive', 0), ('function', 0), ('and', 0), ('education', 0), ('.', 0), ('As', 0), ('sample', 0), ('sizes', 0), ('grow', 0), (',', 0), ('cognitive', 0), ('GWAS', 0), ('will', 0), ('identify', 0), ('increasing', 0), ('numbers', 0), ('of', 0), ('associated', 0), ('loci', 0), (',', 0), ('as', 0), ('has', 0), ('been', 0), ('accomplished', 0), ('in', 0), ('other', 0), ('polygenic', 0), ('quantitative', 0), ('traits', 0), (',', 0), ('which', 0), ('may', 0), ('be', 0), ('relevant', 0), ('to', 0), ('psychiatric', 0), ('illness', 0), ('.', 0), ('ZZZsTEXT', 0), ('AAAsTITLE', 0), ('Introduction', 0), ('ZZZsTITLE', 0), ('AAAsTEXT', 0), ('A', 0), ('general', 0), ('cognitive', 0), ('ability', 0), ('factor', 0), ('(', 0), ('also', 0), ('termed', 0), ('g', 0), (')', 0), ('typically', 0), ('captures', 0), ('just', 0), ('under', 0)]\n[15, 112, 40, 29]\n"
    }
   ],
   "source": "sample_submission = pd.read_csv('/kaggle/input/coleridgeinitiative-show-us-the-data/sample_submission.csv')\npapers = load_papers('/kaggle/input/coleridgeinitiative-show-us-the-data/test', sample_submission.Id)\n\nclasslabel = get_ner_classlabel()\npretokenizer = BertPreTokenizer()\ntest_rows, paper_length = get_ner_inference_data(papers, sample_submission, \n                                                 mark_title=True, mark_text=True,\n                                                 classlabel=classlabel, pretokenizer=pretokenizer,\n                                                 sentence_definition='paper', max_length=340, overlap=20,\n                                                 min_length=0, contains_keywords=None)\nprint(test_rows[0])\nprint(paper_length)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#export\n\ndef batched_write_ner_inference_json(papers, sample_submission, \n                                     pth='test_ner.json', batch_size=1_000, **kwargs):\n\n    paper_length = []\n    \n    for i in range(0, len(sample_submission), batch_size):\n        test_rows, bpaper_length = get_ner_inference_data(\n            papers, sample_submission.iloc[i:i + batch_size], **kwargs)\n        \n        write_ner_json(test_rows, pth, mode='w' if i==0 else 'a')\n        paper_length.extend(bpaper_length)\n        \n    return paper_length"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "total number of \"sentences\": 15\ntotal number of \"sentences\": 112\ntotal number of \"sentences\": 40\ntotal number of \"sentences\": 29\n"
    }
   ],
   "source": "sample_submission = pd.read_csv('/kaggle/input/coleridgeinitiative-show-us-the-data/sample_submission.csv')\npapers = load_papers('/kaggle/input/coleridgeinitiative-show-us-the-data/test/', sample_submission.Id)\nbatch_size=2\n\npaper_length = batched_write_ner_inference_json(papers, sample_submission, \n                                                pth='batched_write_test_ner.json', batch_size=1,\n                                                mark_title=True, mark_text=True, \n                                                classlabel=get_ner_classlabel(), pretokenizer=BertPreTokenizer(),\n                                                sentence_definition='paper', max_length=340, overlap=20,\n                                                min_length=0, contains_keywords=None)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "([15, 112, 40, 29], 196)"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "paper_length, sum(paper_length)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Downloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/json/default-7de9e6789f1ed4f5/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02...\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-7de9e6789f1ed4f5/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02. Subsequent calls will reuse this data.\n{'tokens': ['AAAsTITLE', 'Abstract', 'ZZZsTITLE', 'AAAsTEXT', 'Cognitive', 'deficits', 'and', 'reduced', 'educational', 'achievement', 'are', 'common', 'in', 'psychiatric', 'illness', ';', 'understanding', 'the', 'genetic', 'basis', 'of', 'cognitive', 'and', 'educational', 'deficits', 'may', 'be', 'informative', 'about', 'the', 'etiology', 'of', 'psychiatric', 'disorders', '.', 'A', 'recent', ',', 'large', 'genomewide', 'association', 'study', '(', 'GWAS', ')', 'reported', 'a', 'genome', '-', 'wide', 'significant', 'locus', 'for', 'years', 'of', 'education', ',', 'which', 'subsequently', 'demonstrated', 'association', 'to', 'general', 'cognitive', 'ability', '(', '\"', 'g', '\"', ')', 'in', 'overlapping', 'cohorts', '.', 'The', 'current', 'study', 'was', 'designed', 'to', 'test', 'whether', 'GWAS', 'hits', 'for', 'educational', 'attainment', 'are', 'involved', 'in', 'general', 'cognitive', 'ability', 'in', 'an', 'independent', ',', 'large', '-', 'scale', 'collection', 'of', 'cohorts', '.', 'Using', 'cohorts', 'in', 'the', 'Cognitive', 'Genomics', 'Consortium', '(', 'COGENT', ';', 'up', 'to', '20', ',', '495', 'healthy', 'individuals', ')', ',', 'we', 'examined', 'the', 'relationship', 'between', 'g', 'and', 'variants', 'associated', 'with', 'educational', 'attainment', '.', 'We', 'next', 'conducted', 'meta', '-', 'analyses', 'with', '24', ',', '189', 'individuals', 'with', 'neurocognitive', 'data', 'from', 'the', 'educational', 'attainment', 'studies', ',', 'and', 'then', 'with', '53', ',', '188', 'largely', 'independent', 'individuals', 'from', 'a', 'recent', 'GWAS', 'of', 'cognition', '.', 'A', 'SNP', '(', 'rs1906252', ')', 'located', 'at', 'chromosome', '6q16', '.', '1', ',', 'previously', 'associated', 'with', 'years', 'of', 'schooling', ',', 'was', 'significantly', 'associated', 'with', 'g', '(', 'P', '=', '1', '.', '47×10', '−4', ')', 'in', 'COGENT', '.', 'The', 'first', 'joint', 'analysis', 'of', '43', ',', '381', 'non', '-', 'overlapping', 'individuals', 'for', 'this', 'a', 'priori', '-', 'designated', 'locus', 'was', 'strongly', 'significant', '(', 'P', '=', '4', '.', '94×10', '−7', ')', ',', 'and', 'the', 'second', 'joint', 'analysis', 'of', '68', ',', '159', 'non', '-', 'overlapping', 'individuals', 'was', 'even', 'more', 'robust', '(', 'P', '=', '1', '.', '65×10', '−9', ')', '.', 'These', 'results', 'provide', 'independent', 'replication', ',', 'in', 'a', 'large', '-', 'scale', 'dataset', ',', 'of', 'a', 'genetic', 'locus', 'associated', 'with', 'cognitive', 'function', 'and', 'education', '.', 'As', 'sample', 'sizes', 'grow', ',', 'cognitive', 'GWAS', 'will', 'identify', 'increasing', 'numbers', 'of', 'associated', 'loci', ',', 'as', 'has', 'been', 'accomplished', 'in', 'other', 'polygenic', 'quantitative', 'traits', ',', 'which', 'may', 'be', 'relevant', 'to', 'psychiatric', 'illness', '.', 'ZZZsTEXT', 'AAAsTITLE', 'Introduction', 'ZZZsTITLE', 'AAAsTEXT', 'A', 'general', 'cognitive', 'ability', 'factor', '(', 'also', 'termed', 'g', ')', 'typically', 'captures', 'just', 'under'], 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
    }
   ],
   "source": "datasets = load_ner_datasets(data_files={'test': 'batched_write_test_ner.json'})\nprint(datasets['test'][0])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(1680, 264)"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "sys.getsizeof(test_rows), sys.getsizeof(datasets)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#export\n\ndef ner_predict(pth=None, tokenizer=None, model=None, metric=None, \n                per_device_train_batch_size=16, per_device_eval_batch_size=16):\n    classlabel = get_ner_classlabel()\n    datasets = load_ner_datasets(data_files={'test':pth})\n\n    print('Tokenizing testset...', end='')\n    t0 = time.time()\n    tokenized_datasets = datasets.map(\n        partial(tokenize_and_align_labels, tokenizer=tokenizer, label_all_tokens=True), \n        batched=True)\n    print(f'completed in {(time.time() - t0) / 60:.2f} mins.')\n    \n    print('Creating data collator...')\n    data_collator = DataCollatorForTokenClassification(tokenizer)\n    \n    print('Creating (dummy) training arguments...')\n    args = TrainingArguments(output_dir='test_ner', num_train_epochs=3, \n                             learning_rate=2e-5, weight_decay=0.01,\n                             per_device_train_batch_size=per_device_train_batch_size, \n                             per_device_eval_batch_size=per_device_eval_batch_size,\n                             evaluation_strategy='epoch', logging_steps=4, report_to='none', \n                             save_strategy='epoch', save_total_limit=6)\n\n    print('Creating trainer...')\n    word_ids = tokenized_datasets['test']['word_ids']\n    compute_metrics_ = partial(compute_metrics, metric=metric, label_list=classlabel.names, word_ids=word_ids)\n    trainer = Trainer(model=model, args=args, \n                      train_dataset=tokenized_datasets['test'], eval_dataset=tokenized_datasets['test'], \n                      data_collator=data_collator, tokenizer=tokenizer, compute_metrics=compute_metrics_)\n\n    print('Predicting on test samples...')\n    t0 = time.time()\n    predictions, label_ids, _ = trainer.predict(tokenized_datasets['test'])\n    print(f'completed in {(time.time() - t0) / 60:.2f} mins.')\n    \n    print('Argmaxing...')\n    t0 = time.time()\n    predictions = predictions.argmax(axis=2)\n    print(f'completed in {(time.time() - t0) / 60:.2f} mins.')\n    \n    print('Removing non-original outputs...', end='')\n    t0 = time.time()\n    predictions = remove_nonoriginal_outputs(predictions, word_ids)\n    label_ids   = remove_nonoriginal_outputs(label_ids, word_ids)\n    print(f'completed in {(time.time() - t0) / 60:.2f} mins.')\n    \n    return predictions, label_ids"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# This shows where to look for the cached metric `seqeval`.\n# metric = load_metric('/root/.cache/huggingface/modules/datasets_modules/metrics/seqeval/ec5b7242a8c40468d189ca0b2b10612578dbcad311b2a134c99e3ded58a0d6e3/seqeval.py')\n\n# Exporting the cached metric \n\n# %cd /root/.cache\n# ! zip -r huggingface_cache.zip huggingface/modules/datasets_modules/metrics/seqeval/ec5b7242a8c40468d189ca0b2b10612578dbcad311b2a134c99e3ded58a0d6e3/\n# %cd "
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Downloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/json/default-b984c80449d5016a/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02...\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-b984c80449d5016a/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02. Subsequent calls will reuse this data.\nTokenizing testset..."
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f344db7839704b77b5a3272b3852d524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\ncompleted in 0.00 mins.\nCreating data collator...\nCreating (dummy) training arguments...\nCreating trainer...\nPredicting on test samples...\n"
    },
    {
     "data": {
      "text/html": "\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n        </style>\n      \n      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1/1 : < :]\n    </div>\n    ",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/opt/conda/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "completed in 0.01 mins.\nArgmaxing...\ncompleted in 0.00 mins.\nRemoving non-original outputs...completed in 0.00 mins.\nSample 0: 15 15 15\nSample 1: 32 32 32\n"
    }
   ],
   "source": "samples = ['''Archaeologists estimate the carvings are between 4,000 and 5,000 years old''', \n           ('''I could see that I was looking at a deer stag upside down, '''\n            '''and as I continued looking around, more animals appeared on the rock,” he said.''')]\n\nsamples = [text2words(sample, pretokenizer=BertPreTokenizer()) for sample in samples]\ntest_rows = [list(zip(sample, len(sample) * [0])) for sample in samples]\nwrite_ner_json(test_rows, pth='test_ner.json')\n\nmodel_checkpoint = 'test_training/checkpoint-4/'\ntokenizer = create_tokenizer(model_checkpoint=model_checkpoint)\nmodel = AutoModelForTokenClassification.from_pretrained(model_checkpoint)\nmetric = load_metric('/root/.cache/huggingface/modules/datasets_modules/metrics/seqeval/ec5b7242a8c40468d189ca0b2b10612578dbcad311b2a134c99e3ded58a0d6e3/seqeval.py')\n\npredictions, label_ids = ner_predict(pth='test_ner.json', tokenizer=tokenizer, model=model, metric=metric, \n                                     per_device_train_batch_size=4, per_device_eval_batch_size=4)\n\n\nfor i in range(len(predictions)):\n    print(f'Sample {i}:', len(predictions[i]), len(label_ids[i]), len(samples[i]))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#export\n\ndef batched_ner_predict(pth, tokenizer=None, model=None, metric=None, \n                        batch_size=64_000, \n                        per_device_train_batch_size=16, per_device_eval_batch_size=16):\n    '''\n    Do inference on dataset in batches.\n    '''\n    lines = open(pth, mode='r').readlines()\n    \n    pth_tmp = 'ner_predict_tmp.json'\n    predictions, label_ids = [], []\n    for ib in range(0, len(lines), batch_size):\n        with open(pth_tmp, mode='w') as f:\n            f.writelines(lines[ ib: ib + batch_size ])\n\n        predictions_, label_ids_ = ner_predict(\n            pth_tmp, tokenizer=tokenizer, model=model, metric=metric, \n            per_device_train_batch_size=per_device_train_batch_size, \n            per_device_eval_batch_size=per_device_eval_batch_size)\n        predictions.extend(predictions_)\n        label_ids.extend(label_ids_)\n    return predictions, label_ids"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Downloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/json/default-6e0a5a8b54ff410f/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02...\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-6e0a5a8b54ff410f/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02. Subsequent calls will reuse this data.\nTokenizing testset..."
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e94974751d4c1f904ec7a5d1134367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\ncompleted in 0.00 mins.\nCreating data collator...\nCreating (dummy) training arguments...\nCreating trainer...\nPredicting on test samples...\n"
    },
    {
     "data": {
      "text/html": "\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n        </style>\n      \n      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1/1 : < :]\n    </div>\n    ",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "completed in 0.01 mins.\nArgmaxing...\ncompleted in 0.00 mins.\nRemoving non-original outputs...completed in 0.00 mins.\nDownloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/json/default-b4d6f39d3a2db8fb/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02...\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-b4d6f39d3a2db8fb/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02. Subsequent calls will reuse this data.\nTokenizing testset..."
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb6557f909f4770b4a2775cafc94418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\ncompleted in 0.00 mins.\nCreating data collator...\nCreating (dummy) training arguments...\nCreating trainer...\nPredicting on test samples...\n"
    },
    {
     "data": {
      "text/html": "\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n        </style>\n      \n      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1/1 : < :]\n    </div>\n    ",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "completed in 0.01 mins.\nArgmaxing...\ncompleted in 0.00 mins.\nRemoving non-original outputs...completed in 0.00 mins.\nSample 0: 15 15 15\nSample 1: 32 32 32\nSample 2: 16 16 16\nSample 3: 18 18 18\n"
    }
   ],
   "source": "samples = ['''Archaeologists estimate the carvings are between 4,000 and 5,000 years old''', \n           ('''I could see that I was looking at a deer stag upside down, '''\n            '''and as I continued looking around, more animals appeared on the rock,” he said.'''),\n           '''The RNN model we are about to build has LSTM cells as basic hidden units.''', \n           '''YouTube series, the Crooner Sessions. Now he gets his musical pals together in real life for ''']\n\nsamples = [text2words(sample, pretokenizer=BertPreTokenizer()) for sample in samples]\ntest_rows = [list(zip(sample, len(sample) * [0])) for sample in samples]\nwrite_ner_json(test_rows, pth='test_ner.json')\n\nmodel_checkpoint = 'test_training/checkpoint-4/'\ntokenizer = create_tokenizer(model_checkpoint=model_checkpoint)\nmodel = AutoModelForTokenClassification.from_pretrained(model_checkpoint)\nmetric = load_metric('/root/.cache/huggingface/modules/datasets_modules/metrics/seqeval/ec5b7242a8c40468d189ca0b2b10612578dbcad311b2a134c99e3ded58a0d6e3/seqeval.py')\n\npredictions, label_ids = batched_ner_predict(\n    'test_ner.json', tokenizer=tokenizer, model=model, metric=metric, batch_size=2, \n    per_device_train_batch_size=16, per_device_eval_batch_size=16)\n\n\nfor i in range(len(predictions)):\n    print(f'Sample {i}:', len(predictions[i]), len(label_ids[i]), len(samples[i]))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#export\ndef get_paper_dataset_labels(pth, paper_length, predictions):\n    '''\n    Args:\n        pth (Path, str): Path to json file containing NER data.  Each row is \n            of form: {'tokens': ['Studying', 'human'], 'ner_tags': [0, 0, ...]}.\n    \n    Returns:\n        paper_dataset_labels (list): Each element is a set consisting of labels predicted\n            by the model.\n    '''\n    test_sentences = [json.loads(sample)['tokens'] for sample in open(pth).readlines()]\n    \n    paper_dataset_labels = [] # store all dataset labels for each publication\n    for ipaper in range(len(paper_length)):\n        istart = sum(paper_length[:ipaper])\n        iend = istart + paper_length[ipaper]\n        \n        labels = set()\n        for sentence, pred in zip(test_sentences[istart:iend], predictions[istart:iend]):\n            curr_phrase = ''\n            for word, tag in zip(sentence, pred):\n                if tag == 'B': # start a new phrase\n                    if curr_phrase:\n                        labels.add(curr_phrase)\n                        curr_phrase = ''\n                    curr_phrase = word\n                elif tag == 'I' and curr_phrase: # continue the phrase\n                    curr_phrase += ' ' + word\n                else: # end last phrase (if any)\n                    if curr_phrase:\n                        labels.add(curr_phrase)\n                        curr_phrase = ''\n            # check if the label is the suffix of the sentence\n            if curr_phrase:\n                labels.add(curr_phrase)\n                curr_phrase = ''\n\n        # record dataset labels for this publication\n        paper_dataset_labels.append(labels)\n\n    return paper_dataset_labels"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[{'present all the', 'Tigers EcoNAX dataset'}, {'WGS Equality Definitiveness Dataset'}]\n"
    }
   ],
   "source": "sentences = ['They do not present all the features', \n             'Despite the pretraining on the Tigers EcoNAX dataset',\n             'Weirdly there has been lots of studies based on WGS Equality Definitiveness Dataset']\npaper_length = [2, 1]\ntest_rows = [[(word, 0) for word in sentence.split()] for sentence in sentences]\npredictions = [['O', 'O', 'O', 'B', 'I', 'I', 'O'],\n               ['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I'],\n               ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I']]\nfor i, row in enumerate(test_rows):\n    assert len(row) == len(predictions[i])\n\nwrite_ner_json(test_rows, pth='test_ner.json')\n\npaper_dataset_labels = get_paper_dataset_labels('test_ner.json', paper_length, predictions)\nprint(paper_dataset_labels)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Literal matching"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#export\ndef create_knowledge_bank(pth):\n    '''\n    Args:\n        pth (str): Path to meta data like 'train.csv', which\n        needs to have columns: 'dataset_title', 'dataset_label', and 'cleaned_label'.\n        \n    Returns:\n        all_labels (set): All possible strings associated with a dataset from the meta data.\n    '''\n    df = load_train_meta(pth, group_id=False)\n    all_labels = set()\n    for label_1, label_2, label_3 in df[['dataset_title', 'dataset_label', 'cleaned_label']].itertuples(index=False):\n        all_labels.add(str(label_1).lower())\n        all_labels.add(str(label_2).lower())\n        all_labels.add(str(label_3).lower())\n    return all_labels"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Creating knowledge bank...completed in 0.1352 s.\n180\n['2019 ncov complete genome sequences', '2019 ncov genome sequence', '2019 ncov genome sequences', '2019-ncov complete genome sequences', '2019-ncov genome sequence', '2019-ncov genome sequences', 'adni', 'advanced national seismic system (anss) comprehensive catalog (comcat)', 'advanced national seismic system anss comprehensive catalog comcat ', 'advanced national seismic system comprehensive catalog']\n"
    }
   ],
   "source": "pth = Path('/kaggle/input/coleridgeinitiative-show-us-the-data/train.csv')\n\nprint('Creating knowledge bank...', end='')\nt0 = time.time()\nknowledge_bank = create_knowledge_bank(pth)\nprint(f'completed in {time.time() - t0:.4f} s.')\n\nprint(len(knowledge_bank))\nprint(sorted(knowledge_bank)[:10])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#export\ndef literal_match(paper, all_labels):\n    '''\n    Args:\n        paper ()\n    '''\n    text_1 = '. '.join(section['text'] for section in paper).lower()\n    text_2 = clean_training_text(text_1, lower=True, total_clean=True)\n    \n    labels = set()\n    for label in all_labels:\n        if label in text_1 or label in text_2:\n            labels.add(clean_training_text(label, lower=True, total_clean=True))\n    return labels"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[{'adni', 'alzheimer s disease neuroimaging initiative adni'}, {'trends in international mathematics and science study', 'common core of data', 'nces common core of data'}, {'sea lake and overland surges from hurricanes', 'slosh model', 'noaa storm surge inundation'}, {'rural urban continuum codes'}]\n"
    }
   ],
   "source": "pth = Path('/kaggle/input/coleridgeinitiative-show-us-the-data/train.csv')\nknowledge_bank = create_knowledge_bank(pth)\n\nsample_submission = pd.read_csv('/kaggle/input/coleridgeinitiative-show-us-the-data/sample_submission.csv')\npapers = load_papers('/kaggle/input/coleridgeinitiative-show-us-the-data/test/', sample_submission.Id)\n\nliteral_preds = [literal_match(papers[paper_id], knowledge_bank) for paper_id in sample_submission.Id]\nprint(literal_preds)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Overall prediction for submission"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#export\ndef combine_matching_and_model(literal_preds, paper_dataset_labels):\n    '''\n    Args:\n        literal_preds (list): Each element is a set, containing predicted labels for a paper\n            using literal matching.\n        paper_dataset_labels (list): Each element is a set, containing predicted labels for \n            a paper using trained model.\n            \n    Returns:\n        filtered_dataset_labels (list): Each element is a string, containing \n            labels seperated by '|'.  \n            \n    Notes:\n        Combine literal matching predictions and model predictions. \n        Literal match predictions are appended IN FRONT of the model predictions,\n        because literal matches will be kept when removing labels that are too\n        similar to each other.\n    '''\n    all_labels = [list(literal_match) + list(model_pred) \n                  for literal_match, model_pred in zip(literal_preds, paper_dataset_labels)]\n    return all_labels"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[['mongolian racing cars', 'reallife headphones', 'dataset', 'data'],\n ['hifi dataset', 'headphones collection data'],\n ['rhs flowers fertiliser index',\n  'rhs fertiliser index',\n  'deep sea rock salts'],\n ['moma artists catalogue', 'moma artists', 'housing market']]"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "literal_preds = [\n    {'mongolian racing cars', 'reallife headphones'}, \n    {},\n    {'rhs flowers fertiliser index'}, \n    {'moma artists catalogue'}]\n\npaper_dataset_labels = [\n    {'data', 'dataset'}, \n    {'hifi dataset', 'headphones collection data'}, \n    {'deep sea rock salts', 'rhs fertiliser index'}, \n    {'moma artists', 'housing market'}]\n\ncombine_matching_and_model(literal_preds, paper_dataset_labels)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#export\ndef filter_dataset_labels(all_labels, max_similarity=0.75):\n    '''\n    When several labels for a paper are too similar, keep just one of them,\n    the one that appears FIRST.\n    \n    Args:\n        all_labels (list, set): Each element is a list of labels (str).\n        \n    Returns:\n        filtered_dataset_labels (list): Each element is a string, containing \n            labels seperated by '|'.\n    '''\n    filtered_dataset_labels = []\n\n    for labels in all_labels:\n        filtered = []\n\n        for label in labels:\n            label = clean_training_text(label, lower=True)\n            if len(filtered) == 0 or all(jaccard_similarity(label, got_label) < max_similarity \n                                         for got_label in filtered):\n                filtered.append(label)\n\n        filtered_dataset_labels.append('|'.join(filtered))\n    return filtered_dataset_labels"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['moma artists catalogue|moma artists|housing market', 'rhs flowers fertiliser index|deep sea rock salts|rhs fertiliser index']\n\n['moma artists|housing market|moma artists catalogue', 'rhs fertiliser index|deep sea rock salts']\n"
    }
   ],
   "source": "all_labels = [\n    ['moma artists catalogue', 'moma artists', 'housing market'],\n    ['rhs flowers fertiliser index', 'deep sea rock salts', 'rhs fertiliser index']]\nprint(filter_dataset_labels(all_labels, max_similarity=.9))\n\nprint()\n\nall_labels = [\n    {'moma artists catalogue', 'moma artists', 'housing market'},\n    {'rhs flowers fertiliser index', 'deep sea rock salts', 'rhs fertiliser index'}]\nprint(filter_dataset_labels(all_labels))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Inference script"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "! cp ../input/huggingface-cache/huggingface/modules/datasets_modules/metrics/seqeval/ec5b7242a8c40468d189ca0b2b10612578dbcad311b2a134c99e3ded58a0d6e3/seqeval.py ."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# sample_submission = pd.read_csv('/kaggle/input/coleridgeinitiative-show-us-the-data/train.csv').sample(500)\n# papers = load_papers('/kaggle/input/coleridgeinitiative-show-us-the-data/train/', sample_submission.Id)\n# pth_json = 'test_ner.json'\n\n# classlabel = get_ner_classlabel()\n\n# print('Preparing NER inference data...')\n# paper_length = batched_write_ner_inference_json(papers, sample_submission, \n#                                                 pth=pth_json, batch_size=3_000,\n#                                                 classlabel=classlabel, pretokenizer=BertPreTokenizer(),\n#                                                 sentence_definition='paper', max_length=360, overlap=20,\n#                                                 min_length=0, contains_keywords=None)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# model_checkpoint = '../input/showusdata-roberta-base-ner/training_results_roberta-base/checkpoint-25458'\n# bs, batch_size = 300, 64_000\n# max_similarity = 1\n\n# print('Loading model, tokenizer, and metric...')\n# tokenizer = create_tokenizer(model_checkpoint=model_checkpoint)\n# model = AutoModelForTokenClassification.from_pretrained(model_checkpoint)\n# metric = load_metric('seqeval.py')\n\n# print('Predicting on test set with model...')\n# predictions, label_ids = batched_ner_predict(\n#     pth_json, tokenizer=tokenizer, model=model, metric=metric, batch_size=batch_size, \n#     per_device_train_batch_size=bs, per_device_eval_batch_size=bs)\n# predictions = [[classlabel.int2str(p) for p in pred] for pred in predictions]\n# label_ids   = [[classlabel.int2str(l) for l in label] for label in label_ids]\n\n# print('Getting predicted labels for each article...')\n# paper_dataset_labels = get_paper_dataset_labels(pth_json, paper_length, predictions)\n\n# print('String matching...')\n# knowledge_bank = create_knowledge_bank('/kaggle/input/coleridgeinitiative-show-us-the-data/train.csv')\n# literal_preds = []\n# for paper_id in sample_submission.Id:\n#     literal_preds.append(literal_match(papers[paper_id], knowledge_bank))\n\n# print('Combining literal matches and model predictions...')\n# all_labels = combine_matching_and_model(literal_preds, paper_dataset_labels)\n\n# print('Keeping just one of labels that are too similar to each other...')\n# filtered_dataset_labels = filter_dataset_labels(all_labels, max_similarity=max_similarity)\n\n# sample_submission['PredictionString'] = filtered_dataset_labels\n\n# sample_submission.to_csv('submission.csv', index=False)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# with pd.option_context('max_colwidth', -1):\n#     display(pd.read_csv('submission.csv')[['dataset_label', 'PredictionString']])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Inference script (ensemble)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Preparing NER inference data...\ntotal number of \"sentences\": 289\n"
    }
   ],
   "source": "# ! cp ../input/huggingface-cache/huggingface/modules/datasets_modules/metrics/seqeval/ec5b7242a8c40468d189ca0b2b10612578dbcad311b2a134c99e3ded58a0d6e3/seqeval.py .\n\n# print('Preparing NER inference data...')\n# sample_submission = pd.read_csv('/kaggle/input/coleridgeinitiative-show-us-the-data/sample_submission.csv')\n# papers = load_papers('/kaggle/input/coleridgeinitiative-show-us-the-data/test/', sample_submission.Id)\n# classlabel = get_ner_classlabel()\n# pretokenizer = BertPreTokenizer()\n# test_rows, paper_length = get_ner_inference_data(papers, sample_submission, \n#                                                  classlabel=classlabel, pretokenizer=pretokenizer,\n#                                                  sentence_definition='section', max_length=300, overlap=20,\n#                                                  min_length=0, contains_keywords=None)\n# write_ner_json(test_rows, pth='test_ner.json')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ensembles_inference_kwargs = [\n#     {'model_name': 'roberta-base',\n#      'model_checkpoint': '../input/showusdata-roberta-base-ner/training_results_roberta-base/checkpoint-114561',\n#      'per_device_batch_size': 8, 'batch_size': 40_000}, \n#     {'model_name': 'distilbert-base-cased', \n#      'model_checkpoint': '../input/showusdata-distilbert-base-cased-ner/training_results_distilbert-base-cased/checkpoint-56997',\n#      'per_device_batch_size': 20, 'batch_size': 64_000}]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ensemble_model_preds = []\n\n# for d in ensembles_inference_kwargs:\n#     print(f\">>>> {d['model_name']}\")\n    \n#     print('Loading model, tokenizer, and metric...')\n#     model_checkpoint = d['model_checkpoint']\n#     tokenizer = create_tokenizer(model_checkpoint=model_checkpoint)\n#     model = AutoModelForTokenClassification.from_pretrained(model_checkpoint)\n#     metric = load_metric('seqeval.py')\n\n#     print('Predicting on each sentence...')\n#     bs = d['per_device_batch_size']\n#     predictions, _ = batched_ner_predict(\n#         'test_ner.json', tokenizer=tokenizer, model=model, metric=metric, \n#         batch_size=d['batch_size'], per_device_train_batch_size=bs, per_device_eval_batch_size=bs)\n#     predictions = [[classlabel.int2str(p) for p in pred] for pred in predictions]\n\n#     print('Getting predicted labels for each article...')\n#     paper_dataset_labels = get_paper_dataset_labels('test_ner.json', paper_length, predictions)\n    \n#     ensemble_model_preds.append(paper_dataset_labels)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# print('String matching...')\n# knowledge_bank = create_knowledge_bank('/kaggle/input/coleridgeinitiative-show-us-the-data/train.csv')\n# literal_preds = []\n# for paper_id in sample_submission.Id:\n#     literal_preds.append(literal_match(papers[paper_id], knowledge_bank))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# print('Combining all sets of predictions...')\n\n# all_labels = [[label for label_set in set_tuple for label in label_set] \n#               for set_tuple in zip(literal_preds, *ensemble_model_preds)]\n\n# all_labels"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# print('Keeping just one of labels that are too similar to each other...')\n# filtered_dataset_labels = filter_dataset_labels(all_labels, max_similarity=1)\n\n# sample_submission['PredictionString'] = filtered_dataset_labels\n\n# sample_submission.to_csv('submission.csv', index=False)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ! cat submission.csv"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Error analysis"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# model_checkpoint = '../input/showusdata-distilbert-base-cased-ner/training_results_distilbert-base-cased/checkpoint-56997'\n# pth_valid_json = '../input/showdata-ner-datasets-distilbert/train_ner.json'\n\n# ner_data_valid = random.sample(open(pth_valid_json).readlines(), 100_000)\n# ner_data_valid = [json.loads(sample) for sample in ner_data_valid]\n# ner_data_valid = [list(zip(sample['tokens'], sample['ner_tags'])) for sample in ner_data_valid]\n# write_ner_json(ner_data_valid, pth='valid_ner.json')\n\n# tokenizer = create_tokenizer(model_checkpoint=model_checkpoint)\n# classlabel = get_ner_classlabel()\n# model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=classlabel.num_classes)\n# metric = load_metric('seqeval')\n\n# predictions, label_ids = batched_ner_predict(\n#     pth='valid_ner.json', tokenizer=tokenizer, model=model, metric=metric, \n#     per_device_train_batch_size=20, per_device_eval_batch_size=20, batch_size=64_000)\n# predictions = [[classlabel.int2str(p) for p in pred] for pred in predictions]\n# label_ids   = [[classlabel.int2str(l) for l in label] for label in label_ids]\n\n# paper_dataset_labels = get_paper_dataset_labels('valid_ner.json', len(predictions) * [1], predictions)\n# gt_paper_dataset_labels = get_paper_dataset_labels('valid_ner.json', len(label_ids) * [1], label_ids)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# for predicted_labels, gt_labels in zip(paper_dataset_labels, gt_paper_dataset_labels):\n#     if gt_labels:\n#         print(predicted_labels, gt_labels)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# metric.compute(predictions=predictions, references=label_ids)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# References\n- https://www.kaggle.com/tungmphung/pytorch-bert-for-named-entity-recognition/notebook\n- https://www.kaggle.com/tungmphung/coleridge-matching-bert-ner/notebook\n- https://github.com/huggingface/notebooks/blob/master/examples/token_classification.ipynb\n- https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin\n- https://huggingface.co/docs/datasets/loading_metrics.html\n- [Python strings and memory](https://rushter.com/blog/python-strings-and-memory/)\n- [Grandmaster Series – Building World-Class NLP Models with Transformers and Hugging Face](https://www.kaggle.com/c/commonlitreadabilityprize/discussion/245004)\n- https://huggingface.co/transformers/tokenizer_summary.html\n- https://discuss.huggingface.co/t/t5-seq2seq-custom-fine-tuning/1497/4\n- https://www.kaggle.com/c/google-quest-challenge/discussion/123770"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
